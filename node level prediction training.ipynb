{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "339da00e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-22 17:53:06.560074: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import fire\n",
    "from visdom import Visdom\n",
    "import pickle\n",
    "import sys, os\n",
    "import umap, numba\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import os,glob, pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "import copy\n",
    "from collections import Counter\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch_geometric.nn import GCNConv, GATConv, DeepGraphInfomax, SAGEConv\n",
    "from torch_geometric.nn import DenseGraphConv\n",
    "from torch_geometric.utils import to_dense_batch, to_dense_adj, dense_to_sparse\n",
    "from torch_geometric.nn import GINEConv\n",
    "from torch_geometric.utils import dropout_adj\n",
    "from torch_geometric.nn import APPNP\n",
    "from torch_cluster import knn_graph\n",
    "from torch_geometric.data import Data \n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "from torch_geometric.data import InMemoryDataset,DataLoader\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32ee50a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1e-15\n",
    "\n",
    "class GCNNet(torch.nn.Module):\n",
    "    def __init__(self, inp_dim, out_dim, hidden_topology=[32,64,128,128], p=0.5, p2=0.1, drop_each=True):\n",
    "        super(GCNNet, self).__init__()\n",
    "        self.out_dim=out_dim\n",
    "        self.convs = nn.ModuleList([GATConv(inp_dim, hidden_topology[0])]+[GATConv(hidden_topology[i],hidden_topology[i+1]) for i in range(len(hidden_topology[:-1]))])\n",
    "        self.drop_edge = lambda edge_index: dropout_adj(edge_index,p=p2)[0]\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.fc = nn.Linear(hidden_topology[-1], out_dim)\n",
    "        self.drop_each=drop_each\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr=None):\n",
    "        for conv in self.convs:\n",
    "            if self.drop_each and self.training: edge_index=self.drop_edge(edge_index)\n",
    "            x=conv(x, edge_index, edge_attr)\n",
    "            x = F.relu(x)\n",
    "        z=x\n",
    "        if self.training:\n",
    "            z = self.dropout(z)\n",
    "        x = self.fc(z)\n",
    "        return x,z\n",
    "    \n",
    "class GCNFeatures(torch.nn.Module):\n",
    "    def __init__(self, gcn, bayes=False):\n",
    "        super(GCNFeatures, self).__init__()\n",
    "        self.gcn=gcn\n",
    "        self.drop_each=bayes\n",
    "    \n",
    "    def forward(self, x, edge_index, edge_attr=None):\n",
    "        for conv in self.gcn.convs:\n",
    "            if self.drop_each: edge_index=self.gcn.drop_edge(edge_index)\n",
    "            x = F.relu(conv(x, edge_index, edge_attr))\n",
    "        if self.drop_each:\n",
    "            x = self.gcn.dropout(x)\n",
    "        y = F.softmax(self.gcn.fc(x))\n",
    "        return x,y\n",
    "\n",
    "def fit_model(graph_data='',\n",
    "                use_weights=False,\n",
    "                use_model=None,\n",
    "                n_batches_backward=1,\n",
    "                f1_metric='weighted',\n",
    "                n_epochs=1500,\n",
    "                out_dir=\"/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/users/Sophie_Chen/gnn/\",\n",
    "                lr=1e-2,\n",
    "                eta_min=1e-4,\n",
    "                T_max=20,\n",
    "                wd=0,\n",
    "                hidden_topology=[32,64,128,128],\n",
    "                p=0.5,\n",
    "                p2=0.3,\n",
    "                burnin=400,\n",
    "                warmup=100,\n",
    "                gpu_id=0,\n",
    "                batch_size=1\n",
    "                ):\n",
    "    print(gpu_id); torch.cuda.set_device(gpu_id)\n",
    "    datasets=pickle.load(open(graph_data,'rb'))\n",
    "    train_dataset = [dataset for key in datasets for dataset in datasets[key]['train']]\n",
    "    val_dataset = [dataset for key in datasets for dataset in datasets[key]['val']]\n",
    "    print(len(train_dataset), 'training graphs,', len(val_dataset), 'validation graphs')\n",
    "    \n",
    "    print(\"training graph sizes:\", end='')\n",
    "    for x in train_dataset:\n",
    "        print(x.x.shape[0], end=\", \")\n",
    "    print(\"\\nValidation graph sizes:\", end=\" \")\n",
    "    for x in val_dataset:\n",
    "        print(x.x.shape[0], end=\", \")\n",
    " \n",
    "    y_train=np.hstack([graph.y.numpy() for graph in train_dataset])\n",
    "\n",
    "    if use_weights: \n",
    "        weights=compute_class_weight('balanced',classes=np.unique(y_train),y=y_train)\n",
    "    else: \n",
    "        weights=None \n",
    "       \n",
    "    # load model\n",
    "    model=GCNNet(train_dataset[0].x.shape[1],len(np.unique(y_train)),hidden_topology=hidden_topology,p=p,p2=p2)\n",
    "    model=model.cuda()\n",
    "\n",
    "    # load optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=lr,weight_decay=wd)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max, eta_min=eta_min, last_epoch=-1)\n",
    "    criterion=nn.CrossEntropyLoss(weight=torch.tensor(weights).float() if use_weights else None)\n",
    "    criterion=criterion.cuda()\n",
    "\n",
    "    # initialize val saving\n",
    "    save_mod=False\n",
    "    past_performance=[0]\n",
    "\n",
    "    # dataloaders\n",
    "    dataloaders={}\n",
    "\n",
    "    dataloaders['train']=DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
    "    dataloaders['val']=DataLoader(val_dataset,shuffle=True)\n",
    "    dataloaders['warmup']=DataLoader(train_dataset,shuffle=False)\n",
    "    train_loader=dataloaders['warmup']\n",
    "\n",
    "    n_total_batches=0\n",
    "    train_val_f1=[]\n",
    "    for epoch in range(n_epochs):\n",
    "        Y,Y_Pred=[],[]\n",
    "        for i,data in enumerate(train_loader):\n",
    "            n_total_batches+=1\n",
    "            model.train(True)\n",
    "            x=data.x.cuda()\n",
    "            edge_index=data.edge_index.cuda()\n",
    "            y=data.y.cuda()\n",
    "            y_out=model(x,edge_index)\n",
    "            loss = criterion(y_out, y) / n_batches_backward\n",
    "            loss.backward()\n",
    "            if n_total_batches%n_batches_backward==0 or (i==len(train_loader.dataset)-1):\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            Y_Pred.append(F.softmax(y_out, dim=1).argmax(1).detach().cpu().numpy().flatten())\n",
    "            Y.append(y.detach().cpu().numpy().flatten())\n",
    "            del x, edge_index, loss, y_out\n",
    "            if epoch <=warmup:\n",
    "                break \n",
    "        if epoch == warmup:\n",
    "            train_loader=dataloaders['train']\n",
    "        if epoch>=burnin:\n",
    "            save_mod=True\n",
    "        train_f1=f1_score(np.hstack(Y),np.hstack(Y_Pred),average=f1_metric)\n",
    "        scheduler.step()\n",
    "        Y,Y_Pred=[],[]\n",
    "        for i,data in enumerate(dataloaders['val']):\n",
    "            model.train(False)\n",
    "            x=data.x.cuda()\n",
    "            edge_index=data.edge_index.cuda()\n",
    "            y=data.y.cuda()\n",
    "            y_out=model(x,edge_index)\n",
    "            loss = criterion(y_out, y) \n",
    "            y_prob=F.softmax(y_out, dim=1).detach().cpu().numpy()\n",
    "            y_pred=y_prob.argmax(1).flatten()\n",
    "            y_true=y.detach().cpu().numpy().flatten()\n",
    "            Y_Pred.append(y_pred)\n",
    "            Y.append(y_true)\n",
    "            #if vis_every and epoch%vis_every==0 and not i:\n",
    "               # vis.scatter(data.pos.numpy(),opts=dict(markercolor=(y_pred*255).astype(int),webgl=False,markerborderwidth=0,markersize=5),win=\"pred\")\n",
    "               # vis.scatter(data.pos.numpy(),opts=dict(markercolor=y_true*255,webgl=False,markerborderwidth=0,markersize=5),win=\"true\")\n",
    "            del x, edge_index, loss, y_out\n",
    "        val_f1=f1_score(np.hstack(Y),np.hstack(Y_Pred),average=f1_metric)\n",
    "        if save_mod and val_f1>=max(past_performance):\n",
    "            best_model_dict=copy.deepcopy(model.state_dict())\n",
    "            past_performance.append(val_f1)\n",
    "        print(epoch,train_f1,val_f1,flush=True)\n",
    "        train_val_f1.append((train_f1,val_f1))\n",
    "\n",
    "    model.load_state_dict(best_model_dict)\n",
    "    torch.save(model.state_dict(),os.path.join(out_dir,f\"model.pth\"))\n",
    "    torch.save(train_val_f1,os.path.join(out_dir,f\"f1.log.pth\"))\n",
    "    return Y, Y_Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e0d6a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8659e37f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "234 training graphs, 90 validation graphs\n",
      "training graph sizes:20589, 5563, 5101, 5719, 5649, 6098, 6239, 4220, 4557, 4607, 817, 795, 703, 832, 668, 884, 583, 902, 815, 878, 844, 826, 871, 842, 2626, 1742, 2955, 2561, 2825, 7126, 6957, 5176, 4841, 5075, 4659, 5137, 5193, 10733, 10457, 10168, 10205, 7420, 6622, 7200, 6892, 6043, 8925, 7523, 8040, 18384, 3285, 3282, 2217, 2806, 817, 795, 703, 832, 668, 884, 583, 902, 815, 878, 844, 826, 871, 842, 6056, 217, 22341, 8943, 23840, 2319, 2536, 2706, 2642, 2598, 2578, 5059, 4642, 5019, 5072, 2608, 532, 2529, 2207, 2774, 2110, 256, 647, 1926, 256, 1968, 2800, 369, 358, 2152, 2573, 5921, 2435, 6168, 6601, 6353, 6222, 5494, 5831, 4710, 5083, 1686, 1663, 1787, 1805, 1665, 3270, 3424, 3966, 3803, 3460, 3076, 3317, 3746, 3797, 3216, 2713, 2708, 2900, 2921, 2752, 2578, 2365, 2314, 2572, 2198, 2440, 2460, 2678, 2647, 2462, 4220, 4557, 4607, 13521, 15681, 18198, 459, 8477, 2248, 11270, 12102, 7910, 2793, 2950, 3738, 3631, 2626, 1742, 2955, 2561, 2825, 3117, 2663, 5892, 3544, 5045, 506, 8312, 15269, 10656, 10277, 8771, 10713, 10333, 8385, 8318, 11918, 7890, 7228, 7762, 6950, 7567, 6416, 6347, 186, 6236, 6896, 5952, 7163, 8481, 8477, 2290, 2311, 2053, 2518, 14939, 16135, 17493, 4862, 5344, 3579, 2806, 3465, 3510, 3861, 1230, 1299, 3534, 3522, 3468, 3051, 2460, 3236, 3291, 7697, 1708, 2059, 2178, 2096, 2145, 212, 2055, 1275, 1771, 1686, 1663, 1787, 1805, 1665, 6353, 6222, 5494, 5831, 4710, 5083, \n",
      "Validation graph sizes: 20706, 5804, 5642, 6085, 4472, 935, 850, 3280, 6814, 4577, 5046, 5220, 10638, 10268, 10423, 8924, 6675, 7185, 6557, 6294, 9594, 8280, 20123, 2812, 1747, 935, 850, 10754, 14272, 2423, 2523, 4837, 4723, 296, 223, 375, 2947, 6628, 5921, 5516, 4639, 1672, 3325, 3533, 3023, 2780, 1890, 4472, 2063, 10642, 13586, 7125, 2684, 3395, 3280, 3285, 2890, 6360, 8954, 10950, 10025, 10069, 10265, 8570, 11553, 7129, 7887, 8013, 6763, 5449, 6673, 8178, 8539, 2000, 14068, 15735, 16641, 4344, 3144, 851, 3362, 3383, 3095, 7718, 2201, 2088, 1672, 5921, 5516, 4639, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dartfs-hpc/rc/home/3/f006n33/anaconda3/envs/hiss/lib/python3.8/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7576670517340872 0.6567232646383594\n",
      "1 0.8925171231906389 0.6827593169576053\n",
      "2 0.9512308352798088 0.7251630603274609\n",
      "3 0.9673065460700395 0.7359452608350822\n",
      "4 0.9745752404400914 0.7599332948809647\n",
      "5 0.977137020256 0.7833815680988803\n",
      "6 0.9783759051111769 0.786171318040969\n",
      "7 0.9779372361278236 0.7871418053807854\n",
      "8 0.9791518868436854 0.784315243681778\n",
      "9 0.9779680203448804 0.7774041537835195\n",
      "10 0.9760511003583089 0.7713587754330876\n",
      "11 0.9747361686781612 0.7697116096982307\n",
      "12 0.9706079751963161 0.7654883510923532\n",
      "13 0.9670623111607559 0.7639590032773195\n",
      "14 0.9655244419586676 0.767050485891488\n",
      "15 0.9637469744988574 0.7676360094209151\n",
      "16 0.9646395830392398 0.7662928870647098\n",
      "17 0.9663632881747346 0.7665612983980747\n",
      "18 0.9680590687880833 0.7676409274318248\n",
      "19 0.9692876817253276 0.7762777962203208\n",
      "20 0.9708484400608575 0.7815885963530007\n",
      "21 0.972419910056201 0.7818423464566379\n",
      "22 0.9743585572571725 0.7796819754603438\n",
      "23 0.9754153241272533 0.7778651185414359\n",
      "24 0.974906027571371 0.7825218653815502\n",
      "25 0.9772871360599685 0.7846076177923103\n",
      "26 0.9747613350007364 0.7843712839201638\n",
      "27 0.9739208176993766 0.7841706413913473\n",
      "28 0.9712024360611422 0.7842494292450919\n",
      "29 0.9678843412435747 0.78451404215183\n",
      "30 0.963731501485067 0.7843668821025017\n",
      "31 0.9642506657306726 0.7841996934461181\n",
      "32 0.9657133282088648 0.7843214427129599\n",
      "33 0.9683244628076858 0.7843207876523093\n",
      "34 0.9721401018024939 0.7844092653201156\n",
      "35 0.9727785467883122 0.7857941400283216\n",
      "36 0.9744943256298894 0.7877817886290857\n",
      "37 0.9727057619756073 0.7883332917951829\n",
      "38 0.9739450688844188 0.7884349443358057\n",
      "39 0.97274719562176 0.7885322757590911\n",
      "40 0.9733217174196743 0.7885222802345019\n",
      "41 0.9763115883258656 0.7884855213317525\n",
      "42 0.9792519674315623 0.7885033719278052\n",
      "43 0.9768116477783199 0.7884038685543452\n",
      "44 0.9756829545225923 0.7878854589296109\n",
      "45 0.9712406445661338 0.7876363444371002\n",
      "46 0.9682122502510259 0.7872281268025968\n",
      "47 0.9686601818899643 0.7874019894983235\n",
      "48 0.9700120512871484 0.787601983395493\n",
      "49 0.9734152648110441 0.7875695581180677\n",
      "50 0.9730446447466452 0.7874561773407269\n",
      "51 0.9740263894758977 0.7877019844682486\n",
      "52 0.9720612035220237 0.7875369756042009\n",
      "53 0.9706839326811815 0.7872127084485111\n",
      "54 0.9673172082427229 0.7873902365903324\n",
      "55 0.9735842587651707 0.7882854314936648\n",
      "56 0.9771505173295022 0.7900206844299282\n",
      "57 0.9793640540146222 0.7928103776295979\n",
      "58 0.9775372512559134 0.7969674834296403\n",
      "59 0.9745890055829566 0.8004764973816781\n",
      "60 0.9694655222497918 0.8025618307040568\n",
      "61 0.9672958388828032 0.8030754915512079\n",
      "62 0.9713169728865092 0.8022588528191699\n",
      "63 0.9764360085577936 0.7991247271641064\n",
      "64 0.9775806402547932 0.7943547733745862\n",
      "65 0.9778060924367238 0.7907172584443022\n",
      "66 0.9748832458937695 0.7891607767990033\n",
      "67 0.9720241852870207 0.7882508619830153\n",
      "68 0.9689006404242619 0.7875462792760864\n",
      "69 0.9698367752605888 0.7871371755837462\n",
      "70 0.9748306816918901 0.7872379199412325\n",
      "71 0.9785168373563254 0.7883935568077399\n",
      "72 0.9776122670049613 0.7898690162535076\n",
      "73 0.9767541333605303 0.7904552052576104\n",
      "74 0.9726225399662803 0.7899841854363581\n",
      "75 0.9714306523933555 0.7894518561292397\n",
      "76 0.9762695930180764 0.7887981098733061\n",
      "77 0.9773371668535833 0.7876093899440846\n",
      "78 0.9759515520663671 0.7861383526606859\n",
      "79 0.9746103225487278 0.7843227188405419\n",
      "80 0.9738261491093242 0.784312001483001\n",
      "81 0.9729102889816179 0.7834469230851346\n",
      "82 0.976470446702881 0.7823784616522471\n",
      "83 0.977133132804809 0.7813209280771581\n",
      "84 0.9770619491182916 0.7798987113340278\n",
      "85 0.9739303301308702 0.7765809171905373\n",
      "86 0.9728571157846408 0.7732039773262027\n",
      "87 0.9747164933035036 0.7705382677317392\n",
      "88 0.9776106248704329 0.7688676963145501\n",
      "89 0.9756925026595644 0.7678589602115928\n",
      "90 0.9710001803399083 0.7674511296655019\n",
      "91 0.9732317203167435 0.7671585795466068\n",
      "92 0.9764936999360627 0.7666963893535477\n",
      "93 0.9770869738144851 0.7665773812798808\n",
      "94 0.9763198117147373 0.7675535991969785\n",
      "95 0.9751911812861981 0.7686058646773958\n",
      "96 0.9784954699495836 0.7698576241685305\n",
      "97 0.9780039210675749 0.7710232689753864\n",
      "98 0.9778498531549833 0.7715350310795029\n",
      "99 0.9745399864249491 0.7717392942723955\n",
      "100 0.9775101196434843 0.7699019629375414\n",
      "101 0.6870383756767999 0.7931994719063858\n",
      "102 0.7329995093403424 0.7937659210506551\n",
      "103 0.732656479192891 0.7937659210506551\n",
      "104 0.7343512134644934 0.7937501617538629\n",
      "105 0.736034178548619 0.7925805291105825\n",
      "106 0.7366163339573615 0.7937510887816347\n",
      "107 0.7350252623883656 0.7936874247704843\n",
      "108 0.7381169228680697 0.7922724605700443\n",
      "109 0.7324094801268085 0.7922724605700443\n",
      "110 0.732424381776108 0.7922724605700443\n",
      "111 0.7324017525993146 0.7922724605700443\n",
      "112 0.732558527131582 0.7922724605700443\n",
      "113 0.7325562595347588 0.7922733673166905\n",
      "114 0.7325503904165958 0.7922760875459453\n",
      "115 0.7360490119445846 0.7922760875459453\n",
      "116 0.732548589607226 0.7922779010232125\n",
      "117 0.7325495233706173 0.7922779010232125\n",
      "118 0.732553591892619 0.7922742740615559\n",
      "119 0.7325599225501492 0.7922742740615559\n",
      "120 0.7325489897373391 0.7922760875459453\n",
      "121 0.7336016501827672 0.7922869683027197\n",
      "122 0.7325499902515851 0.7922869683027197\n",
      "123 0.7325499902515851 0.7922869683027197\n",
      "124 0.7325499902515851 0.7922869683027197\n",
      "125 0.7325495233706173 0.7922869683027197\n",
      "126 0.7325490564891644 0.7922869683027197\n",
      "127 0.7325499902515851 0.7922869683027197\n",
      "128 0.7325499902515851 0.7922869683027197\n",
      "129 0.7325499902515851 0.7922869683027197\n",
      "130 0.7325499902515851 0.7922869683027197\n",
      "131 0.7325499902515851 0.7922869683027197\n",
      "132 0.7325499902515851 0.7922869683027197\n",
      "133 0.7325499902515851 0.7922869683027197\n",
      "134 0.7325499902515851 0.7922869683027197\n",
      "135 0.7325499902515851 0.7922869683027197\n",
      "136 0.7325499902515851 0.7922869683027197\n",
      "137 0.7325499902515851 0.7922869683027197\n",
      "138 0.7325499902515851 0.7922869683027197\n",
      "139 0.7325499902515851 0.7922869683027197\n",
      "140 0.7325499902515851 0.7922869683027197\n",
      "141 0.7325499902515851 0.7922869683027197\n",
      "142 0.7325499902515851 0.7922869683027197\n",
      "143 0.7325499902515851 0.7922869683027197\n",
      "144 0.7325499902515851 0.7922869683027197\n",
      "145 0.7325499902515851 0.7922869683027197\n",
      "146 0.7325499902515851 0.7922869683027197\n",
      "147 0.7325499902515851 0.7922869683027197\n",
      "148 0.7325499902515851 0.7922869683027197\n",
      "149 0.7325499902515851 0.7922869683027197\n",
      "150 0.7325499902515851 0.7922869683027197\n",
      "151 0.7325499902515851 0.7922869683027197\n",
      "152 0.7325499902515851 0.7922869683027197\n",
      "153 0.7325499902515851 0.7922869683027197\n",
      "154 0.7325499902515851 0.7922869683027197\n",
      "155 0.7325499902515851 0.7922869683027197\n",
      "156 0.7325499902515851 0.7922869683027197\n"
     ]
    }
   ],
   "source": [
    "y, y_pred = fit_model(\"/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/users/Sophie_Chen/graph_dataset/graph_dataset.pkl\", \n",
    "                      use_weights=True, \n",
    "                      lr=1e-4, \n",
    "                      out_dir='/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/users/Sophie_Chen/gnn/', \n",
    "                      n_epochs=1000, \n",
    "                      gpu_id=0, \n",
    "                      burnin=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "602f5a2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "234 training graphs, 90 validation graphs\n",
      "training graph sizes:20589, 5563, 5101, 5719, 5649, 6098, 6239, 4220, 4557, 4607, 817, 795, 703, 832, 668, 884, 583, 902, 815, 878, 844, 826, 871, 842, 2626, 1742, 2955, 2561, 2825, 7126, 6957, 5176, 4841, 5075, 4659, 5137, 5193, 10733, 10457, 10168, 10205, 7420, 6622, 7200, 6892, 6043, 8925, 7523, 8040, 18384, 3285, 3282, 2217, 2806, 817, 795, 703, 832, 668, 884, 583, 902, 815, 878, 844, 826, 871, 842, 6056, 217, 22341, 8943, 23840, 2319, 2536, 2706, 2642, 2598, 2578, 5059, 4642, 5019, 5072, 2608, 532, 2529, 2207, 2774, 2110, 256, 647, 1926, 256, 1968, 2800, 369, 358, 2152, 2573, 5921, 2435, 6168, 6601, 6353, 6222, 5494, 5831, 4710, 5083, 1686, 1663, 1787, 1805, 1665, 3270, 3424, 3966, 3803, 3460, 3076, 3317, 3746, 3797, 3216, 2713, 2708, 2900, 2921, 2752, 2578, 2365, 2314, 2572, 2198, 2440, 2460, 2678, 2647, 2462, 4220, 4557, 4607, 13521, 15681, 18198, 459, 8477, 2248, 11270, 12102, 7910, 2793, 2950, 3738, 3631, 2626, 1742, 2955, 2561, 2825, 3117, 2663, 5892, 3544, 5045, 506, 8312, 15269, 10656, 10277, 8771, 10713, 10333, 8385, 8318, 11918, 7890, 7228, 7762, 6950, 7567, 6416, 6347, 186, 6236, 6896, 5952, 7163, 8481, 8477, 2290, 2311, 2053, 2518, 14939, 16135, 17493, 4862, 5344, 3579, 2806, 3465, 3510, 3861, 1230, 1299, 3534, 3522, 3468, 3051, 2460, 3236, 3291, 7697, 1708, 2059, 2178, 2096, 2145, 212, 2055, 1275, 1771, 1686, 1663, 1787, 1805, 1665, 6353, 6222, 5494, 5831, 4710, 5083, \n",
      "Validation graph sizes: 20706, 5804, 5642, 6085, 4472, 935, 850, 3280, 6814, 4577, 5046, 5220, 10638, 10268, 10423, 8924, 6675, 7185, 6557, 6294, 9594, 8280, 20123, 2812, 1747, 935, 850, 10754, 14272, 2423, 2523, 4837, 4723, 296, 223, 375, 2947, 6628, 5921, 5516, 4639, 1672, 3325, 3533, 3023, 2780, 1890, 4472, 2063, 10642, 13586, 7125, 2684, 3395, 3280, 3285, 2890, 6360, 8954, 10950, 10025, 10069, 10265, 8570, 11553, 7129, 7887, 8013, 6763, 5449, 6673, 8178, 8539, 2000, 14068, 15735, 16641, 4344, 3144, 851, 3362, 3383, 3095, 7718, 2201, 2088, 1672, 5921, 5516, 4639, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dartfs-hpc/rc/home/3/f006n33/anaconda3/envs/hiss/lib/python3.8/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.574741640886651 0.6261320531429796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.7950344363929887 0.65062912760669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.8942356351153934 0.6863920042227517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.9252848692881191 0.7251813639102778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 0.9401986650059074 0.7291048364005899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0.9529921272438477 0.7226095345786548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 0.9609072830537124 0.7297280008981115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 0.9688187476390578 0.736370185435425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 0.9749027003600739 0.7353124673639012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0.9788213579325382 0.7432923409605419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.98085646167947 0.7444153345295051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 0.9814277078114401 0.7432309326458255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 0.982900245141939 0.7422289317428954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 0.9819002585343728 0.7458771997577569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 0.9804588062748704 0.7507966025871571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 0.9783327867937402 0.7468282747909656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 0.9730477705180473 0.7339253029846297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 0.9673574866888677 0.7340580550808138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 0.9654123672914052 0.737083528475738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 0.9638342985964677 0.7448906427867562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 0.9670784056620306 0.7487958637941783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 0.9682511692450754 0.7494168197919056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 0.9687538348348053 0.7501600102099769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 0.9693658864365093 0.752736914836878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 0.9697956546741612 0.7549216407632194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 0.9695925181869791 0.7654630444207696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 0.9718845064061864 0.7727255222504587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 0.9741018390278512 0.7738189030303059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 0.9742980372170341 0.7747677734124191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 0.9739961497150093 0.7765409038389047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 0.9725266211168878 0.777401009034292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 0.9689597093633676 0.7774683454351852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 0.9717726231514053 0.7775054266938561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 0.9725176300547373 0.7775054266938561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 0.9714035662195181 0.7775054266938561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 0.9702766556213719 0.7775054266938561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 0.9715440771867102 0.7775054266938561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 0.9683467644562588 0.7775054266938561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 0.9706460548685334 0.7775054266938561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 0.9681685808327529 0.7775054266938561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 0.9695026144075483 0.7775054266938561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 0.9703031907696933 0.7775054266938561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 0.9724900936936636 0.7775054266938561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 0.9747898027727689 0.7775054266938561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 0.9768468976582427 0.7775171361880893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 0.9782120858524245 0.7775181119711113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 0.9773501719383024 0.7775073782887892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 0.9773687409672777 0.7775054266938561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 0.9780122063378832 0.7775054266938561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 0.9788907502706965 0.7775054266938561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 0.9769546289210632 0.7775054266938561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 0.976445800290025 0.7775054266938561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 0.9743532667851934 0.7775054266938561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 0.9743685435186041 0.7775054266938561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54 0.9719736663671077 0.7775054266938561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 0.9747553261875501 0.7775054266938561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 0.9733865492120929 0.7775054266938561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57 0.9744996507128825 0.7775054266938561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58 0.9757091236667284 0.7775054266938561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59 0.9769546289210632 0.7775054266938561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 0.9779122441803968 0.7775054266938561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 0.9766538634225496 0.7775054266938561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62 0.9761021102445776 0.7775054266938561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 0.9734979664552289 0.7775054266938561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 0.9751228531629312 0.7775054266938561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 0.9745697825577716 0.7775054266938561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 0.9729579967346269 0.7775054266938561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 0.9752413334492237 0.7775054266938561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68 0.9743281288952848 0.7775054266938561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69 0.9739406906808172 0.7774985960720185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70 0.9715562063947321 0.7774517558634058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 0.9735305374804 0.7774156478918727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72 0.9762024631539127 0.7774995718789073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 0.9772302150126495 0.7775054266938561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 0.9780371945353202 0.7775054266938561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 0.9788494187017416 0.7775054266938561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76 0.9772120825590191 0.7774995718789073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77 0.9756074828886105 0.7774156478918727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78 0.9740515404176754 0.7773844179866167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79 0.9730194496391673 0.7774156478918727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 0.9733613487897859 0.7775034750938983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81 0.9727219112538307 0.7775054266938561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82 0.9759508849660489 0.7775054266938561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83 0.9765612467753269 0.7775054266938561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 0.9770619491182916 0.7775054266938561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85 0.9758928391761066 0.7775034750938983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86 0.9738295289726993 0.7774985960720185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87 0.9712024360611422 0.7775054266938561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88 0.9740162159853947 0.7775054266938561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89 0.9738295289726993 0.7775054266938561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 0.9749278832057076 0.7775054266938561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91 0.9770475932685397 0.7775054266938561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92 0.9766050936459262 0.7775366516099428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93 0.9749971983294092 0.7775249424171029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94 0.9735629224197995 0.7775317728015648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 0.9715577685117386 0.7775425061385682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96 0.9740059204913785 0.7775434818889455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97 0.9757169511833703 0.7775971462273387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98 0.9745045629423869 0.7776049516332166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 0.975600113834573 0.7777106056525414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 0.9749834064196063 0.7778195688976508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 0.6727000480541515 0.7843080990453517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102 0.7242540861248148 0.7922869683027197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103 0.7309671264184573 0.7922869683027197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104 0.7300828659161877 0.7922869683027197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 0.7306745230999474 0.7922869683027197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 0.730906004633172 0.7922869683027197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107 0.7320933372452925 0.7922869683027197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108 0.731673987299943 0.7922869683027197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109 0.7324322511196792 0.7922869683027197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110 0.7324640576652617 0.7922869683027197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111 0.7324690748505263 0.7922869683027197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112 0.7324714786787285 0.7922869683027197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113 0.732492025081061 0.7922869683027197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114 0.7324924920338313 0.7922869683027197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115 0.7324899516647153 0.7922869683027197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116 0.7325031637468801 0.7922869683027197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117 0.7324796777395275 0.7922869683027197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118 0.7318957078489989 0.7922869683027197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119 0.7326664312743966 0.7922869683027197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 0.7325201088912768 0.7922869683027197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121 0.7325023658930238 0.7922869683027197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122 0.7324883685315671 0.7922869683027197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123 0.7321187637841315 0.7922869683027197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124 0.7325495233706173 0.7922869683027197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125 0.7325499902515851 0.7922869683027197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126 0.7325499902515851 0.7922869683027197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127 0.7325499902515851 0.7922869683027197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 0.7325499902515851 0.7922869683027197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129 0.7325499902515851 0.7922869683027197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 0.7325499902515851 0.7922869683027197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131 0.7325499902515851 0.7922869683027197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132 0.7325499902515851 0.7922869683027197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133 0.7325499902515851 0.7922869683027197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134 0.7325499902515851 0.7922869683027197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135 0.7325499902515851 0.7922869683027197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136 0.7325499902515851 0.7922869683027197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137 0.7325499902515851 0.7922869683027197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138 0.7325499902515851 0.7922869683027197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139 0.7325499902515851 0.7922869683027197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140 0.7325499902515851 0.7922869683027197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141 0.7325499902515851 0.7922869683027197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142 0.7325499902515851 0.7922869683027197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n",
      "/scratch/ipykernel_116240/1767626643.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_prob=F.softmax(y_out).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143 0.7325499902515851 0.7922869683027197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_116240/1767626643.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  Y_Pred.append(F.softmax(y_out).argmax(1).detach().cpu().numpy().flatten())\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y, y_pred\u001b[38;5;241m=\u001b[39m \u001b[43mfit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/users/Sophie_Chen/graph_dataset/graph_dataset.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                    \u001b[49m\u001b[43muse_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mout_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/users/Sophie_Chen/gnn/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mgpu_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mburnin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36mfit_model\u001b[0;34m(graph_data, use_weights, use_model, n_batches_backward, f1_metric, n_epochs, out_dir, lr, eta_min, T_max, wd, hidden_topology, p, p2, burnin, warmup, gpu_id, batch_size)\u001b[0m\n\u001b[1;32m    106\u001b[0m edge_index\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39medge_index\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m    107\u001b[0m y\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m--> 108\u001b[0m y_out\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(y_out, y) \u001b[38;5;241m/\u001b[39m n_batches_backward\n\u001b[1;32m    110\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/envs/hiss/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36mGCNNet.forward\u001b[0;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m conv \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvs:\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_each \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining: edge_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_edge(edge_index)\n\u001b[0;32m---> 16\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m     18\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/hiss/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/hiss/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py:243\u001b[0m, in \u001b[0;36mGATConv.forward\u001b[0;34m(self, x, edge_index, edge_attr, size, return_attention_weights)\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    238\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe usage of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_attr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madd_self_loops\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    239\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimultaneously is currently not yet supported for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    240\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in a \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSparseTensor\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m form\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    242\u001b[0m \u001b[38;5;66;03m# edge_updater_type: (alpha: OptPairTensor, edge_attr: OptTensor)\u001b[39;00m\n\u001b[0;32m--> 243\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_updater\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: OptPairTensor, alpha: Tensor)\u001b[39;00m\n\u001b[1;32m    246\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpropagate(edge_index, x\u001b[38;5;241m=\u001b[39mx, alpha\u001b[38;5;241m=\u001b[39malpha, size\u001b[38;5;241m=\u001b[39msize)\n",
      "File \u001b[0;32m~/anaconda3/envs/hiss/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py:437\u001b[0m, in \u001b[0;36mMessagePassing.edge_updater\u001b[0;34m(self, edge_index, **kwargs)\u001b[0m\n\u001b[1;32m    433\u001b[0m coll_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__collect__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__edge_user_args__, edge_index, size,\n\u001b[1;32m    434\u001b[0m                              kwargs)\n\u001b[1;32m    436\u001b[0m edge_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minspector\u001b[38;5;241m.\u001b[39mdistribute(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_update\u001b[39m\u001b[38;5;124m'\u001b[39m, coll_dict)\n\u001b[0;32m--> 437\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_update\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43medge_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_edge_update_forward_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m    440\u001b[0m     res \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, (edge_index, kwargs), out)\n",
      "File \u001b[0;32m~/anaconda3/envs/hiss/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py:280\u001b[0m, in \u001b[0;36mGATConv.edge_update\u001b[0;34m(self, alpha_j, alpha_i, edge_attr, index, ptr, size_i)\u001b[0m\n\u001b[1;32m    277\u001b[0m     alpha \u001b[38;5;241m=\u001b[39m alpha \u001b[38;5;241m+\u001b[39m alpha_edge\n\u001b[1;32m    279\u001b[0m alpha \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mleaky_relu(alpha, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnegative_slope)\n\u001b[0;32m--> 280\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize_i\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m alpha \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(alpha, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m alpha\n",
      "File \u001b[0;32m~/anaconda3/envs/hiss/lib/python3.8/site-packages/torch_geometric/utils/softmax.py:51\u001b[0m, in \u001b[0;36msoftmax\u001b[0;34m(src, index, ptr, num_nodes, dim)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_sum\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-16\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "y, y_pred= fit_model(\"/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/users/Sophie_Chen/graph_dataset/graph_dataset.pkl\",\n",
    "                    use_weights=True,\n",
    "                    lr=1e-4,\n",
    "                    out_dir='/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/users/Sophie_Chen/gnn/',\n",
    "                    n_epochs=1500,\n",
    "                    gpu_id=0,\n",
    "                    burnin=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f6abdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hiss",
   "language": "python",
   "name": "hiss"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
