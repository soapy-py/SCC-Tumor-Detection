{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8956b385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch \n",
    "from tqdm import tqdm \n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob, os, pickle\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torch_geometric.data import Data, Dataset\n",
    "import dgl\n",
    "from torch_geometric.utils import dropout_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6ecc5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F \n",
    "from torch.nn import Linear, BatchNorm1d, ModuleList\n",
    "from torch_geometric.nn import TransformerConv, TopKPooling, GATConv, SAGEConv\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf50a1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Dec 29 01:34:23 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:18:00.0 Off |                    0 |\n",
      "| N/A   36C    P0    52W / 300W |      0MiB / 32768MiB |      0%   E. Process |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  Off  | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    54W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  Off  | 00000000:86:00.0 Off |                    0 |\n",
      "| N/A   30C    P0    53W / 300W |      0MiB / 32768MiB |      0%   E. Process |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  Off  | 00000000:AF:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    53W / 300W |      0MiB / 32768MiB |      2%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "336bf912",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bbd19dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda76be4",
   "metadata": {},
   "source": [
    "# Need to define the data class \n",
    "- Here focus mainly on the get() method. We don't need to process anything\n",
    "- We also return masks for each graph, that will help with training \n",
    "- Actually, no masks. Inductive training.\n",
    "- We are no longer using this data class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61c0402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class WSI_Graph_Class(Dataset):\n",
    "    \n",
    "#     def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n",
    "#         super().__init__(None, transform, pre_transform)\n",
    "#         self.root_dir = root\n",
    "#         self.WSI_df = pd.read_csv(root) #get the WSI metadata\n",
    "#         self.masks = {} #map node num -> train/val/test masks\n",
    "#         self.create_all_masks()\n",
    "        \n",
    "#     def create_all_masks(self):\n",
    "        \n",
    "#         for idx in tqdm(range(len(self.WSI_df[\"sample_id\"]))):\n",
    "#             path = self.WSI_df[\"path\"].iloc[idx]\n",
    "            \n",
    "#             #this is the graph. We also need to return the training/validation/testing masks \n",
    "#             data = torch.load(path)\n",
    "#             nodes = [i for i in range(data.x.shape[0])] #node 0 is in 0th pos, 1 in 1, and so on \n",
    "            \n",
    "#             #all of the masks \n",
    "#             train_mask = [False] * len(nodes)\n",
    "#             val_mask = [False] * len(nodes)\n",
    "#             test_mask = [False] * len(nodes)\n",
    "#             self.create_mask(nodes, train_mask, val_mask, test_mask)\n",
    "#             #now add them to dictionary\n",
    "#             self.masks[idx] = [train_mask, val_mask, test_mask]\n",
    "        \n",
    "        \n",
    "#     def create_mask(self, nodes, train_mask, val_mask, test_mask):        \n",
    "#         #create train/test/val nodes (75/25)\n",
    "#         train, test = train_test_split(nodes)\n",
    "#         test, val = train_test_split(test)\n",
    "        \n",
    "#         #now create masks\n",
    "#         for i in range(len(nodes)):\n",
    "#             if i in train: \n",
    "#                 train_mask[i] = True \n",
    "                \n",
    "#         for i in range(len(nodes)):\n",
    "#             if nodes[i] in val: \n",
    "#                 val_mask[i] = True \n",
    "                \n",
    "#         for i in range(len(nodes)):\n",
    "#             if nodes[i] in test: \n",
    "#                 test_mask[i] = True \n",
    "                \n",
    "#     #just pass here, we aren't going to return any raw file names\n",
    "#     def raw_file_names(self):\n",
    "#         pass \n",
    "#     #here we can return each of the WSI \n",
    "#     def processed_file_names(self):\n",
    "#         return list(self.WSI_df[\"sample_id\"])\n",
    "    \n",
    "#     def len(self):\n",
    "#         return len(self.processed_file_names())\n",
    "    \n",
    "#     #return the graph class for that idx \n",
    "#     def get(self, idx):\n",
    "#         path = self.WSI_df[\"path\"].iloc[idx]\n",
    "#         #this is the graph. We also need to return the training/validation/testing masks \n",
    "#         data = torch.load(path)\n",
    "#         masks = self.masks[idx]\n",
    "#         train_mask = masks[0]\n",
    "#         val_mask = masks[1]\n",
    "#         test_mask = masks[2]\n",
    "#         return (data, torch.tensor(train_mask), torch.tensor(val_mask), torch.tensor(test_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34847690",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [01:02<00:00,  2.08s/it]\n"
     ]
    }
   ],
   "source": [
    "# root = \"/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/users/Gokul_Srinivasan/SCC-Tumor-Detection/Gokul_files/graph_data/metadata.csv\"\n",
    "\n",
    "# dataset = WSI_Graph_Class(root = root, transform = None, pre_transform = None, pre_filter = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45858761",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset.get(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3fe586b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, testing_data = train_test_split(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4a59aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, val_data = train_test_split(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ff628d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8821af01",
   "metadata": {},
   "source": [
    "# Data Sanity Check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6da44cbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(x=[14807, 2048], edge_index=[2, 113718], y=[14807]),\n",
       " tensor([ True, False,  True,  ..., False, False,  True]),\n",
       " tensor([False, False, False,  ..., False,  True, False]),\n",
       " tensor([False,  True, False,  ...,  True, False, False]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3fbb0a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3422)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(data[0].y == 1)/sum(data[0].y == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1bb895f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b51a2a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3273, 0.3910, 0.2434,  ..., 0.1320, 0.3427, 0.1643],\n",
       "        [0.3633, 0.4324, 0.2210,  ..., 0.1202, 0.3847, 0.1370],\n",
       "        [0.3143, 0.3583, 0.1967,  ..., 0.1235, 0.3223, 0.1408],\n",
       "        ...,\n",
       "        [0.3529, 0.3735, 0.1997,  ..., 0.1163, 0.3923, 0.1283],\n",
       "        [0.3563, 0.4631, 0.2405,  ..., 0.1372, 0.4183, 0.1589],\n",
       "        [0.3672, 0.4138, 0.1967,  ..., 0.1255, 0.4014, 0.1501]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d1e8966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3775)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(graph.y == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02a97f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_mask = data[2]\n",
    "train_mask = data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6746b272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2848)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(graph.y[train_mask] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7319a3e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8257)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(graph.y[train_mask] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76167319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.3273),\n",
       " tensor(0.3910),\n",
       " tensor(0.2434),\n",
       " tensor(0.2740),\n",
       " tensor(0.3770),\n",
       " tensor(0.1986),\n",
       " tensor(0.2894),\n",
       " tensor(0.2798),\n",
       " tensor(0.2180),\n",
       " tensor(0.2774),\n",
       " tensor(0.2228),\n",
       " tensor(0.2582),\n",
       " tensor(0.2934),\n",
       " tensor(0.2616),\n",
       " tensor(0.2318),\n",
       " tensor(0.2059),\n",
       " tensor(0.2734),\n",
       " tensor(0.1345),\n",
       " tensor(0.1636),\n",
       " tensor(0.2380),\n",
       " tensor(0.2302),\n",
       " tensor(0.1834),\n",
       " tensor(0.3113),\n",
       " tensor(0.2886),\n",
       " tensor(0.2514),\n",
       " tensor(0.3097),\n",
       " tensor(0.2254),\n",
       " tensor(0.2886),\n",
       " tensor(0.3816),\n",
       " tensor(0.1610),\n",
       " tensor(0.1412),\n",
       " tensor(0.1973),\n",
       " tensor(0.1213),\n",
       " tensor(0.2101),\n",
       " tensor(0.3877),\n",
       " tensor(0.1789),\n",
       " tensor(0.3065),\n",
       " tensor(0.2127),\n",
       " tensor(0.2804),\n",
       " tensor(0.2757),\n",
       " tensor(0.2536),\n",
       " tensor(0.4117),\n",
       " tensor(0.2085),\n",
       " tensor(0.2539),\n",
       " tensor(0.3148),\n",
       " tensor(0.3571),\n",
       " tensor(0.1836),\n",
       " tensor(0.3520),\n",
       " tensor(0.1677),\n",
       " tensor(0.1936),\n",
       " tensor(0.2729),\n",
       " tensor(0.1984),\n",
       " tensor(0.3282),\n",
       " tensor(0.2191),\n",
       " tensor(0.3683),\n",
       " tensor(0.3351),\n",
       " tensor(0.2762),\n",
       " tensor(0.1524),\n",
       " tensor(0.4025),\n",
       " tensor(0.2192),\n",
       " tensor(0.2530),\n",
       " tensor(0.3256),\n",
       " tensor(0.4555),\n",
       " tensor(0.3200),\n",
       " tensor(0.0932),\n",
       " tensor(0.7171),\n",
       " tensor(0.2958),\n",
       " tensor(0.2278),\n",
       " tensor(0.2305),\n",
       " tensor(0.2367),\n",
       " tensor(0.1748),\n",
       " tensor(0.1469),\n",
       " tensor(0.3821),\n",
       " tensor(0.3457),\n",
       " tensor(0.3750),\n",
       " tensor(0.2272),\n",
       " tensor(0.2334),\n",
       " tensor(0.2105),\n",
       " tensor(0.1619),\n",
       " tensor(0.3365),\n",
       " tensor(0.2878),\n",
       " tensor(0.2675),\n",
       " tensor(0.4504),\n",
       " tensor(0.2532),\n",
       " tensor(0.1979),\n",
       " tensor(0.3086),\n",
       " tensor(0.2062),\n",
       " tensor(0.2158),\n",
       " tensor(0.5469),\n",
       " tensor(0.2451),\n",
       " tensor(0.2377),\n",
       " tensor(0.2028),\n",
       " tensor(0.1602),\n",
       " tensor(0.1894),\n",
       " tensor(0.1260),\n",
       " tensor(0.4325),\n",
       " tensor(0.2113),\n",
       " tensor(0.1640),\n",
       " tensor(0.1742),\n",
       " tensor(0.2188),\n",
       " tensor(0.2867),\n",
       " tensor(0.3470),\n",
       " tensor(0.2760),\n",
       " tensor(0.2958),\n",
       " tensor(0.2714),\n",
       " tensor(0.2494),\n",
       " tensor(0.1504),\n",
       " tensor(0.0958),\n",
       " tensor(0.3887),\n",
       " tensor(0.1629),\n",
       " tensor(0.3681),\n",
       " tensor(0.3370),\n",
       " tensor(0.1792),\n",
       " tensor(0.3364),\n",
       " tensor(0.2998),\n",
       " tensor(0.2097),\n",
       " tensor(0.1199),\n",
       " tensor(0.1660),\n",
       " tensor(0.1678),\n",
       " tensor(0.3896),\n",
       " tensor(0.3943),\n",
       " tensor(0.1493),\n",
       " tensor(0.3261),\n",
       " tensor(0.3729),\n",
       " tensor(0.2572),\n",
       " tensor(0.2610),\n",
       " tensor(0.1415),\n",
       " tensor(0.2401),\n",
       " tensor(0.1379),\n",
       " tensor(0.4360),\n",
       " tensor(0.1053),\n",
       " tensor(0.1900),\n",
       " tensor(0.1661),\n",
       " tensor(0.1443),\n",
       " tensor(0.3521),\n",
       " tensor(0.4479),\n",
       " tensor(0.3198),\n",
       " tensor(0.2263),\n",
       " tensor(0.2551),\n",
       " tensor(0.4092),\n",
       " tensor(0.2935),\n",
       " tensor(0.1355),\n",
       " tensor(0.1793),\n",
       " tensor(0.2718),\n",
       " tensor(0.2278),\n",
       " tensor(0.2321),\n",
       " tensor(0.1213),\n",
       " tensor(0.2157),\n",
       " tensor(0.3173),\n",
       " tensor(0.6109),\n",
       " tensor(0.3617),\n",
       " tensor(0.2105),\n",
       " tensor(0.2348),\n",
       " tensor(0.2837),\n",
       " tensor(0.3081),\n",
       " tensor(0.3812),\n",
       " tensor(0.1356),\n",
       " tensor(0.2096),\n",
       " tensor(0.2766),\n",
       " tensor(0.3198),\n",
       " tensor(0.1800),\n",
       " tensor(0.2227),\n",
       " tensor(0.1589),\n",
       " tensor(0.4447),\n",
       " tensor(0.2157),\n",
       " tensor(0.2781),\n",
       " tensor(0.3046),\n",
       " tensor(0.4184),\n",
       " tensor(0.2674),\n",
       " tensor(0.1064),\n",
       " tensor(0.2558),\n",
       " tensor(0.3710),\n",
       " tensor(0.1788),\n",
       " tensor(0.3709),\n",
       " tensor(0.1921),\n",
       " tensor(0.3299),\n",
       " tensor(0.2167),\n",
       " tensor(0.1751),\n",
       " tensor(0.2840),\n",
       " tensor(0.3128),\n",
       " tensor(0.2306),\n",
       " tensor(0.3264),\n",
       " tensor(0.4592),\n",
       " tensor(0.1267),\n",
       " tensor(0.1790),\n",
       " tensor(0.2698),\n",
       " tensor(0.1070),\n",
       " tensor(0.2191),\n",
       " tensor(0.3505),\n",
       " tensor(0.4041),\n",
       " tensor(0.2407),\n",
       " tensor(0.1964),\n",
       " tensor(0.2029),\n",
       " tensor(0.2087),\n",
       " tensor(0.3174),\n",
       " tensor(0.3459),\n",
       " tensor(0.1691),\n",
       " tensor(0.1022),\n",
       " tensor(0.3544),\n",
       " tensor(0.1437),\n",
       " tensor(0.3711),\n",
       " tensor(0.2982),\n",
       " tensor(0.1357),\n",
       " tensor(0.3322),\n",
       " tensor(0.2333),\n",
       " tensor(0.4134),\n",
       " tensor(0.1971),\n",
       " tensor(0.3041),\n",
       " tensor(0.2427),\n",
       " tensor(0.3167),\n",
       " tensor(0.2456),\n",
       " tensor(0.1500),\n",
       " tensor(0.2837),\n",
       " tensor(0.3291),\n",
       " tensor(0.3364),\n",
       " tensor(0.2023),\n",
       " tensor(0.2564),\n",
       " tensor(0.1958),\n",
       " tensor(0.3108),\n",
       " tensor(0.2685),\n",
       " tensor(0.1784),\n",
       " tensor(0.2135),\n",
       " tensor(0.2533),\n",
       " tensor(0.3854),\n",
       " tensor(0.1797),\n",
       " tensor(0.2630),\n",
       " tensor(0.3202),\n",
       " tensor(0.3469),\n",
       " tensor(0.2304),\n",
       " tensor(0.1831),\n",
       " tensor(0.2955),\n",
       " tensor(0.3662),\n",
       " tensor(0.2986),\n",
       " tensor(0.1341),\n",
       " tensor(0.1281),\n",
       " tensor(0.1460),\n",
       " tensor(0.3815),\n",
       " tensor(0.2405),\n",
       " tensor(0.2738),\n",
       " tensor(0.3198),\n",
       " tensor(0.2571),\n",
       " tensor(0.2598),\n",
       " tensor(0.2335),\n",
       " tensor(0.3745),\n",
       " tensor(0.2416),\n",
       " tensor(0.3252),\n",
       " tensor(0.3167),\n",
       " tensor(0.3251),\n",
       " tensor(0.2549),\n",
       " tensor(0.1878),\n",
       " tensor(0.3575),\n",
       " tensor(0.2688),\n",
       " tensor(0.3548),\n",
       " tensor(0.1992),\n",
       " tensor(0.1783),\n",
       " tensor(0.2071),\n",
       " tensor(0.2819),\n",
       " tensor(0.3119),\n",
       " tensor(0.2963),\n",
       " tensor(0.1110),\n",
       " tensor(0.3686),\n",
       " tensor(0.2922),\n",
       " tensor(0.2111),\n",
       " tensor(0.0828),\n",
       " tensor(0.4621),\n",
       " tensor(0.2011),\n",
       " tensor(0.3009),\n",
       " tensor(0.4751),\n",
       " tensor(0.3010),\n",
       " tensor(0.3923),\n",
       " tensor(0.1570),\n",
       " tensor(0.2957),\n",
       " tensor(0.3037),\n",
       " tensor(0.1313),\n",
       " tensor(0.3556),\n",
       " tensor(0.1511),\n",
       " tensor(0.4402),\n",
       " tensor(0.2325),\n",
       " tensor(0.4440),\n",
       " tensor(0.5724),\n",
       " tensor(0.2025),\n",
       " tensor(0.1913),\n",
       " tensor(0.2392),\n",
       " tensor(0.1000),\n",
       " tensor(0.1478),\n",
       " tensor(0.2420),\n",
       " tensor(0.2012),\n",
       " tensor(0.2303),\n",
       " tensor(0.3026),\n",
       " tensor(0.3728),\n",
       " tensor(0.2083),\n",
       " tensor(0.2745),\n",
       " tensor(0.2023),\n",
       " tensor(0.3505),\n",
       " tensor(0.2123),\n",
       " tensor(0.3115),\n",
       " tensor(0.3421),\n",
       " tensor(0.2622),\n",
       " tensor(0.0991),\n",
       " tensor(0.1256),\n",
       " tensor(0.4118),\n",
       " tensor(0.3139),\n",
       " tensor(0.3342),\n",
       " tensor(0.2934),\n",
       " tensor(0.2115),\n",
       " tensor(0.3691),\n",
       " tensor(0.3514),\n",
       " tensor(0.1923),\n",
       " tensor(0.3726),\n",
       " tensor(0.1990),\n",
       " tensor(0.1593),\n",
       " tensor(0.3346),\n",
       " tensor(0.1554),\n",
       " tensor(0.5058),\n",
       " tensor(0.2142),\n",
       " tensor(0.1717),\n",
       " tensor(0.2796),\n",
       " tensor(0.2956),\n",
       " tensor(0.3347),\n",
       " tensor(0.3140),\n",
       " tensor(0.2069),\n",
       " tensor(0.2106),\n",
       " tensor(0.3190),\n",
       " tensor(0.1418),\n",
       " tensor(0.2579),\n",
       " tensor(0.1451),\n",
       " tensor(0.1283),\n",
       " tensor(0.3875),\n",
       " tensor(0.3195),\n",
       " tensor(0.3380),\n",
       " tensor(0.2050),\n",
       " tensor(0.4696),\n",
       " tensor(0.2777),\n",
       " tensor(0.2483),\n",
       " tensor(0.2336),\n",
       " tensor(0.3117),\n",
       " tensor(0.2390),\n",
       " tensor(0.1587),\n",
       " tensor(0.2240),\n",
       " tensor(0.2865),\n",
       " tensor(0.1984),\n",
       " tensor(0.2697),\n",
       " tensor(0.1687),\n",
       " tensor(0.3251),\n",
       " tensor(0.2487),\n",
       " tensor(0.2978),\n",
       " tensor(0.4451),\n",
       " tensor(0.1078),\n",
       " tensor(0.2749),\n",
       " tensor(0.3147),\n",
       " tensor(0.2729),\n",
       " tensor(0.1161),\n",
       " tensor(0.2518),\n",
       " tensor(0.1996),\n",
       " tensor(0.2710),\n",
       " tensor(0.4010),\n",
       " tensor(0.3189),\n",
       " tensor(0.0989),\n",
       " tensor(0.2640),\n",
       " tensor(0.3447),\n",
       " tensor(0.1671),\n",
       " tensor(0.1752),\n",
       " tensor(0.1957),\n",
       " tensor(0.2630),\n",
       " tensor(0.3538),\n",
       " tensor(0.2602),\n",
       " tensor(0.2968),\n",
       " tensor(0.2894),\n",
       " tensor(0.1903),\n",
       " tensor(0.2374),\n",
       " tensor(0.3854),\n",
       " tensor(0.2296),\n",
       " tensor(0.2627),\n",
       " tensor(0.3403),\n",
       " tensor(0.4025),\n",
       " tensor(0.2371),\n",
       " tensor(0.1943),\n",
       " tensor(0.3130),\n",
       " tensor(0.2484),\n",
       " tensor(0.3482),\n",
       " tensor(0.4356),\n",
       " tensor(0.2508),\n",
       " tensor(0.1764),\n",
       " tensor(0.2082),\n",
       " tensor(0.1387),\n",
       " tensor(0.2052),\n",
       " tensor(0.3208),\n",
       " tensor(0.1213),\n",
       " tensor(0.9368),\n",
       " tensor(0.5649),\n",
       " tensor(0.3274),\n",
       " tensor(0.3064),\n",
       " tensor(0.2300),\n",
       " tensor(0.3573),\n",
       " tensor(0.3631),\n",
       " tensor(0.1974),\n",
       " tensor(0.3275),\n",
       " tensor(0.1869),\n",
       " tensor(0.1329),\n",
       " tensor(0.2340),\n",
       " tensor(0.1526),\n",
       " tensor(0.2847),\n",
       " tensor(0.2313),\n",
       " tensor(0.1774),\n",
       " tensor(0.1603),\n",
       " tensor(0.3232),\n",
       " tensor(0.1399),\n",
       " tensor(0.1090),\n",
       " tensor(0.1751),\n",
       " tensor(0.3474),\n",
       " tensor(0.2461),\n",
       " tensor(0.3612),\n",
       " tensor(0.1716),\n",
       " tensor(0.2980),\n",
       " tensor(0.3933),\n",
       " tensor(0.1353),\n",
       " tensor(0.3196),\n",
       " tensor(0.4597),\n",
       " tensor(0.2620),\n",
       " tensor(0.4086),\n",
       " tensor(0.2664),\n",
       " tensor(0.2353),\n",
       " tensor(0.2353),\n",
       " tensor(0.1312),\n",
       " tensor(0.3257),\n",
       " tensor(0.1363),\n",
       " tensor(0.2342),\n",
       " tensor(0.3071),\n",
       " tensor(0.2166),\n",
       " tensor(0.2017),\n",
       " tensor(0.3568),\n",
       " tensor(0.6127),\n",
       " tensor(0.2743),\n",
       " tensor(0.2129),\n",
       " tensor(0.3028),\n",
       " tensor(0.1795),\n",
       " tensor(0.0734),\n",
       " tensor(0.1608),\n",
       " tensor(0.2825),\n",
       " tensor(0.1135),\n",
       " tensor(0.1868),\n",
       " tensor(0.2729),\n",
       " tensor(0.2473),\n",
       " tensor(0.1970),\n",
       " tensor(0.3178),\n",
       " tensor(0.2154),\n",
       " tensor(0.2447),\n",
       " tensor(0.2268),\n",
       " tensor(0.2515),\n",
       " tensor(0.2936),\n",
       " tensor(0.2871),\n",
       " tensor(0.5409),\n",
       " tensor(0.1430),\n",
       " tensor(0.2051),\n",
       " tensor(0.1999),\n",
       " tensor(0.1666),\n",
       " tensor(0.2272),\n",
       " tensor(0.2759),\n",
       " tensor(0.2799),\n",
       " tensor(0.1818),\n",
       " tensor(0.3598),\n",
       " tensor(0.1592),\n",
       " tensor(0.3388),\n",
       " tensor(0.2916),\n",
       " tensor(0.3167),\n",
       " tensor(0.2343),\n",
       " tensor(0.5001),\n",
       " tensor(0.2170),\n",
       " tensor(0.2161),\n",
       " tensor(0.1182),\n",
       " tensor(0.3128),\n",
       " tensor(0.1600),\n",
       " tensor(0.3729),\n",
       " tensor(0.3985),\n",
       " tensor(0.1536),\n",
       " tensor(0.3418),\n",
       " tensor(0.5546),\n",
       " tensor(0.1929),\n",
       " tensor(0.1895),\n",
       " tensor(0.2930),\n",
       " tensor(0.1538),\n",
       " tensor(0.2124),\n",
       " tensor(0.1039),\n",
       " tensor(0.2362),\n",
       " tensor(0.2706),\n",
       " tensor(0.2118),\n",
       " tensor(0.2268),\n",
       " tensor(0.2876),\n",
       " tensor(0.1747),\n",
       " tensor(0.2428),\n",
       " tensor(0.3528),\n",
       " tensor(0.1321),\n",
       " tensor(0.2512),\n",
       " tensor(0.1382),\n",
       " tensor(0.2667),\n",
       " tensor(0.2605),\n",
       " tensor(0.4242),\n",
       " tensor(0.1406),\n",
       " tensor(0.3069),\n",
       " tensor(0.2351),\n",
       " tensor(0.1687),\n",
       " tensor(0.2319),\n",
       " tensor(0.1618),\n",
       " tensor(0.2356),\n",
       " tensor(0.1309),\n",
       " tensor(0.3748),\n",
       " tensor(0.3080),\n",
       " tensor(0.1416),\n",
       " tensor(0.2848),\n",
       " tensor(0.2122),\n",
       " tensor(0.1602),\n",
       " tensor(0.3116),\n",
       " tensor(0.3197),\n",
       " tensor(0.1411),\n",
       " tensor(0.3898),\n",
       " tensor(0.2962),\n",
       " tensor(0.4119),\n",
       " tensor(0.3681),\n",
       " tensor(0.3445),\n",
       " tensor(0.2489),\n",
       " tensor(0.3491),\n",
       " tensor(0.2193),\n",
       " tensor(0.3344),\n",
       " tensor(0.3132),\n",
       " tensor(0.2630),\n",
       " tensor(0.1987),\n",
       " tensor(0.3530),\n",
       " tensor(0.0931),\n",
       " tensor(0.2836),\n",
       " tensor(0.1762),\n",
       " tensor(0.2165),\n",
       " tensor(0.3077),\n",
       " tensor(0.2954),\n",
       " tensor(0.3143),\n",
       " tensor(0.3480),\n",
       " tensor(0.1881),\n",
       " tensor(0.2326),\n",
       " tensor(0.1437),\n",
       " tensor(0.1929),\n",
       " tensor(0.3215),\n",
       " tensor(0.2382),\n",
       " tensor(0.1460),\n",
       " tensor(0.2634),\n",
       " tensor(0.1851),\n",
       " tensor(0.3773),\n",
       " tensor(0.2756),\n",
       " tensor(0.1890),\n",
       " tensor(0.2544),\n",
       " tensor(0.2629),\n",
       " tensor(0.2930),\n",
       " tensor(0.1854),\n",
       " tensor(0.2867),\n",
       " tensor(0.3306),\n",
       " tensor(0.2861),\n",
       " tensor(0.0986),\n",
       " tensor(0.2606),\n",
       " tensor(0.4356),\n",
       " tensor(0.3265),\n",
       " tensor(0.2753),\n",
       " tensor(0.2607),\n",
       " tensor(0.2536),\n",
       " tensor(0.2778),\n",
       " tensor(0.2284),\n",
       " tensor(0.2470),\n",
       " tensor(0.6350),\n",
       " tensor(0.2986),\n",
       " tensor(0.3245),\n",
       " tensor(0.2319),\n",
       " tensor(0.4224),\n",
       " tensor(0.2049),\n",
       " tensor(0.3869),\n",
       " tensor(0.3318),\n",
       " tensor(0.3382),\n",
       " tensor(0.1750),\n",
       " tensor(0.3637),\n",
       " tensor(0.4837),\n",
       " tensor(0.2752),\n",
       " tensor(0.1545),\n",
       " tensor(0.2248),\n",
       " tensor(0.3205),\n",
       " tensor(0.4679),\n",
       " tensor(0.2596),\n",
       " tensor(0.1068),\n",
       " tensor(0.2751),\n",
       " tensor(0.1767),\n",
       " tensor(0.2041),\n",
       " tensor(0.3316),\n",
       " tensor(0.2383),\n",
       " tensor(0.1958),\n",
       " tensor(0.4311),\n",
       " tensor(0.2788),\n",
       " tensor(0.3312),\n",
       " tensor(0.2058),\n",
       " tensor(0.3429),\n",
       " tensor(0.2967),\n",
       " tensor(0.2688),\n",
       " tensor(0.1535),\n",
       " tensor(0.2658),\n",
       " tensor(0.2612),\n",
       " tensor(0.4289),\n",
       " tensor(0.3495),\n",
       " tensor(0.0817),\n",
       " tensor(0.1686),\n",
       " tensor(0.2705),\n",
       " tensor(0.2066),\n",
       " tensor(0.3691),\n",
       " tensor(0.3267),\n",
       " tensor(0.3072),\n",
       " tensor(0.1119),\n",
       " tensor(0.1556),\n",
       " tensor(0.1858),\n",
       " tensor(0.2446),\n",
       " tensor(0.4952),\n",
       " tensor(0.1709),\n",
       " tensor(0.2788),\n",
       " tensor(0.1878),\n",
       " tensor(0.2903),\n",
       " tensor(0.9482),\n",
       " tensor(0.1072),\n",
       " tensor(0.2213),\n",
       " tensor(0.2222),\n",
       " tensor(0.3871),\n",
       " tensor(0.1016),\n",
       " tensor(0.2936),\n",
       " tensor(0.3929),\n",
       " tensor(0.1681),\n",
       " tensor(0.1890),\n",
       " tensor(0.1587),\n",
       " tensor(0.3509),\n",
       " tensor(0.2707),\n",
       " tensor(0.2066),\n",
       " tensor(0.3713),\n",
       " tensor(0.3002),\n",
       " tensor(0.3317),\n",
       " tensor(0.2367),\n",
       " tensor(0.4006),\n",
       " tensor(0.1446),\n",
       " tensor(0.2953),\n",
       " tensor(0.3756),\n",
       " tensor(0.2145),\n",
       " tensor(0.2816),\n",
       " tensor(0.1671),\n",
       " tensor(0.1612),\n",
       " tensor(0.1185),\n",
       " tensor(0.3168),\n",
       " tensor(0.1261),\n",
       " tensor(0.2871),\n",
       " tensor(0.2255),\n",
       " tensor(0.2905),\n",
       " tensor(0.1295),\n",
       " tensor(0.3206),\n",
       " tensor(0.1772),\n",
       " tensor(0.3654),\n",
       " tensor(0.3972),\n",
       " tensor(0.1125),\n",
       " tensor(0.3889),\n",
       " tensor(0.3891),\n",
       " tensor(0.2145),\n",
       " tensor(0.3528),\n",
       " tensor(0.2171),\n",
       " tensor(0.1878),\n",
       " tensor(0.3447),\n",
       " tensor(0.1496),\n",
       " tensor(0.4142),\n",
       " tensor(0.3487),\n",
       " tensor(0.3193),\n",
       " tensor(0.6742),\n",
       " tensor(0.4941),\n",
       " tensor(0.4009),\n",
       " tensor(0.3514),\n",
       " tensor(0.3581),\n",
       " tensor(0.3228),\n",
       " tensor(0.2518),\n",
       " tensor(0.2805),\n",
       " tensor(0.1549),\n",
       " tensor(0.0978),\n",
       " tensor(0.2573),\n",
       " tensor(0.2486),\n",
       " tensor(0.2903),\n",
       " tensor(0.1884),\n",
       " tensor(0.3747),\n",
       " tensor(0.2448),\n",
       " tensor(0.1879),\n",
       " tensor(0.3721),\n",
       " tensor(0.3066),\n",
       " tensor(0.2119),\n",
       " tensor(0.3509),\n",
       " tensor(0.2530),\n",
       " tensor(0.2672),\n",
       " tensor(0.3142),\n",
       " tensor(0.4026),\n",
       " tensor(0.1790),\n",
       " tensor(0.1571),\n",
       " tensor(0.1975),\n",
       " tensor(0.1273),\n",
       " tensor(0.2671),\n",
       " tensor(0.2140),\n",
       " tensor(0.1877),\n",
       " tensor(0.2224),\n",
       " tensor(0.2326),\n",
       " tensor(0.0959),\n",
       " tensor(0.2676),\n",
       " tensor(0.4239),\n",
       " tensor(0.1647),\n",
       " tensor(0.2382),\n",
       " tensor(0.3707),\n",
       " tensor(0.1898),\n",
       " tensor(0.1508),\n",
       " tensor(0.2379),\n",
       " tensor(0.1916),\n",
       " tensor(0.3032),\n",
       " tensor(0.4294),\n",
       " tensor(0.4077),\n",
       " tensor(0.3197),\n",
       " tensor(0.2562),\n",
       " tensor(0.2682),\n",
       " tensor(0.2549),\n",
       " tensor(0.2042),\n",
       " tensor(0.1079),\n",
       " tensor(0.2177),\n",
       " tensor(0.2983),\n",
       " tensor(0.3233),\n",
       " tensor(0.1093),\n",
       " tensor(0.2604),\n",
       " tensor(0.3739),\n",
       " tensor(0.3401),\n",
       " tensor(0.3042),\n",
       " tensor(0.1280),\n",
       " tensor(0.1538),\n",
       " tensor(0.3943),\n",
       " tensor(0.1800),\n",
       " tensor(0.2048),\n",
       " tensor(0.1577),\n",
       " tensor(0.2681),\n",
       " tensor(0.1807),\n",
       " tensor(0.3109),\n",
       " tensor(0.3134),\n",
       " tensor(0.2404),\n",
       " tensor(0.2416),\n",
       " tensor(0.2617),\n",
       " tensor(0.1937),\n",
       " tensor(0.1690),\n",
       " tensor(0.3273),\n",
       " tensor(0.2979),\n",
       " tensor(0.2943),\n",
       " tensor(0.2095),\n",
       " tensor(0.2155),\n",
       " tensor(0.2678),\n",
       " tensor(0.2410),\n",
       " tensor(0.1685),\n",
       " tensor(0.2639),\n",
       " tensor(0.2933),\n",
       " tensor(0.3102),\n",
       " tensor(0.4481),\n",
       " tensor(0.2651),\n",
       " tensor(0.1125),\n",
       " tensor(0.1811),\n",
       " tensor(0.1632),\n",
       " tensor(0.6691),\n",
       " tensor(0.3030),\n",
       " tensor(0.3235),\n",
       " tensor(0.3832),\n",
       " tensor(0.2399),\n",
       " tensor(0.1440),\n",
       " tensor(0.3943),\n",
       " tensor(0.3684),\n",
       " tensor(0.3927),\n",
       " tensor(0.4821),\n",
       " tensor(0.3395),\n",
       " tensor(0.2397),\n",
       " tensor(0.4394),\n",
       " tensor(0.1554),\n",
       " tensor(0.3613),\n",
       " tensor(0.2770),\n",
       " tensor(0.2962),\n",
       " tensor(0.2091),\n",
       " tensor(0.3355),\n",
       " tensor(0.1654),\n",
       " tensor(0.2026),\n",
       " tensor(0.2656),\n",
       " tensor(0.1806),\n",
       " tensor(0.2160),\n",
       " tensor(0.2193),\n",
       " tensor(0.3411),\n",
       " tensor(0.1611),\n",
       " tensor(0.1761),\n",
       " tensor(0.2432),\n",
       " tensor(0.2139),\n",
       " tensor(0.1762),\n",
       " tensor(0.0762),\n",
       " tensor(0.2709),\n",
       " tensor(0.1336),\n",
       " tensor(0.2206),\n",
       " tensor(0.2368),\n",
       " tensor(0.2401),\n",
       " tensor(0.3137),\n",
       " tensor(0.3189),\n",
       " tensor(0.2767),\n",
       " tensor(0.1894),\n",
       " tensor(0.1909),\n",
       " tensor(0.3188),\n",
       " tensor(0.2801),\n",
       " tensor(0.0725),\n",
       " tensor(0.1585),\n",
       " tensor(0.1801),\n",
       " tensor(0.2920),\n",
       " tensor(0.4491),\n",
       " tensor(0.1918),\n",
       " tensor(0.2791),\n",
       " tensor(0.2025),\n",
       " tensor(0.5277),\n",
       " tensor(0.2803),\n",
       " tensor(0.2435),\n",
       " tensor(0.2800),\n",
       " tensor(0.2629),\n",
       " tensor(0.2151),\n",
       " tensor(0.2957),\n",
       " tensor(0.1239),\n",
       " tensor(0.1057),\n",
       " tensor(0.3031),\n",
       " tensor(0.1071),\n",
       " tensor(0.3120),\n",
       " tensor(0.2766),\n",
       " tensor(0.2207),\n",
       " tensor(0.1630),\n",
       " tensor(0.3345),\n",
       " tensor(0.1041),\n",
       " tensor(0.1758),\n",
       " tensor(0.3582),\n",
       " tensor(0.3739),\n",
       " tensor(0.2842),\n",
       " tensor(0.4275),\n",
       " tensor(0.0900),\n",
       " tensor(0.2800),\n",
       " tensor(0.1052),\n",
       " tensor(0.1405),\n",
       " tensor(0.3870),\n",
       " tensor(0.0896),\n",
       " tensor(0.1374),\n",
       " tensor(0.4286),\n",
       " tensor(0.3116),\n",
       " tensor(0.1512),\n",
       " tensor(0.3493),\n",
       " tensor(0.4526),\n",
       " tensor(0.3280),\n",
       " tensor(0.2454),\n",
       " tensor(0.4012),\n",
       " tensor(0.1617),\n",
       " tensor(0.1037),\n",
       " tensor(0.3322),\n",
       " tensor(0.2858),\n",
       " tensor(0.2979),\n",
       " tensor(0.3137),\n",
       " tensor(0.1779),\n",
       " tensor(0.2666),\n",
       " tensor(0.2777),\n",
       " tensor(0.2547),\n",
       " tensor(0.1991),\n",
       " tensor(0.3025),\n",
       " tensor(0.2753),\n",
       " tensor(0.3969),\n",
       " tensor(0.3604),\n",
       " tensor(0.1392),\n",
       " tensor(0.2180),\n",
       " tensor(0.3352),\n",
       " tensor(0.3789),\n",
       " tensor(0.1571),\n",
       " tensor(0.1712),\n",
       " tensor(0.1758),\n",
       " tensor(0.1344),\n",
       " tensor(0.3472),\n",
       " tensor(0.2741),\n",
       " tensor(0.2845),\n",
       " tensor(0.4354),\n",
       " tensor(0.4985),\n",
       " tensor(0.6206),\n",
       " tensor(0.3457),\n",
       " tensor(0.1451),\n",
       " tensor(0.3689),\n",
       " tensor(0.5256),\n",
       " tensor(0.2581),\n",
       " tensor(0.3081),\n",
       " tensor(0.4264),\n",
       " tensor(0.3438),\n",
       " tensor(0.2617),\n",
       " tensor(0.2879),\n",
       " tensor(0.2868),\n",
       " tensor(0.2168),\n",
       " tensor(0.2104),\n",
       " tensor(0.2347),\n",
       " tensor(0.3445),\n",
       " tensor(0.2112),\n",
       " tensor(0.1668),\n",
       " tensor(0.4512),\n",
       " tensor(0.1422),\n",
       " tensor(0.5000),\n",
       " tensor(0.1982),\n",
       " tensor(0.3208),\n",
       " tensor(0.7068),\n",
       " tensor(0.3507),\n",
       " tensor(0.1127),\n",
       " tensor(0.2224),\n",
       " tensor(0.1741),\n",
       " tensor(0.2637),\n",
       " tensor(0.2544),\n",
       " tensor(0.3057),\n",
       " tensor(0.3074),\n",
       " tensor(0.5702),\n",
       " tensor(0.2309),\n",
       " tensor(0.2906),\n",
       " tensor(0.1862),\n",
       " tensor(0.2934),\n",
       " tensor(0.3600),\n",
       " tensor(0.1842),\n",
       " tensor(0.1240),\n",
       " tensor(0.1361),\n",
       " tensor(0.1530),\n",
       " tensor(0.1490),\n",
       " tensor(0.5227),\n",
       " tensor(0.1961),\n",
       " tensor(0.1410),\n",
       " tensor(0.2138),\n",
       " tensor(0.3031),\n",
       " tensor(0.3849),\n",
       " tensor(0.4770),\n",
       " tensor(0.4480),\n",
       " tensor(0.2121),\n",
       " tensor(0.2304),\n",
       " tensor(0.3845),\n",
       " tensor(0.3498),\n",
       " tensor(0.3557),\n",
       " tensor(0.3359),\n",
       " tensor(0.1642),\n",
       " tensor(0.2656),\n",
       " tensor(0.2091),\n",
       " tensor(0.3149),\n",
       " tensor(0.1904),\n",
       " tensor(0.3239),\n",
       " tensor(0.2692),\n",
       " tensor(0.2053),\n",
       " tensor(0.2903),\n",
       " tensor(0.2042),\n",
       " tensor(0.4573),\n",
       " tensor(0.2363),\n",
       " tensor(0.4477),\n",
       " tensor(0.5833),\n",
       " tensor(0.1233),\n",
       " tensor(0.2599),\n",
       " tensor(0.3657),\n",
       " tensor(0.3351),\n",
       " tensor(0.3525),\n",
       " tensor(0.1934),\n",
       " tensor(0.3936),\n",
       " tensor(0.3501),\n",
       " tensor(0.3340),\n",
       " tensor(0.2184),\n",
       " tensor(0.1949),\n",
       " tensor(0.3047),\n",
       " tensor(0.4438),\n",
       " tensor(0.4427),\n",
       " tensor(0.2477),\n",
       " tensor(0.2983),\n",
       " tensor(0.1391),\n",
       " tensor(0.1884),\n",
       " tensor(0.3120),\n",
       " tensor(0.2914),\n",
       " tensor(0.0931),\n",
       " tensor(0.2663),\n",
       " tensor(0.2557),\n",
       " tensor(0.2020),\n",
       " tensor(0.4113),\n",
       " tensor(0.1397),\n",
       " tensor(0.4838),\n",
       " tensor(0.3532),\n",
       " tensor(0.2430),\n",
       " tensor(0.2997),\n",
       " tensor(0.1922),\n",
       " tensor(0.1798),\n",
       " tensor(0.3908),\n",
       " tensor(0.1764),\n",
       " tensor(0.3649),\n",
       " tensor(0.2598),\n",
       " tensor(0.1509),\n",
       " tensor(0.1840),\n",
       " tensor(0.2277),\n",
       " tensor(0.3341),\n",
       " tensor(0.2312),\n",
       " tensor(0.2600),\n",
       " tensor(0.4186),\n",
       " tensor(0.3439),\n",
       " tensor(0.2119),\n",
       " tensor(0.3041),\n",
       " tensor(0.2968),\n",
       " tensor(0.3119),\n",
       " tensor(0.2085),\n",
       " tensor(0.2913),\n",
       " tensor(0.2847),\n",
       " tensor(0.1479),\n",
       " tensor(0.2860),\n",
       " tensor(0.2171),\n",
       " ...]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(graph.x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f1dc94e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.8893)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how similar are the patch embeddings \n",
    "sum((graph.x[0] - graph.x[8])**2) #so these embeddings are different"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9030ed",
   "metadata": {},
   "source": [
    "# Define Model \n",
    "- This mainly draws upon HIV project code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8392f1d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2baadc843c90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# class GNN(torch.nn.Module):\n",
    "#     def __init__(self, feature_size):\n",
    "#         super(GNN, self).__init__()\n",
    "#         num_classes = 2\n",
    "#         embedding_size = 2048 # from resnet  \n",
    "\n",
    "#         #define the GNN layers \n",
    "\n",
    "#         #layer 1\n",
    "#         #the first graph attention layer which will create 3*embed size embeddings for each node. This will also take care of all the message passing and aggregation\n",
    "#         self.conv1 = GATConv(feature_size, embedding_size, heads=3, dropout = 0.3)\n",
    "#         #reduce the dimensionality back\n",
    "#         self.head_transform1 = Linear(embedding_size*3, embedding_size)\n",
    "#         self.pool1 = TopKPooling(embedding_size, ratio=0.8)\n",
    "\n",
    "#         #layer 2\n",
    "#         self.conv2 = GATConv(embedding_size, embedding_size, heads=3, dropout = 0.3)\n",
    "#         self.head_transform2 = Linear(embedding_size*3, embedding_size)\n",
    "#         self.pool2 = TopKPooling(embedding_size, ratio=0.5)\n",
    "\n",
    "#         #layer 3\n",
    "#         self.conv3 = GATConv(embedding_size, embedding_size, heads=3, dropout = 0.3)\n",
    "#         self.head_transform3 = Linear(embedding_size*3, embedding_size)\n",
    "#         self.pool3 = TopKPooling(embedding_size, ratio=0.2)\n",
    "\n",
    "\n",
    "#         #linear layers - these need to be modified to match the output size? Or maybe not\n",
    "#         self.linear1 = Linear(embedding_size*2, embedding_size)\n",
    "#         self.linear2 = Linear(embedding_size, 2)\n",
    "\n",
    "#     def forward(self, x, edge_attr, edge_index, batch_index):\n",
    "#         #block 1 \n",
    "#         x = self.conv1(x, edge_index)\n",
    "#         x = self.head_transform1(x)\n",
    "\n",
    "#         x, edge_index, edge_attr, batch_index, _, _ = self.pool1(x, edge_index, None, batch_index)\n",
    "#         #graph rep. \n",
    "#         x1 = torch.cat([gmp(x, batch_index), gap(x, batch_index)], dim=1)\n",
    "#         #block 2 \n",
    "#         x = self.conv2(x, edge_index)\n",
    "#         x = self.head_transform2(x)\n",
    "\n",
    "#         x, edge_index, edge_attr, batch_index, _, _ = self.pool2(x, edge_index, None, batch_index)\n",
    "#         #graph rep. \n",
    "#         x2 = torch.cat([gmp(x, batch_index), gap(x, batch_index)], dim=1)\n",
    "#         #block 3\n",
    "#         x = self.conv3(x, edge_index)\n",
    "#         x = self.head_transform3(x)\n",
    "\n",
    "#         x, edge_index, edge_attr, batch_index, _, _ = self.pool3(x, edge_index, None, batch_index)\n",
    "#         #graph rep. \n",
    "#         x3 = torch.cat([gmp(x, batch_index), gap(x, batch_index)], dim=1)\n",
    "#         #element wise addition , and each is 2048 \n",
    "#         x = x1 + x2 + x3\n",
    "#         #output block \n",
    "#         x = self.linear1(x).relu()\n",
    "#         x = F.dropout(x, p=0.5)\n",
    "#         x = self.linear2(x)\n",
    "\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "04c946ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "class simple_GNN(torch.nn.Module):\n",
    "    def __init__(self, feature_size):\n",
    "        super(simple_GNN, self).__init__()\n",
    "        \n",
    "        self.num_classes = 2 #scc or normal\n",
    "        self.embedding_size = 2048 # this is what we want the embedding to be\n",
    "        \n",
    "        self.linear1 = Linear(self.embedding_size, 64)\n",
    "        #define the GNN layers \n",
    "        \n",
    "        self.drop_edge = lambda edge_index: dropout_edge(edge_index,p=0.3)[0]\n",
    "        \n",
    "        #layer 1\n",
    "        #the first graph attention layer which will create 3*embed size embeddings for each node. This will also take care of all the message passing and aggregation\n",
    "        self.conv1 = GATConv(64, 64, heads=3, dropout = 0.3)\n",
    "        #reduce the dimensionality back\n",
    "        self.head_transform1 = Linear(64*3, 64)\n",
    "        \n",
    "        #layer 2\n",
    "        self.conv2 = GATConv(64, 128, heads=3, dropout = 0.3)\n",
    "        self.head_transform2 = Linear(128*3, 128)\n",
    "\n",
    "        #layer 3\n",
    "        self.conv3 = GATConv(128, 128, heads=3, dropout = 0.3)\n",
    "        self.head_transform3 = Linear(128*3, 128)\n",
    "        \n",
    "        #layer 4\n",
    "        self.conv4 = GATConv(128, 256, heads=3, dropout = 0.3)\n",
    "        self.head_transform4 = Linear(256*3, 256)\n",
    "        \n",
    "        #linear layers - these need to be modified to match the output size? Or maybe not\n",
    "        self.linear2 = Linear(256, 64) \n",
    "        self.linear3 = Linear(64, self.num_classes) #prediction for each class\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = x \n",
    "        edge_index = edge_index\n",
    "        batch = batch \n",
    "        # downsize the embeddings\n",
    "        x = self.linear1(x).relu()\n",
    "    \n",
    "        #block 1 \n",
    "        x = self.conv1(x, edge_index) #this is does all the aggregation and message passing\n",
    "        x = self.head_transform1(x)       \n",
    "       \n",
    "        #block 2\n",
    "#         edge_index = self.drop_edge(edge_index)\n",
    "        x = self.conv2(x, edge_index) \n",
    "        x = self.head_transform2(x)      \n",
    "        \n",
    "        #block 3\n",
    "#         edge_index = self.drop_edge(edge_index)\n",
    "        x = self.conv3(x, edge_index) #this is does all the aggregation and message passing\n",
    "        x = self.head_transform3(x)   \n",
    "        \n",
    "        #block 4\n",
    "#         edge_index = self.drop_edge(edge_index)\n",
    "        x = self.conv4(x, edge_index) \n",
    "        x = self.head_transform4(x)   \n",
    "        \n",
    "        #output block \n",
    "        x = self.linear2(x).relu()\n",
    "        x = F.dropout(x, p=0.5)\n",
    "        x = self.linear3(x)\n",
    "        \n",
    "#         print(\"Inside model, after all computations\", torch.cuda.memory_summary(device=None, abbreviated=False)) #bulk of the memory is used here, somehow\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "02ee440a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sage_GNN(torch.nn.Module):\n",
    "    def __init__(self, feature_size):\n",
    "        super(sage_GNN, self).__init__()\n",
    "        \n",
    "        self.num_classes = 2 #scc or normal\n",
    "        self.embedding_size = 2048 # this is what we want the embedding to be\n",
    "        \n",
    "        #define the GNN layers \n",
    "\n",
    "        #layer 1\n",
    "        self.conv1 = SAGEConv(feature_size, self.embedding_size*2)\n",
    "        \n",
    "        #layer 2\n",
    "        self.conv2 = SAGEConv(self.embedding_size*2, self.embedding_size*4)\n",
    "           \n",
    "        #layer 3\n",
    "        self.conv3 = SAGEConv(self.embedding_size*4, self.embedding_size)\n",
    "\n",
    "        self.linear = Linear(self.embedding_size, 100) \n",
    "        self.linear2 = Linear(100, 2)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        \n",
    "#         x = F.relu(self.conv1(x, edge_index))\n",
    "#         x = F.relu(self.conv2(x, edge_index))\n",
    "#         x = F.relu(self.conv3(x, edge_index))\n",
    "        x = F.relu(self.linear(x))\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "018eedc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class simple_NN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(simple_NN, self).__init__()\n",
    "        \n",
    "\n",
    "        self.linear = Linear(2048, 2048) \n",
    "        self.linear2 = Linear(2048, 100)\n",
    "        self.linear3 = Linear(100, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.linear(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f0ef05",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ade768a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 2048\n",
    "\n",
    "# device_ids = [0, 1]\n",
    "\n",
    "model = simple_GNN(2048)\n",
    "# model= nn.DataParallel(model, device_ids = device_ids)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "bd55029e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "simple_GNN(\n",
       "  (linear1): Linear(in_features=2048, out_features=64, bias=True)\n",
       "  (conv1): GATConv(64, 64, heads=3)\n",
       "  (head_transform1): Linear(in_features=192, out_features=64, bias=True)\n",
       "  (conv2): GATConv(64, 128, heads=3)\n",
       "  (head_transform2): Linear(in_features=384, out_features=128, bias=True)\n",
       "  (conv3): GATConv(128, 128, heads=3)\n",
       "  (head_transform3): Linear(in_features=384, out_features=128, bias=True)\n",
       "  (conv4): GATConv(128, 256, heads=3)\n",
       "  (head_transform4): Linear(in_features=768, out_features=256, bias=True)\n",
       "  (linear2): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (linear3): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e6345fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss and optimizer \n",
    "import torch.optim as optim\n",
    "import torchvision.ops.focal_loss\n",
    "\n",
    "# loss_fn = torchvision.ops.focal_loss.sigmoid_focal_loss\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "8e2eb630",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare training \n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "# train_loader = DataLoader(training_data, batch_size=1, shuffle=True)\n",
    "# val_loader = DataLoader(val_data, batch_size=1, shuffle=True)\n",
    "# test_loader = DataLoader(testing_data, batch_size=1, shuffle=True)\n",
    "\n",
    "# num_epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f30c1a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "softmax = nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28544066",
   "metadata": {},
   "source": [
    "# Inductive Model Training on Gokul Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "01188559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(num_epochs):\n",
    "#     #training portion\n",
    "#     model.train()\n",
    "#     epoch_loss = []\n",
    "#     for data in tqdm(train_loader):\n",
    "#         #get graph and the relevant stuff\n",
    "#         graph = data[0]\n",
    "#         x = data[0].x\n",
    "#         edge_index = data[0].edge_index\n",
    "#         y = data[0].y\n",
    "        \n",
    "#         #move to device\n",
    "#         x = x.to(device)\n",
    "#         edge_index = edge_index.to(device)\n",
    "#         y = y.to(device)\n",
    "\n",
    "#         #get predictions \n",
    "#         logits = model(x, edge_index)\n",
    "#         loss = loss_fn(logits, y) #for CE\n",
    "\n",
    "#         epoch_loss.append(loss.item())\n",
    "\n",
    "#         opt.zero_grad()\n",
    "#         loss.backward()\n",
    "#         opt.step()\n",
    "#     #now find the average training loss for this epoch \n",
    "#     epoch_loss = sum(epoch_loss)/len(epoch_loss)\n",
    "#     print(\"Epoch :%d. Epoch loss: %f\" %(epoch, epoch_loss))    \n",
    "#     #validation portion\n",
    "#     validation_correct = 0\n",
    "#     validation_total = 0\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         for data in tqdm(val_loader):\n",
    "#             #get graph\n",
    "#             graph = data[0]\n",
    "#             x = data[0].x\n",
    "#             edge_index = data[0].edge_index\n",
    "#             y = data[0].y\n",
    "        \n",
    "#             #move to device\n",
    "#             x = x.to(device)\n",
    "#             edge_index = edge_index.to(device)\n",
    "#             y = y.to(device)\n",
    "\n",
    "#             #get predictions \n",
    "#             logits = model(x, edge_index)\n",
    "#             #get them into label predictions\n",
    "#             _, indices = torch.max(logits, dim=1)\n",
    "# #             print(indices)\n",
    "#             validation_correct += sum(indices == y).item()\n",
    "#             validation_total += len(y)\n",
    "# #             print(\"Accuracy on this graph's val set\", sum(indices == y).item()/len(y))\n",
    "# #             print(\"SCC percent\", sum(y == 1).item()/len(y))\n",
    "    \n",
    "#     print(\"Epoch :%d. Validation accuracy: %f\" %(epoch, validation_correct/validation_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b1172f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  #test portion\n",
    "# test_correct = 0\n",
    "# test_total = 0\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     for data in tqdm(data_loader):\n",
    "#         #get graph\n",
    "#         graph = data[0]\n",
    "#         x = graph.x \n",
    "#         edge_index = graph.edge_index\n",
    "#         y = graph.y \n",
    "#         #move to device\n",
    "#         x = x.to(device)\n",
    "#         edge_index = edge_index.to(device)\n",
    "#         y = y.to(device)\n",
    "#         #get masks\n",
    "#         test_mask = data[3].T.reshape([data[3].T.shape[0]])\n",
    "\n",
    "#         #get predictions \n",
    "#         logits = model(x, edge_index)\n",
    "#         #get them into label predictions\n",
    "#         _, indices = torch.max(logits, dim=1)\n",
    "#         print(1 in indices)\n",
    "#         test_correct += sum(indices[test_mask] == y[test_mask]).item()\n",
    "#         test_total += sum(test_mask == True).item()\n",
    "\n",
    "# print(\"Test accuracy: %f\" %(test_correct/test_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e20b47",
   "metadata": {},
   "source": [
    "# Training With Sophie Data\n",
    "- Here, use inductive training \n",
    "- split the ids themselves into different categories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9890dde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sophie_data = pd.read_pickle(\"/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/users/Sophie_Chen/graph_dataset/graph_dataset_modified.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "80a3cabc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'109_A1c_ASAP_tumor_map': [[Data(x=[41295, 2048], edge_index=[2, 204923], y=[41295], pos=[41295, 2], train_mask=[41295], val_mask=[41295], test_mask=[41295])]],\n",
       " '10_A1a_ASAP_tumor_map': [[Data(x=[16468, 2048], edge_index=[2, 80814], y=[16468], pos=[16468, 2], train_mask=[16468], val_mask=[16468], test_mask=[16468])]],\n",
       " '10_A1b_ASAP_tumor_map': [[Data(x=[17010, 2048], edge_index=[2, 83576], y=[17010], pos=[17010, 2], train_mask=[17010], val_mask=[17010], test_mask=[17010])]],\n",
       " '10_A2b_ASAP_tumor_map': [[Data(x=[18422, 2048], edge_index=[2, 90600], y=[18422], pos=[18422, 2], train_mask=[18422], val_mask=[18422], test_mask=[18422])]],\n",
       " '110_A2b_ASAP_tumor_map': [[Data(x=[17856, 2048], edge_index=[2, 87348], y=[17856], pos=[17856, 2], train_mask=[17856], val_mask=[17856], test_mask=[17856])]],\n",
       " '112_a_ASAP_tumor_map': [[Data(x=[6217, 2048], edge_index=[2, 29695], y=[6217], pos=[6217, 2], train_mask=[6217], val_mask=[6217], test_mask=[6217])]],\n",
       " '112_b_ASAP_tumor_map': [[Data(x=[6828, 2048], edge_index=[2, 32550], y=[6828], pos=[6828, 2], train_mask=[6828], val_mask=[6828], test_mask=[6828])]],\n",
       " '123_A1a_ASAP_tumor_map': [[Data(x=[15989, 2048], edge_index=[2, 76693], y=[15989], pos=[15989, 2], train_mask=[15989], val_mask=[15989], test_mask=[15989])]],\n",
       " '12_A1c_ASAP_tumor_map': [[Data(x=[20897, 2048], edge_index=[2, 102667], y=[20897], pos=[20897, 2], train_mask=[20897], val_mask=[20897], test_mask=[20897])]],\n",
       " '14_A1b_ASAP_tumor_map': [[Data(x=[14594, 2048], edge_index=[2, 70526], y=[14594], pos=[14594, 2], train_mask=[14594], val_mask=[14594], test_mask=[14594])]],\n",
       " '14_A2b_ASAP_tumor_map': [[Data(x=[14780, 2048], edge_index=[2, 70200], y=[14780], pos=[14780, 2], train_mask=[14780], val_mask=[14780], test_mask=[14780])]],\n",
       " '169_A2b_ASAP_tumor_map': [[Data(x=[15550, 2048], edge_index=[2, 76556], y=[15550], pos=[15550, 2], train_mask=[15550], val_mask=[15550], test_mask=[15550])]],\n",
       " '270_A1b_ASAP_tumor_map': [[Data(x=[21371, 2048], edge_index=[2, 105107], y=[21371], pos=[21371, 2], train_mask=[21371], val_mask=[21371], test_mask=[21371])]],\n",
       " '270_A1d_ASAP_tumor_map': [[Data(x=[20725, 2048], edge_index=[2, 102197], y=[20725], pos=[20725, 2], train_mask=[20725], val_mask=[20725], test_mask=[20725])]],\n",
       " '270_A1e_ASAP_tumor_map': [[Data(x=[20591, 2048], edge_index=[2, 101633], y=[20591], pos=[20591, 2], train_mask=[20591], val_mask=[20591], test_mask=[20591])]],\n",
       " '270_A2b_ASAP_tumor_map': [[Data(x=[19129, 2048], edge_index=[2, 94311], y=[19129], pos=[19129, 2], train_mask=[19129], val_mask=[19129], test_mask=[19129])]],\n",
       " '270_A2f_ASAP_tumor_map': [[Data(x=[7420, 2048], edge_index=[2, 36228], y=[7420], pos=[7420, 2], train_mask=[7420], val_mask=[7420], test_mask=[7420])]],\n",
       " '281_A1d_ASAP_tumor_map': [[Data(x=[13297, 2048], edge_index=[2, 65497], y=[13297], pos=[13297, 2], train_mask=[13297], val_mask=[13297], test_mask=[13297])]],\n",
       " '281_A1f_ASAP_tumor_map': [[Data(x=[14385, 2048], edge_index=[2, 70949], y=[14385], pos=[14385, 2], train_mask=[14385], val_mask=[14385], test_mask=[14385])]],\n",
       " '281_A2eX_ASAP_tumor_map': [[Data(x=[13449, 2048], edge_index=[2, 66323], y=[13449], pos=[13449, 2], train_mask=[13449], val_mask=[13449], test_mask=[13449])]],\n",
       " '311_A2c_ASAP_tumor_map': [[Data(x=[12337, 2048], edge_index=[2, 60653], y=[12337], pos=[12337, 2], train_mask=[12337], val_mask=[12337], test_mask=[12337])]],\n",
       " '327_A1a_ASAP_tumor_map': [[Data(x=[26042, 2048], edge_index=[2, 128022], y=[26042], pos=[26042, 2], train_mask=[26042], val_mask=[26042], test_mask=[26042])]],\n",
       " '327_A1d_ASAP_tumor_map': [[Data(x=[16320, 2048], edge_index=[2, 80024], y=[16320], pos=[16320, 2], train_mask=[16320], val_mask=[16320], test_mask=[16320])]],\n",
       " '327_B1c_ASAP_tumor_map': [[Data(x=[38507, 2048], edge_index=[2, 190173], y=[38507], pos=[38507, 2], train_mask=[38507], val_mask=[38507], test_mask=[38507])]],\n",
       " '341_a_ASAP_tumor_map': [[Data(x=[9379, 2048], edge_index=[2, 45857], y=[9379], pos=[9379, 2], train_mask=[9379], val_mask=[9379], test_mask=[9379])]],\n",
       " '341_b_ASAP_tumor_map': [[Data(x=[6770, 2048], edge_index=[2, 32990], y=[6770], pos=[6770, 2], train_mask=[6770], val_mask=[6770], test_mask=[6770])]],\n",
       " '342_a_ASAP_tumor_map': [[Data(x=[6217, 2048], edge_index=[2, 29695], y=[6217], pos=[6217, 2], train_mask=[6217], val_mask=[6217], test_mask=[6217])]],\n",
       " '342_b_ASAP_tumor_map': [[Data(x=[6828, 2048], edge_index=[2, 32550], y=[6828], pos=[6828, 2], train_mask=[6828], val_mask=[6828], test_mask=[6828])]],\n",
       " '343_a_ASAP_tumor_map': [[Data(x=[17027, 2048], edge_index=[2, 81229], y=[17027], pos=[17027, 2], train_mask=[17027], val_mask=[17027], test_mask=[17027])]],\n",
       " '343_b_ASAP_tumor_map': [[Data(x=[22341, 2048], edge_index=[2, 109241], y=[22341], pos=[22341, 2], train_mask=[22341], val_mask=[22341], test_mask=[22341])]],\n",
       " '343_c_ASAP_tumor_map': [[Data(x=[23215, 2048], edge_index=[2, 113369], y=[23215], pos=[23215, 2], train_mask=[23215], val_mask=[23215], test_mask=[23215])]],\n",
       " '343_d_ASAP_tumor_map': [[Data(x=[23840, 2048], edge_index=[2, 116080], y=[23840], pos=[23840, 2], train_mask=[23840], val_mask=[23840], test_mask=[23840])]],\n",
       " '344_a_ASAP_tumor_map': [[Data(x=[9984, 2048], edge_index=[2, 47972], y=[9984], pos=[9984, 2], train_mask=[9984], val_mask=[9984], test_mask=[9984])]],\n",
       " '344_b_ASAP_tumor_map': [[Data(x=[10341, 2048], edge_index=[2, 50033], y=[10341], pos=[10341, 2], train_mask=[10341], val_mask=[10341], test_mask=[10341])]],\n",
       " '345_a_ASAP_tumor_map': [[Data(x=[14538, 2048], edge_index=[2, 71502], y=[14538], pos=[14538, 2], train_mask=[14538], val_mask=[14538], test_mask=[14538])]],\n",
       " '345_b_ASAP_tumor_map': [[Data(x=[14814, 2048], edge_index=[2, 72786], y=[14814], pos=[14814, 2], train_mask=[14814], val_mask=[14814], test_mask=[14814])]],\n",
       " '346_a_ASAP_tumor_map': [[Data(x=[10946, 2048], edge_index=[2, 51998], y=[10946], pos=[10946, 2], train_mask=[10946], val_mask=[10946], test_mask=[10946])]],\n",
       " '346_b_ASAP_tumor_map': [[Data(x=[11288, 2048], edge_index=[2, 53376], y=[11288], pos=[11288, 2], train_mask=[11288], val_mask=[11288], test_mask=[11288])]],\n",
       " '350_A1a_ASAP_tumor_map': [[Data(x=[16028, 2048], edge_index=[2, 77616], y=[16028], pos=[16028, 2], train_mask=[16028], val_mask=[16028], test_mask=[16028])]],\n",
       " '350_A1b_ASAP_tumor_map': [[Data(x=[19397, 2048], edge_index=[2, 95109], y=[19397], pos=[19397, 2], train_mask=[19397], val_mask=[19397], test_mask=[19397])]],\n",
       " '350_A1c_ASAP_tumor_map': [[Data(x=[18496, 2048], edge_index=[2, 90860], y=[18496], pos=[18496, 2], train_mask=[18496], val_mask=[18496], test_mask=[18496])]],\n",
       " '350_A1d_ASAP_tumor_map': [[Data(x=[16841, 2048], edge_index=[2, 82713], y=[16841], pos=[16841, 2], train_mask=[16841], val_mask=[16841], test_mask=[16841])]],\n",
       " '350_A1e_ASAP_tumor_map': [[Data(x=[14432, 2048], edge_index=[2, 70866], y=[14432], pos=[14432, 2], train_mask=[14432], val_mask=[14432], test_mask=[14432])]],\n",
       " '351_A2b_ASAP_tumor_map': [[Data(x=[10278, 2048], edge_index=[2, 49952], y=[10278], pos=[10278, 2], train_mask=[10278], val_mask=[10278], test_mask=[10278])]],\n",
       " '352_A1d_ASAP_tumor_map': [[Data(x=[21248, 2048], edge_index=[2, 104224], y=[21248], pos=[21248, 2], train_mask=[21248], val_mask=[21248], test_mask=[21248])]],\n",
       " '352_A1e_ASAP_tumor_map': [[Data(x=[20685, 2048], edge_index=[2, 101469], y=[20685], pos=[20685, 2], train_mask=[20685], val_mask=[20685], test_mask=[20685])]],\n",
       " '352_A1g_ASAP_tumor_map': [[Data(x=[17017, 2048], edge_index=[2, 83333], y=[17017], pos=[17017, 2], train_mask=[17017], val_mask=[17017], test_mask=[17017])]],\n",
       " '352_A1h_ASAP_tumor_map': [[Data(x=[14807, 2048], edge_index=[2, 72129], y=[14807], pos=[14807, 2], train_mask=[14807], val_mask=[14807], test_mask=[14807])]],\n",
       " '352_A1i_ASAP_tumor_map': [[Data(x=[14577, 2048], edge_index=[2, 71183], y=[14577], pos=[14577, 2], train_mask=[14577], val_mask=[14577], test_mask=[14577])]],\n",
       " '353_A2b_ASAP_tumor_map': [[Data(x=[17856, 2048], edge_index=[2, 87348], y=[17856], pos=[17856, 2], train_mask=[17856], val_mask=[17856], test_mask=[17856])]],\n",
       " '354_A1b_ASAP_tumor_map': [[Data(x=[13521, 2048], edge_index=[2, 65591], y=[13521], pos=[13521, 2], train_mask=[13521], val_mask=[13521], test_mask=[13521])]],\n",
       " '354_A1c_ASAP_tumor_map': [[Data(x=[15681, 2048], edge_index=[2, 76283], y=[15681], pos=[15681, 2], train_mask=[15681], val_mask=[15681], test_mask=[15681])]],\n",
       " '354_A1d_ASAP_tumor_map': [[Data(x=[18198, 2048], edge_index=[2, 89710], y=[18198], pos=[18198, 2], train_mask=[18198], val_mask=[18198], test_mask=[18198])]],\n",
       " '354_A3a_ASAP_tumor_map': [[Data(x=[13247, 2048], edge_index=[2, 62619], y=[13247], pos=[13247, 2], train_mask=[13247], val_mask=[13247], test_mask=[13247])]],\n",
       " '354_A3b_ASAP_tumor_map': [[Data(x=[21912, 2048], edge_index=[2, 106228], y=[21912], pos=[21912, 2], train_mask=[21912], val_mask=[21912], test_mask=[21912])]],\n",
       " '354_A3c_ASAP_tumor_map': [[Data(x=[25688, 2048], edge_index=[2, 124634], y=[25688], pos=[25688, 2], train_mask=[25688], val_mask=[25688], test_mask=[25688])]],\n",
       " '354_D1b_ASAP_tumor_map': [[Data(x=[15035, 2048], edge_index=[2, 72861], y=[15035], pos=[15035, 2], train_mask=[15035], val_mask=[15035], test_mask=[15035])]],\n",
       " '355_A1d_ASAP_tumor_map': [[Data(x=[8427, 2048], edge_index=[2, 41089], y=[8427], pos=[8427, 2], train_mask=[8427], val_mask=[8427], test_mask=[8427])]],\n",
       " '356_A1b_ASAP_tumor_map': [[Data(x=[10764, 2048], edge_index=[2, 52644], y=[10764], pos=[10764, 2], train_mask=[10764], val_mask=[10764], test_mask=[10764])]],\n",
       " '358_A1a_ASAP_tumor_map': [[Data(x=[15989, 2048], edge_index=[2, 76693], y=[15989], pos=[15989, 2], train_mask=[15989], val_mask=[15989], test_mask=[15989])]],\n",
       " '358_A1b_ASAP_tumor_map': [[Data(x=[18501, 2048], edge_index=[2, 89751], y=[18501], pos=[18501, 2], train_mask=[18501], val_mask=[18501], test_mask=[18501])]],\n",
       " '361_a_ASAP_tumor_map': [[Data(x=[16753, 2048], edge_index=[2, 81581], y=[16753], pos=[16753, 2], train_mask=[16753], val_mask=[16753], test_mask=[16753])]],\n",
       " '361_b_ASAP_tumor_map': [[Data(x=[21629, 2048], edge_index=[2, 106179], y=[21629], pos=[21629, 2], train_mask=[21629], val_mask=[21629], test_mask=[21629])]],\n",
       " '362_A1a_ASAP_tumor_map': [[Data(x=[19610, 2048], edge_index=[2, 95728], y=[19610], pos=[19610, 2], train_mask=[19610], val_mask=[19610], test_mask=[19610])]],\n",
       " '362_A1b_ASAP_tumor_map': [[Data(x=[21227, 2048], edge_index=[2, 104153], y=[21227], pos=[21227, 2], train_mask=[21227], val_mask=[21227], test_mask=[21227])]],\n",
       " '362_A1c_ASAP_tumor_map': [[Data(x=[18796, 2048], edge_index=[2, 92020], y=[18796], pos=[18796, 2], train_mask=[18796], val_mask=[18796], test_mask=[18796])]],\n",
       " '363_A1b_ASAP_tumor_map': [[Data(x=[20782, 2048], edge_index=[2, 102188], y=[20782], pos=[20782, 2], train_mask=[20782], val_mask=[20782], test_mask=[20782])]],\n",
       " '363_A1c_ASAP_tumor_map': [[Data(x=[20598, 2048], edge_index=[2, 101562], y=[20598], pos=[20598, 2], train_mask=[20598], val_mask=[20598], test_mask=[20598])]],\n",
       " '363_A2b_ASAP_tumor_map': [[Data(x=[25273, 2048], edge_index=[2, 124205], y=[25273], pos=[25273, 2], train_mask=[25273], val_mask=[25273], test_mask=[25273])]],\n",
       " '363_A3b_ASAP_tumor_map': [[Data(x=[23471, 2048], edge_index=[2, 115461], y=[23471], pos=[23471, 2], train_mask=[23471], val_mask=[23471], test_mask=[23471])]],\n",
       " '364_A1b_ASAP_tumor_map': [[Data(x=[22247, 2048], edge_index=[2, 108537], y=[22247], pos=[22247, 2], train_mask=[22247], val_mask=[22247], test_mask=[22247])]],\n",
       " '364_A2b_ASAP_tumor_map': [[Data(x=[22599, 2048], edge_index=[2, 108635], y=[22599], pos=[22599, 2], train_mask=[22599], val_mask=[22599], test_mask=[22599])]],\n",
       " '364_A4b_ASAP_tumor_map': [[Data(x=[21996, 2048], edge_index=[2, 106260], y=[21996], pos=[21996, 2], train_mask=[21996], val_mask=[21996], test_mask=[21996])]],\n",
       " '365_A1b_ASAP_tumor_map': [[Data(x=[19532, 2048], edge_index=[2, 95670], y=[19532], pos=[19532, 2], train_mask=[19532], val_mask=[19532], test_mask=[19532])]],\n",
       " '365_A2b_ASAP_tumor_map': [[Data(x=[18297, 2048], edge_index=[2, 89529], y=[18297], pos=[18297, 2], train_mask=[18297], val_mask=[18297], test_mask=[18297])]],\n",
       " '366_A1a_ASAP_tumor_map': [[Data(x=[13836, 2048], edge_index=[2, 66980], y=[13836], pos=[13836, 2], train_mask=[13836], val_mask=[13836], test_mask=[13836])]],\n",
       " '366_A1b_ASAP_tumor_map': [[Data(x=[16659, 2048], edge_index=[2, 81447], y=[16659], pos=[16659, 2], train_mask=[16659], val_mask=[16659], test_mask=[16659])]],\n",
       " '366_A1c_ASAP_tumor_map': [[Data(x=[17016, 2048], edge_index=[2, 83338], y=[17016], pos=[17016, 2], train_mask=[17016], val_mask=[17016], test_mask=[17016])]],\n",
       " '367_A2b_ASAP_tumor_map': [[Data(x=[11172, 2048], edge_index=[2, 54330], y=[11172], pos=[11172, 2], train_mask=[11172], val_mask=[11172], test_mask=[11172])]],\n",
       " '368_A1b_ASAP_tumor_map': [[Data(x=[29007, 2048], edge_index=[2, 142163], y=[29007], pos=[29007, 2], train_mask=[29007], val_mask=[29007], test_mask=[29007])]],\n",
       " '368_A1c_ASAP_tumor_map': [[Data(x=[31870, 2048], edge_index=[2, 156436], y=[31870], pos=[31870, 2], train_mask=[31870], val_mask=[31870], test_mask=[31870])]],\n",
       " '368_A1d_ASAP_tumor_map': [[Data(x=[34134, 2048], edge_index=[2, 168360], y=[34134], pos=[34134, 2], train_mask=[34134], val_mask=[34134], test_mask=[34134])]],\n",
       " '369_A1b_ASAP_tumor_map': [[Data(x=[14550, 2048], edge_index=[2, 70924], y=[14550], pos=[14550, 2], train_mask=[14550], val_mask=[14550], test_mask=[14550])]],\n",
       " '369_A1c_ASAP_tumor_map': [[Data(x=[12994, 2048], edge_index=[2, 63080], y=[12994], pos=[12994, 2], train_mask=[12994], val_mask=[12994], test_mask=[12994])]],\n",
       " '369_A2b_ASAP_tumor_map': [[Data(x=[14285, 2048], edge_index=[2, 69153], y=[14285], pos=[14285, 2], train_mask=[14285], val_mask=[14285], test_mask=[14285])]],\n",
       " '370_A1b_ASAP_tumor_map': [[Data(x=[10352, 2048], edge_index=[2, 50610], y=[10352], pos=[10352, 2], train_mask=[10352], val_mask=[10352], test_mask=[10352])]],\n",
       " '370_A2a_ASAP_tumor_map': [[Data(x=[8894, 2048], edge_index=[2, 43366], y=[8894], pos=[8894, 2], train_mask=[8894], val_mask=[8894], test_mask=[8894])]],\n",
       " '370_A2b_ASAP_tumor_map': [[Data(x=[9622, 2048], edge_index=[2, 47192], y=[9622], pos=[9622, 2], train_mask=[9622], val_mask=[9622], test_mask=[9622])]],\n",
       " '37_A2d_ASAP_tumor_map': [[Data(x=[15415, 2048], edge_index=[2, 73359], y=[15415], pos=[15415, 2], train_mask=[15415], val_mask=[15415], test_mask=[15415])]],\n",
       " '61_A1a_ASAP_tumor_map': [[Data(x=[10242, 2048], edge_index=[2, 49648], y=[10242], pos=[10242, 2], train_mask=[10242], val_mask=[10242], test_mask=[10242])]],\n",
       " '61_B1a_ASAP_tumor_map': [[Data(x=[9546, 2048], edge_index=[2, 46092], y=[9546], pos=[9546, 2], train_mask=[9546], val_mask=[9546], test_mask=[9546])]],\n",
       " '70_A2b_ASAP_tumor_map': [[Data(x=[10278, 2048], edge_index=[2, 49952], y=[10278], pos=[10278, 2], train_mask=[10278], val_mask=[10278], test_mask=[10278])]],\n",
       " '7_A1c_ASAP_tumor_map': [[Data(x=[18496, 2048], edge_index=[2, 90860], y=[18496], pos=[18496, 2], train_mask=[18496], val_mask=[18496], test_mask=[18496])]],\n",
       " '7_A1d_ASAP_tumor_map': [[Data(x=[16841, 2048], edge_index=[2, 82713], y=[16841], pos=[16841, 2], train_mask=[16841], val_mask=[16841], test_mask=[16841])]],\n",
       " '7_A1e_ASAP_tumor_map': [[Data(x=[14432, 2048], edge_index=[2, 70866], y=[14432], pos=[14432, 2], train_mask=[14432], val_mask=[14432], test_mask=[14432])]]}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sophie_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fe4fcd01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sophie_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "709d206b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ids = []\n",
    "for id in sophie_data:\n",
    "    dataset_ids.append(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "58c6f509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8276a878",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids, test_ids = train_test_split(dataset_ids, train_size = .9, test_size = .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "acee01ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85 10\n"
     ]
    }
   ],
   "source": [
    "print(len(train_ids), len(test_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "06014a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids, val_ids = train_test_split(train_ids, train_size = .9, test_size = .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9766dc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76 9\n"
     ]
    }
   ],
   "source": [
    "print(len(train_ids), len(val_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b353ca6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76 10 9\n"
     ]
    }
   ],
   "source": [
    "print(len(train_ids), len(test_ids), len(val_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "413779e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here collect all of the graphs - expect sophie's data set doesn't have test sets, only test masks\n",
    "\n",
    "train_dataset = []\n",
    "\n",
    "for id in train_ids:\n",
    "    train_dataset.append(sophie_data[id][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "275d7ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = []\n",
    "\n",
    "for id in val_ids:\n",
    "    val_dataset.append(sophie_data[id][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a52c2aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = []\n",
    "\n",
    "for id in test_ids:\n",
    "    test_dataset.append(sophie_data[id][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "6a029f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=5)\n",
    "val_loader = DataLoader(val_dataset, batch_size=5)\n",
    "test_loader = DataLoader(test_dataset, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2e2b7d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 2 2\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader), len(val_loader), len(test_loader))\n",
    "num_epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b77d13c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                | 0/38 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[31134, 2048], edge_index=[2, 152810], y=[31134], pos=[31134, 2], train_mask=[31134], val_mask=[31134], test_mask=[31134], batch=[31134], ptr=[3])\n",
      "tensor([[ 4.7501, -4.3944],\n",
      "        [ 6.9683,  0.3502],\n",
      "        [ 0.0289, -1.8279],\n",
      "        ...,\n",
      "        [12.1640,  0.3582],\n",
      "        [12.2839, 17.3762],\n",
      "        [ 5.0911,  0.7027]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# for data in tqdm(train_loader):\n",
    "#     print(data)\n",
    "#     x = data.x\n",
    "#     edge_index = data.edge_index\n",
    "#     y = data.y\n",
    "#     batch = data.batch\n",
    "    \n",
    "#     x = x.to(device)\n",
    "#     edge_index = edge_index.to(device)\n",
    "#     y = y.to(device)\n",
    "#     batch = batch.to(device)\n",
    "\n",
    "#     print(model(x, edge_index, batch))\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "04064a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossess = []\n",
    "rocs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "9811ab2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                | 0/16 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.21 GiB (GPU 0; 31.75 GiB total capacity; 26.48 GiB already allocated; 1014.19 MiB free; 29.83 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/scratch/ipykernel_141218/3411217258.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m#now find the average training loss for this epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jupyter_ultimate/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[1;32m    487\u001b[0m         torch.autograd.backward(\n\u001b[0;32m--> 488\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m         )\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jupyter_ultimate/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    197\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m def grad(\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.21 GiB (GPU 0; 31.75 GiB total capacity; 26.48 GiB already allocated; 1014.19 MiB free; 29.83 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    #training portion\n",
    "    model.train()\n",
    "    epoch_loss = []\n",
    "    for data in tqdm(train_loader):\n",
    "        #get graph and the relevant stuff\n",
    "        graph = data\n",
    "        x = data.x\n",
    "        edge_index = data.edge_index\n",
    "        y = data.y\n",
    "        batch = data.batch \n",
    "        \n",
    "        #move to device\n",
    "        x = x.to(device)\n",
    "        edge_index = edge_index.to(device)\n",
    "        y = y.to(device)\n",
    "        batch = batch.to(device)\n",
    "        #get predictions \n",
    "        logits = model(x, edge_index, batch) #for CE - CE takes logics \n",
    "#         scores = softmax(model(x, edge_index))[:, 1] # for FL - takes the class prob\n",
    "        loss = loss_fn(logits, y) #for CE\n",
    "#         loss = loss_fn(scores, y.float()).sum() #for focal loss\n",
    "        epoch_loss.append(loss.item())\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    #now find the average training loss for this epoch \n",
    "    epoch_loss = sum(epoch_loss)/len(epoch_loss)\n",
    "    lossess.append(epoch_loss) #append to master array \n",
    "    print(\"Epoch :%d. Epoch loss: %f\" %(epoch, epoch_loss))   \n",
    "    \n",
    "    #validation portion\n",
    "    probabilities = torch.Tensor([])\n",
    "    ground_truth = torch.Tensor([])\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(val_loader):\n",
    "            #get graph\n",
    "            graph = data\n",
    "            x = graph.x \n",
    "            edge_index = graph.edge_index\n",
    "            y = graph.y \n",
    "            batch = graph.batch\n",
    "            #move to device\n",
    "            x = x.to(device)\n",
    "            edge_index = edge_index.to(device)\n",
    "            y = y.to(device)\n",
    "            batch = batch.to(device)\n",
    "            #find the probs\n",
    "            scores = softmax(model(x, edge_index, batch))\n",
    "\n",
    "            #move to cpu\n",
    "            scores = scores.detach().cpu()\n",
    "            y = y.detach().cpu()\n",
    "\n",
    "            #concat them \n",
    "            probabilities = torch.cat((probabilities, scores))\n",
    "            ground_truth = torch.cat((ground_truth, y))\n",
    "    roc = roc_auc_score(ground_truth, probabilities[:, 1])\n",
    "    rocs.append(roc) #add to ROC master array \n",
    "    print(\"Epoch :%d. Validation AUC-ROC: %f\" %(epoch, roc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "3d5d6c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 35.88it/s]\n"
     ]
    }
   ],
   "source": [
    "# #test portion\n",
    "    \n",
    "# probabilities = torch.Tensor([])\n",
    "# ground_truth = torch.Tensor([])\n",
    "\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     for data in tqdm(test_loader):\n",
    "#         #get graph\n",
    "#         graph = data[0]\n",
    "#         x = graph.x \n",
    "#         edge_index = graph.edge_index\n",
    "#         y = graph.y \n",
    "        \n",
    "#         #move to device\n",
    "#         x = x.to(device)\n",
    "#         edge_index = edge_index.to(device)\n",
    "#         y = y.to(device)\n",
    "        \n",
    "#         #find the probs\n",
    "#         scores = softmax(model(x, edge_index))\n",
    "        \n",
    "#         #move to cpu\n",
    "#         scores = scores.detach().cpu()\n",
    "#         y = y.detach().cpu()\n",
    "        \n",
    "#         #concat them \n",
    "#         probabilities = torch.cat((probabilities, scores))\n",
    "#         ground_truth = torch.cat((ground_truth, y))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "988ba80b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+00, 1.1201e-15],\n",
       "        [1.0000e+00, 1.5853e-29],\n",
       "        [1.0000e+00, 1.3365e-22],\n",
       "        ...,\n",
       "        [1.0000e+00, 5.8069e-13],\n",
       "        [1.0000e+00, 7.8413e-14],\n",
       "        [1.0000e+00, 7.1734e-13]])"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "f1f72d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5987004724159877"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict the whole test cohort AUC-ROC\n",
    "\n",
    "roc_auc_score(ground_truth, probabilities[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "60edaaab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#from sophie's code - viz. the curve \n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# fpr and tpr of all thresohlds\n",
    "true = ground_truth\n",
    "preds = probabilities[:, 1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(true, preds)\n",
    "\n",
    "#get the metrics \n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "#plot\n",
    "plt.title('Test Cohort-wide AUC-ROC')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddd2b8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Dec 24 02:12:11 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:18:00.0 Off |                    0 |\n",
      "| N/A   37C    P0    54W / 300W |   3046MiB / 32768MiB |      0%   E. Process |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  Off  | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    52W / 300W |    780MiB / 32768MiB |      0%   E. Process |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  Off  | 00000000:86:00.0 Off |                    0 |\n",
      "| N/A   30C    P0    41W / 300W |      3MiB / 32768MiB |      0%   E. Process |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  Off  | 00000000:AF:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    39W / 300W |      3MiB / 32768MiB |      0%   E. Process |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     18039      C   ...nda3/envs/hiss/bin/python     3043MiB |\n",
      "|    1   N/A  N/A     47354      C   ...pyter_ultimate/bin/python      777MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6d91140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a925531",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_ultimate",
   "language": "python",
   "name": "jupyter_ultimate"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
