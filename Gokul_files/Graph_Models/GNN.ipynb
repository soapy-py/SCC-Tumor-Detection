{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8956b385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch \n",
    "from tqdm import tqdm \n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob, os, pickle\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "import dgl\n",
    "from torch_geometric.utils import dropout_edge\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torch.optim as optim\n",
    "import torchvision.ops.focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6ecc5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F \n",
    "from torch.nn import Linear, BatchNorm1d, ModuleList\n",
    "from torch_geometric.nn import TransformerConv, TopKPooling, GATConv, SAGEConv\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf50a1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Dec 29 02:57:41 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:18:00.0 Off |                    0 |\n",
      "| N/A   35C    P0    52W / 300W |      0MiB / 32768MiB |      0%   E. Process |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  Off  | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   29C    P0    53W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  Off  | 00000000:86:00.0 Off |                    0 |\n",
      "| N/A   29C    P0    53W / 300W |      0MiB / 32768MiB |      0%   E. Process |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  Off  | 00000000:AF:00.0 Off |                    0 |\n",
      "| N/A   33C    P0    53W / 300W |      0MiB / 32768MiB |      2%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "336bf912",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bbd19dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda76be4",
   "metadata": {},
   "source": [
    "# Need to define the data class \n",
    "- Here focus mainly on the get() method. We don't need to process anything\n",
    "- We also return masks for each graph, that will help with training \n",
    "- Actually, no masks. Inductive training.\n",
    "- We are no longer using this data class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e61c0402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class WSI_Graph_Class(Dataset):\n",
    "    \n",
    "#     def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n",
    "#         super().__init__(None, transform, pre_transform)\n",
    "#         self.root_dir = root\n",
    "#         self.WSI_df = pd.read_csv(root) #get the WSI metadata\n",
    "#         self.masks = {} #map node num -> train/val/test masks\n",
    "#         self.create_all_masks()\n",
    "        \n",
    "#     def create_all_masks(self):\n",
    "        \n",
    "#         for idx in tqdm(range(len(self.WSI_df[\"sample_id\"]))):\n",
    "#             path = self.WSI_df[\"path\"].iloc[idx]\n",
    "            \n",
    "#             #this is the graph. We also need to return the training/validation/testing masks \n",
    "#             data = torch.load(path)\n",
    "#             nodes = [i for i in range(data.x.shape[0])] #node 0 is in 0th pos, 1 in 1, and so on \n",
    "            \n",
    "#             #all of the masks \n",
    "#             train_mask = [False] * len(nodes)\n",
    "#             val_mask = [False] * len(nodes)\n",
    "#             test_mask = [False] * len(nodes)\n",
    "#             self.create_mask(nodes, train_mask, val_mask, test_mask)\n",
    "#             #now add them to dictionary\n",
    "#             self.masks[idx] = [train_mask, val_mask, test_mask]\n",
    "        \n",
    "        \n",
    "#     def create_mask(self, nodes, train_mask, val_mask, test_mask):        \n",
    "#         #create train/test/val nodes (75/25)\n",
    "#         train, test = train_test_split(nodes)\n",
    "#         test, val = train_test_split(test)\n",
    "        \n",
    "#         #now create masks\n",
    "#         for i in range(len(nodes)):\n",
    "#             if i in train: \n",
    "#                 train_mask[i] = True \n",
    "                \n",
    "#         for i in range(len(nodes)):\n",
    "#             if nodes[i] in val: \n",
    "#                 val_mask[i] = True \n",
    "                \n",
    "#         for i in range(len(nodes)):\n",
    "#             if nodes[i] in test: \n",
    "#                 test_mask[i] = True \n",
    "                \n",
    "#     #just pass here, we aren't going to return any raw file names\n",
    "#     def raw_file_names(self):\n",
    "#         pass \n",
    "#     #here we can return each of the WSI \n",
    "#     def processed_file_names(self):\n",
    "#         return list(self.WSI_df[\"sample_id\"])\n",
    "    \n",
    "#     def len(self):\n",
    "#         return len(self.processed_file_names())\n",
    "    \n",
    "#     #return the graph class for that idx \n",
    "#     def get(self, idx):\n",
    "#         path = self.WSI_df[\"path\"].iloc[idx]\n",
    "#         #this is the graph. We also need to return the training/validation/testing masks \n",
    "#         data = torch.load(path)\n",
    "#         masks = self.masks[idx]\n",
    "#         train_mask = masks[0]\n",
    "#         val_mask = masks[1]\n",
    "#         test_mask = masks[2]\n",
    "#         return (data, torch.tensor(train_mask), torch.tensor(val_mask), torch.tensor(test_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34847690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root = \"/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/users/Gokul_Srinivasan/SCC-Tumor-Detection/Gokul_files/graph_data/metadata.csv\"\n",
    "\n",
    "# dataset = WSI_Graph_Class(root = root, transform = None, pre_transform = None, pre_filter = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9030ed",
   "metadata": {},
   "source": [
    "# Define Model \n",
    "- This mainly draws upon HIV project code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8392f1d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2ad051d8acf0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# class GNN(torch.nn.Module):\n",
    "#     def __init__(self, feature_size):\n",
    "#         super(GNN, self).__init__()\n",
    "#         num_classes = 2\n",
    "#         embedding_size = 2048 # from resnet  \n",
    "\n",
    "#         #define the GNN layers \n",
    "\n",
    "#         #layer 1\n",
    "#         #the first graph attention layer which will create 3*embed size embeddings for each node. This will also take care of all the message passing and aggregation\n",
    "#         self.conv1 = GATConv(feature_size, embedding_size, heads=3, dropout = 0.3)\n",
    "#         #reduce the dimensionality back\n",
    "#         self.head_transform1 = Linear(embedding_size*3, embedding_size)\n",
    "#         self.pool1 = TopKPooling(embedding_size, ratio=0.8)\n",
    "\n",
    "#         #layer 2\n",
    "#         self.conv2 = GATConv(embedding_size, embedding_size, heads=3, dropout = 0.3)\n",
    "#         self.head_transform2 = Linear(embedding_size*3, embedding_size)\n",
    "#         self.pool2 = TopKPooling(embedding_size, ratio=0.5)\n",
    "\n",
    "#         #layer 3\n",
    "#         self.conv3 = GATConv(embedding_size, embedding_size, heads=3, dropout = 0.3)\n",
    "#         self.head_transform3 = Linear(embedding_size*3, embedding_size)\n",
    "#         self.pool3 = TopKPooling(embedding_size, ratio=0.2)\n",
    "\n",
    "\n",
    "#         #linear layers - these need to be modified to match the output size? Or maybe not\n",
    "#         self.linear1 = Linear(embedding_size*2, embedding_size)\n",
    "#         self.linear2 = Linear(embedding_size, 2)\n",
    "\n",
    "#     def forward(self, x, edge_attr, edge_index, batch_index):\n",
    "#         #block 1 \n",
    "#         x = self.conv1(x, edge_index)\n",
    "#         x = self.head_transform1(x)\n",
    "\n",
    "#         x, edge_index, edge_attr, batch_index, _, _ = self.pool1(x, edge_index, None, batch_index)\n",
    "#         #graph rep. \n",
    "#         x1 = torch.cat([gmp(x, batch_index), gap(x, batch_index)], dim=1)\n",
    "#         #block 2 \n",
    "#         x = self.conv2(x, edge_index)\n",
    "#         x = self.head_transform2(x)\n",
    "\n",
    "#         x, edge_index, edge_attr, batch_index, _, _ = self.pool2(x, edge_index, None, batch_index)\n",
    "#         #graph rep. \n",
    "#         x2 = torch.cat([gmp(x, batch_index), gap(x, batch_index)], dim=1)\n",
    "#         #block 3\n",
    "#         x = self.conv3(x, edge_index)\n",
    "#         x = self.head_transform3(x)\n",
    "\n",
    "#         x, edge_index, edge_attr, batch_index, _, _ = self.pool3(x, edge_index, None, batch_index)\n",
    "#         #graph rep. \n",
    "#         x3 = torch.cat([gmp(x, batch_index), gap(x, batch_index)], dim=1)\n",
    "#         #element wise addition , and each is 2048 \n",
    "#         x = x1 + x2 + x3\n",
    "#         #output block \n",
    "#         x = self.linear1(x).relu()\n",
    "#         x = F.dropout(x, p=0.5)\n",
    "#         x = self.linear2(x)\n",
    "\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04c946ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "class simple_GNN(torch.nn.Module):\n",
    "    def __init__(self, feature_size):\n",
    "        super(simple_GNN, self).__init__()\n",
    "        \n",
    "        self.num_classes = 2 #scc or normal\n",
    "        self.embedding_size = 2048 # this is what we want the embedding to be\n",
    "        \n",
    "        self.linear1 = Linear(self.embedding_size, 128)\n",
    "        #define the GNN layers \n",
    "        \n",
    "        self.drop_edge = lambda edge_index: dropout_edge(edge_index,p=0.3)[0]\n",
    "        self.layer_norm = nn.LayerNorm(128)\n",
    "        #layer 1\n",
    "        #the first graph attention layer which will create 3*embed size embeddings for each node. This will also take care of all the message passing and aggregation\n",
    "        self.conv1 = GATConv(128, 128, heads=3, dropout = 0.3)\n",
    "        #reduce the dimensionality back\n",
    "        self.head_transform1 = Linear(256*3, 256)\n",
    "        \n",
    "        #layer 2\n",
    "        self.conv2 = GATConv(256, 256, heads=3, dropout = 0.3)\n",
    "        self.head_transform2 = Linear(256*3, 256)\n",
    "\n",
    "        #layer 3\n",
    "        self.conv3 = GATConv(256, 256, heads=3, dropout = 0.3)\n",
    "        self.head_transform3 = Linear(256*3, 256)\n",
    "        \n",
    "#         #layer 4\n",
    "#         self.conv4 = GATConv(128, 256, heads=3, dropout = 0.3)\n",
    "#         self.head_transform4 = Linear(256*3, 256)\n",
    "        \n",
    "        #linear layers - these need to be modified to match the output size? Or maybe not\n",
    "        self.linear2 = Linear(256, 64) \n",
    "        self.linear3 = Linear(64, self.num_classes) #prediction for each class\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = x \n",
    "        edge_index = edge_index\n",
    "        batch = batch \n",
    "        # downsize the embeddings\n",
    "        x = self.linear1(x).relu()\n",
    "        \n",
    "        #block 1 \n",
    "        x = self.conv1(x, edge_index) #this is does all the aggregation and message passing\n",
    "        x = self.head_transform1(x)       \n",
    "        x = self.layer_norm(x)\n",
    "        #block 2\n",
    "#         edge_index = self.drop_edge(edge_index)\n",
    "        x = self.conv2(x, edge_index) \n",
    "        x = self.head_transform2(x)      \n",
    "        x = self.layer_norm(x)\n",
    "\n",
    "        #block 3\n",
    "#         edge_index = self.drop_edge(edge_index)\n",
    "        x = self.conv3(x, edge_index) #this is does all the aggregation and message passing\n",
    "        x = self.head_transform3(x)   \n",
    "        x = self.layer_norm(x)\n",
    "\n",
    "#         #block 4\n",
    "# #         edge_index = self.drop_edge(edge_index)\n",
    "#         x = self.conv4(x, edge_index) \n",
    "#         x = self.head_transform4(x)   \n",
    "        \n",
    "        #output block \n",
    "        x = self.linear2(x).relu()\n",
    "        x = F.dropout(x, p=0.5)\n",
    "        x = self.linear3(x)\n",
    "        \n",
    "#         print(\"Inside model, after all computations\", torch.cuda.memory_summary(device=None, abbreviated=False)) #bulk of the memory is used here, somehow\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02ee440a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sage_GNN(torch.nn.Module):\n",
    "    def __init__(self, feature_size):\n",
    "        super(sage_GNN, self).__init__()\n",
    "        \n",
    "        self.num_classes = 2 #scc or normal\n",
    "        self.embedding_size = 2048 # this is what we want the embedding to be\n",
    "        \n",
    "        self.linear1 = Linear(2048, 512)\n",
    "\n",
    "        #define the GNN layers \n",
    "    \n",
    "        #layer 1\n",
    "        self.conv1 = SAGEConv(512, 128)\n",
    "        \n",
    "        #layer 2\n",
    "        self.conv2 = SAGEConv(128, 128)\n",
    "           \n",
    "        #layer 3\n",
    "        self.conv3 = SAGEConv(128,128)\n",
    "\n",
    "        self.linear2 = Linear(128, 64) \n",
    "        self.linear3 = Linear(64, 2)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.linear1(x).relu()\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "018eedc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class simple_NN(torch.nn.Module):\n",
    "    def __init__(self, embedding_size):\n",
    "        super(simple_NN, self).__init__()\n",
    "        \n",
    "\n",
    "        self.linear = Linear(2048, 512) \n",
    "        self.linear2 = Linear(512, 64)\n",
    "        self.linear3 = Linear(64, 2)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        \n",
    "        x = F.relu(self.linear(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = F.dropout(x, p=0.5)\n",
    "        x = self.linear3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f0ef05",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ade768a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_features = 2048\n",
    "\n",
    "# # device_ids = [0, 1]\n",
    "# model = simple_GNN(2048)\n",
    "# # model= nn.DataParallel(model, device_ids = device_ids)\n",
    "# model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd55029e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6345fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #loss and optimizer \n",
    "# import torch.optim as optim\n",
    "# import torchvision.ops.focal_loss\n",
    "\n",
    "# # loss_fn = torchvision.ops.focal_loss.sigmoid_focal_loss\n",
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "# opt = optim.Adam(model.parameters(), lr=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e2eb630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #prepare training \n",
    "# from torch_geometric.data import DataLoader\n",
    "\n",
    "# # train_loader = DataLoader(training_data, batch_size=1, shuffle=True)\n",
    "# # val_loader = DataLoader(val_data, batch_size=1, shuffle=True)\n",
    "# # test_loader = DataLoader(testing_data, batch_size=1, shuffle=True)\n",
    "\n",
    "# # num_epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f30c1a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# softmax = nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28544066",
   "metadata": {},
   "source": [
    "# Inductive Model Training on Gokul Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01188559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(num_epochs):\n",
    "#     #training portion\n",
    "#     model.train()\n",
    "#     epoch_loss = []\n",
    "#     for data in tqdm(train_loader):\n",
    "#         #get graph and the relevant stuff\n",
    "#         graph = data[0]\n",
    "#         x = data[0].x\n",
    "#         edge_index = data[0].edge_index\n",
    "#         y = data[0].y\n",
    "        \n",
    "#         #move to device\n",
    "#         x = x.to(device)\n",
    "#         edge_index = edge_index.to(device)\n",
    "#         y = y.to(device)\n",
    "\n",
    "#         #get predictions \n",
    "#         logits = model(x, edge_index)\n",
    "#         loss = loss_fn(logits, y) #for CE\n",
    "\n",
    "#         epoch_loss.append(loss.item())\n",
    "\n",
    "#         opt.zero_grad()\n",
    "#         loss.backward()\n",
    "#         opt.step()\n",
    "#     #now find the average training loss for this epoch \n",
    "#     epoch_loss = sum(epoch_loss)/len(epoch_loss)\n",
    "#     print(\"Epoch :%d. Epoch loss: %f\" %(epoch, epoch_loss))    \n",
    "#     #validation portion\n",
    "#     validation_correct = 0\n",
    "#     validation_total = 0\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         for data in tqdm(val_loader):\n",
    "#             #get graph\n",
    "#             graph = data[0]\n",
    "#             x = data[0].x\n",
    "#             edge_index = data[0].edge_index\n",
    "#             y = data[0].y\n",
    "        \n",
    "#             #move to device\n",
    "#             x = x.to(device)\n",
    "#             edge_index = edge_index.to(device)\n",
    "#             y = y.to(device)\n",
    "\n",
    "#             #get predictions \n",
    "#             logits = model(x, edge_index)\n",
    "#             #get them into label predictions\n",
    "#             _, indices = torch.max(logits, dim=1)\n",
    "# #             print(indices)\n",
    "#             validation_correct += sum(indices == y).item()\n",
    "#             validation_total += len(y)\n",
    "# #             print(\"Accuracy on this graph's val set\", sum(indices == y).item()/len(y))\n",
    "# #             print(\"SCC percent\", sum(y == 1).item()/len(y))\n",
    "    \n",
    "#     print(\"Epoch :%d. Validation accuracy: %f\" %(epoch, validation_correct/validation_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1172f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  #test portion\n",
    "# test_correct = 0\n",
    "# test_total = 0\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     for data in tqdm(data_loader):\n",
    "#         #get graph\n",
    "#         graph = data[0]\n",
    "#         x = graph.x \n",
    "#         edge_index = graph.edge_index\n",
    "#         y = graph.y \n",
    "#         #move to device\n",
    "#         x = x.to(device)\n",
    "#         edge_index = edge_index.to(device)\n",
    "#         y = y.to(device)\n",
    "#         #get masks\n",
    "#         test_mask = data[3].T.reshape([data[3].T.shape[0]])\n",
    "\n",
    "#         #get predictions \n",
    "#         logits = model(x, edge_index)\n",
    "#         #get them into label predictions\n",
    "#         _, indices = torch.max(logits, dim=1)\n",
    "#         print(1 in indices)\n",
    "#         test_correct += sum(indices[test_mask] == y[test_mask]).item()\n",
    "#         test_total += sum(test_mask == True).item()\n",
    "\n",
    "# print(\"Test accuracy: %f\" %(test_correct/test_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e20b47",
   "metadata": {},
   "source": [
    "# Training With Sophie Data\n",
    "- Here, use inductive training \n",
    "- split the ids themselves into different categories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12204726",
   "metadata": {},
   "outputs": [],
   "source": [
    "sophie_data = pd.read_pickle(\"/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/users/Sophie_Chen/graph_dataset/graph_dataset_modified.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cceb1cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'109_A1c_ASAP_tumor_map': [[Data(x=[41295, 2048], edge_index=[2, 204923], y=[41295], pos=[41295, 2], train_mask=[41295], val_mask=[41295], test_mask=[41295])]],\n",
       " '10_A1a_ASAP_tumor_map': [[Data(x=[16468, 2048], edge_index=[2, 80814], y=[16468], pos=[16468, 2], train_mask=[16468], val_mask=[16468], test_mask=[16468])]],\n",
       " '10_A1b_ASAP_tumor_map': [[Data(x=[17010, 2048], edge_index=[2, 83576], y=[17010], pos=[17010, 2], train_mask=[17010], val_mask=[17010], test_mask=[17010])]],\n",
       " '10_A2b_ASAP_tumor_map': [[Data(x=[18422, 2048], edge_index=[2, 90600], y=[18422], pos=[18422, 2], train_mask=[18422], val_mask=[18422], test_mask=[18422])]],\n",
       " '110_A2b_ASAP_tumor_map': [[Data(x=[17856, 2048], edge_index=[2, 87348], y=[17856], pos=[17856, 2], train_mask=[17856], val_mask=[17856], test_mask=[17856])]],\n",
       " '112_a_ASAP_tumor_map': [[Data(x=[6217, 2048], edge_index=[2, 29695], y=[6217], pos=[6217, 2], train_mask=[6217], val_mask=[6217], test_mask=[6217])]],\n",
       " '112_b_ASAP_tumor_map': [[Data(x=[6828, 2048], edge_index=[2, 32550], y=[6828], pos=[6828, 2], train_mask=[6828], val_mask=[6828], test_mask=[6828])]],\n",
       " '123_A1a_ASAP_tumor_map': [[Data(x=[15989, 2048], edge_index=[2, 76693], y=[15989], pos=[15989, 2], train_mask=[15989], val_mask=[15989], test_mask=[15989])]],\n",
       " '12_A1c_ASAP_tumor_map': [[Data(x=[20897, 2048], edge_index=[2, 102667], y=[20897], pos=[20897, 2], train_mask=[20897], val_mask=[20897], test_mask=[20897])]],\n",
       " '14_A1b_ASAP_tumor_map': [[Data(x=[14594, 2048], edge_index=[2, 70526], y=[14594], pos=[14594, 2], train_mask=[14594], val_mask=[14594], test_mask=[14594])]],\n",
       " '14_A2b_ASAP_tumor_map': [[Data(x=[14780, 2048], edge_index=[2, 70200], y=[14780], pos=[14780, 2], train_mask=[14780], val_mask=[14780], test_mask=[14780])]],\n",
       " '169_A2b_ASAP_tumor_map': [[Data(x=[15550, 2048], edge_index=[2, 76556], y=[15550], pos=[15550, 2], train_mask=[15550], val_mask=[15550], test_mask=[15550])]],\n",
       " '270_A1b_ASAP_tumor_map': [[Data(x=[21371, 2048], edge_index=[2, 105107], y=[21371], pos=[21371, 2], train_mask=[21371], val_mask=[21371], test_mask=[21371])]],\n",
       " '270_A1d_ASAP_tumor_map': [[Data(x=[20725, 2048], edge_index=[2, 102197], y=[20725], pos=[20725, 2], train_mask=[20725], val_mask=[20725], test_mask=[20725])]],\n",
       " '270_A1e_ASAP_tumor_map': [[Data(x=[20591, 2048], edge_index=[2, 101633], y=[20591], pos=[20591, 2], train_mask=[20591], val_mask=[20591], test_mask=[20591])]],\n",
       " '270_A2b_ASAP_tumor_map': [[Data(x=[19129, 2048], edge_index=[2, 94311], y=[19129], pos=[19129, 2], train_mask=[19129], val_mask=[19129], test_mask=[19129])]],\n",
       " '270_A2f_ASAP_tumor_map': [[Data(x=[7420, 2048], edge_index=[2, 36228], y=[7420], pos=[7420, 2], train_mask=[7420], val_mask=[7420], test_mask=[7420])]],\n",
       " '281_A1d_ASAP_tumor_map': [[Data(x=[13297, 2048], edge_index=[2, 65497], y=[13297], pos=[13297, 2], train_mask=[13297], val_mask=[13297], test_mask=[13297])]],\n",
       " '281_A1f_ASAP_tumor_map': [[Data(x=[14385, 2048], edge_index=[2, 70949], y=[14385], pos=[14385, 2], train_mask=[14385], val_mask=[14385], test_mask=[14385])]],\n",
       " '281_A2eX_ASAP_tumor_map': [[Data(x=[13449, 2048], edge_index=[2, 66323], y=[13449], pos=[13449, 2], train_mask=[13449], val_mask=[13449], test_mask=[13449])]],\n",
       " '311_A2c_ASAP_tumor_map': [[Data(x=[12337, 2048], edge_index=[2, 60653], y=[12337], pos=[12337, 2], train_mask=[12337], val_mask=[12337], test_mask=[12337])]],\n",
       " '327_A1a_ASAP_tumor_map': [[Data(x=[26042, 2048], edge_index=[2, 128022], y=[26042], pos=[26042, 2], train_mask=[26042], val_mask=[26042], test_mask=[26042])]],\n",
       " '327_A1d_ASAP_tumor_map': [[Data(x=[16320, 2048], edge_index=[2, 80024], y=[16320], pos=[16320, 2], train_mask=[16320], val_mask=[16320], test_mask=[16320])]],\n",
       " '327_B1c_ASAP_tumor_map': [[Data(x=[38507, 2048], edge_index=[2, 190173], y=[38507], pos=[38507, 2], train_mask=[38507], val_mask=[38507], test_mask=[38507])]],\n",
       " '341_a_ASAP_tumor_map': [[Data(x=[9379, 2048], edge_index=[2, 45857], y=[9379], pos=[9379, 2], train_mask=[9379], val_mask=[9379], test_mask=[9379])]],\n",
       " '341_b_ASAP_tumor_map': [[Data(x=[6770, 2048], edge_index=[2, 32990], y=[6770], pos=[6770, 2], train_mask=[6770], val_mask=[6770], test_mask=[6770])]],\n",
       " '342_a_ASAP_tumor_map': [[Data(x=[6217, 2048], edge_index=[2, 29695], y=[6217], pos=[6217, 2], train_mask=[6217], val_mask=[6217], test_mask=[6217])]],\n",
       " '342_b_ASAP_tumor_map': [[Data(x=[6828, 2048], edge_index=[2, 32550], y=[6828], pos=[6828, 2], train_mask=[6828], val_mask=[6828], test_mask=[6828])]],\n",
       " '343_a_ASAP_tumor_map': [[Data(x=[17027, 2048], edge_index=[2, 81229], y=[17027], pos=[17027, 2], train_mask=[17027], val_mask=[17027], test_mask=[17027])]],\n",
       " '343_b_ASAP_tumor_map': [[Data(x=[22341, 2048], edge_index=[2, 109241], y=[22341], pos=[22341, 2], train_mask=[22341], val_mask=[22341], test_mask=[22341])]],\n",
       " '343_c_ASAP_tumor_map': [[Data(x=[23215, 2048], edge_index=[2, 113369], y=[23215], pos=[23215, 2], train_mask=[23215], val_mask=[23215], test_mask=[23215])]],\n",
       " '343_d_ASAP_tumor_map': [[Data(x=[23840, 2048], edge_index=[2, 116080], y=[23840], pos=[23840, 2], train_mask=[23840], val_mask=[23840], test_mask=[23840])]],\n",
       " '344_a_ASAP_tumor_map': [[Data(x=[9984, 2048], edge_index=[2, 47972], y=[9984], pos=[9984, 2], train_mask=[9984], val_mask=[9984], test_mask=[9984])]],\n",
       " '344_b_ASAP_tumor_map': [[Data(x=[10341, 2048], edge_index=[2, 50033], y=[10341], pos=[10341, 2], train_mask=[10341], val_mask=[10341], test_mask=[10341])]],\n",
       " '345_a_ASAP_tumor_map': [[Data(x=[14538, 2048], edge_index=[2, 71502], y=[14538], pos=[14538, 2], train_mask=[14538], val_mask=[14538], test_mask=[14538])]],\n",
       " '345_b_ASAP_tumor_map': [[Data(x=[14814, 2048], edge_index=[2, 72786], y=[14814], pos=[14814, 2], train_mask=[14814], val_mask=[14814], test_mask=[14814])]],\n",
       " '346_a_ASAP_tumor_map': [[Data(x=[10946, 2048], edge_index=[2, 51998], y=[10946], pos=[10946, 2], train_mask=[10946], val_mask=[10946], test_mask=[10946])]],\n",
       " '346_b_ASAP_tumor_map': [[Data(x=[11288, 2048], edge_index=[2, 53376], y=[11288], pos=[11288, 2], train_mask=[11288], val_mask=[11288], test_mask=[11288])]],\n",
       " '350_A1a_ASAP_tumor_map': [[Data(x=[16028, 2048], edge_index=[2, 77616], y=[16028], pos=[16028, 2], train_mask=[16028], val_mask=[16028], test_mask=[16028])]],\n",
       " '350_A1b_ASAP_tumor_map': [[Data(x=[19397, 2048], edge_index=[2, 95109], y=[19397], pos=[19397, 2], train_mask=[19397], val_mask=[19397], test_mask=[19397])]],\n",
       " '350_A1c_ASAP_tumor_map': [[Data(x=[18496, 2048], edge_index=[2, 90860], y=[18496], pos=[18496, 2], train_mask=[18496], val_mask=[18496], test_mask=[18496])]],\n",
       " '350_A1d_ASAP_tumor_map': [[Data(x=[16841, 2048], edge_index=[2, 82713], y=[16841], pos=[16841, 2], train_mask=[16841], val_mask=[16841], test_mask=[16841])]],\n",
       " '350_A1e_ASAP_tumor_map': [[Data(x=[14432, 2048], edge_index=[2, 70866], y=[14432], pos=[14432, 2], train_mask=[14432], val_mask=[14432], test_mask=[14432])]],\n",
       " '351_A2b_ASAP_tumor_map': [[Data(x=[10278, 2048], edge_index=[2, 49952], y=[10278], pos=[10278, 2], train_mask=[10278], val_mask=[10278], test_mask=[10278])]],\n",
       " '352_A1d_ASAP_tumor_map': [[Data(x=[21248, 2048], edge_index=[2, 104224], y=[21248], pos=[21248, 2], train_mask=[21248], val_mask=[21248], test_mask=[21248])]],\n",
       " '352_A1e_ASAP_tumor_map': [[Data(x=[20685, 2048], edge_index=[2, 101469], y=[20685], pos=[20685, 2], train_mask=[20685], val_mask=[20685], test_mask=[20685])]],\n",
       " '352_A1g_ASAP_tumor_map': [[Data(x=[17017, 2048], edge_index=[2, 83333], y=[17017], pos=[17017, 2], train_mask=[17017], val_mask=[17017], test_mask=[17017])]],\n",
       " '352_A1h_ASAP_tumor_map': [[Data(x=[14807, 2048], edge_index=[2, 72129], y=[14807], pos=[14807, 2], train_mask=[14807], val_mask=[14807], test_mask=[14807])]],\n",
       " '352_A1i_ASAP_tumor_map': [[Data(x=[14577, 2048], edge_index=[2, 71183], y=[14577], pos=[14577, 2], train_mask=[14577], val_mask=[14577], test_mask=[14577])]],\n",
       " '353_A2b_ASAP_tumor_map': [[Data(x=[17856, 2048], edge_index=[2, 87348], y=[17856], pos=[17856, 2], train_mask=[17856], val_mask=[17856], test_mask=[17856])]],\n",
       " '354_A1b_ASAP_tumor_map': [[Data(x=[13521, 2048], edge_index=[2, 65591], y=[13521], pos=[13521, 2], train_mask=[13521], val_mask=[13521], test_mask=[13521])]],\n",
       " '354_A1c_ASAP_tumor_map': [[Data(x=[15681, 2048], edge_index=[2, 76283], y=[15681], pos=[15681, 2], train_mask=[15681], val_mask=[15681], test_mask=[15681])]],\n",
       " '354_A1d_ASAP_tumor_map': [[Data(x=[18198, 2048], edge_index=[2, 89710], y=[18198], pos=[18198, 2], train_mask=[18198], val_mask=[18198], test_mask=[18198])]],\n",
       " '354_A3a_ASAP_tumor_map': [[Data(x=[13247, 2048], edge_index=[2, 62619], y=[13247], pos=[13247, 2], train_mask=[13247], val_mask=[13247], test_mask=[13247])]],\n",
       " '354_A3b_ASAP_tumor_map': [[Data(x=[21912, 2048], edge_index=[2, 106228], y=[21912], pos=[21912, 2], train_mask=[21912], val_mask=[21912], test_mask=[21912])]],\n",
       " '354_A3c_ASAP_tumor_map': [[Data(x=[25688, 2048], edge_index=[2, 124634], y=[25688], pos=[25688, 2], train_mask=[25688], val_mask=[25688], test_mask=[25688])]],\n",
       " '354_D1b_ASAP_tumor_map': [[Data(x=[15035, 2048], edge_index=[2, 72861], y=[15035], pos=[15035, 2], train_mask=[15035], val_mask=[15035], test_mask=[15035])]],\n",
       " '355_A1d_ASAP_tumor_map': [[Data(x=[8427, 2048], edge_index=[2, 41089], y=[8427], pos=[8427, 2], train_mask=[8427], val_mask=[8427], test_mask=[8427])]],\n",
       " '356_A1b_ASAP_tumor_map': [[Data(x=[10764, 2048], edge_index=[2, 52644], y=[10764], pos=[10764, 2], train_mask=[10764], val_mask=[10764], test_mask=[10764])]],\n",
       " '358_A1a_ASAP_tumor_map': [[Data(x=[15989, 2048], edge_index=[2, 76693], y=[15989], pos=[15989, 2], train_mask=[15989], val_mask=[15989], test_mask=[15989])]],\n",
       " '358_A1b_ASAP_tumor_map': [[Data(x=[18501, 2048], edge_index=[2, 89751], y=[18501], pos=[18501, 2], train_mask=[18501], val_mask=[18501], test_mask=[18501])]],\n",
       " '361_a_ASAP_tumor_map': [[Data(x=[16753, 2048], edge_index=[2, 81581], y=[16753], pos=[16753, 2], train_mask=[16753], val_mask=[16753], test_mask=[16753])]],\n",
       " '361_b_ASAP_tumor_map': [[Data(x=[21629, 2048], edge_index=[2, 106179], y=[21629], pos=[21629, 2], train_mask=[21629], val_mask=[21629], test_mask=[21629])]],\n",
       " '362_A1a_ASAP_tumor_map': [[Data(x=[19610, 2048], edge_index=[2, 95728], y=[19610], pos=[19610, 2], train_mask=[19610], val_mask=[19610], test_mask=[19610])]],\n",
       " '362_A1b_ASAP_tumor_map': [[Data(x=[21227, 2048], edge_index=[2, 104153], y=[21227], pos=[21227, 2], train_mask=[21227], val_mask=[21227], test_mask=[21227])]],\n",
       " '362_A1c_ASAP_tumor_map': [[Data(x=[18796, 2048], edge_index=[2, 92020], y=[18796], pos=[18796, 2], train_mask=[18796], val_mask=[18796], test_mask=[18796])]],\n",
       " '363_A1b_ASAP_tumor_map': [[Data(x=[20782, 2048], edge_index=[2, 102188], y=[20782], pos=[20782, 2], train_mask=[20782], val_mask=[20782], test_mask=[20782])]],\n",
       " '363_A1c_ASAP_tumor_map': [[Data(x=[20598, 2048], edge_index=[2, 101562], y=[20598], pos=[20598, 2], train_mask=[20598], val_mask=[20598], test_mask=[20598])]],\n",
       " '363_A2b_ASAP_tumor_map': [[Data(x=[25273, 2048], edge_index=[2, 124205], y=[25273], pos=[25273, 2], train_mask=[25273], val_mask=[25273], test_mask=[25273])]],\n",
       " '363_A3b_ASAP_tumor_map': [[Data(x=[23471, 2048], edge_index=[2, 115461], y=[23471], pos=[23471, 2], train_mask=[23471], val_mask=[23471], test_mask=[23471])]],\n",
       " '364_A1b_ASAP_tumor_map': [[Data(x=[22247, 2048], edge_index=[2, 108537], y=[22247], pos=[22247, 2], train_mask=[22247], val_mask=[22247], test_mask=[22247])]],\n",
       " '364_A2b_ASAP_tumor_map': [[Data(x=[22599, 2048], edge_index=[2, 108635], y=[22599], pos=[22599, 2], train_mask=[22599], val_mask=[22599], test_mask=[22599])]],\n",
       " '364_A4b_ASAP_tumor_map': [[Data(x=[21996, 2048], edge_index=[2, 106260], y=[21996], pos=[21996, 2], train_mask=[21996], val_mask=[21996], test_mask=[21996])]],\n",
       " '365_A1b_ASAP_tumor_map': [[Data(x=[19532, 2048], edge_index=[2, 95670], y=[19532], pos=[19532, 2], train_mask=[19532], val_mask=[19532], test_mask=[19532])]],\n",
       " '365_A2b_ASAP_tumor_map': [[Data(x=[18297, 2048], edge_index=[2, 89529], y=[18297], pos=[18297, 2], train_mask=[18297], val_mask=[18297], test_mask=[18297])]],\n",
       " '366_A1a_ASAP_tumor_map': [[Data(x=[13836, 2048], edge_index=[2, 66980], y=[13836], pos=[13836, 2], train_mask=[13836], val_mask=[13836], test_mask=[13836])]],\n",
       " '366_A1b_ASAP_tumor_map': [[Data(x=[16659, 2048], edge_index=[2, 81447], y=[16659], pos=[16659, 2], train_mask=[16659], val_mask=[16659], test_mask=[16659])]],\n",
       " '366_A1c_ASAP_tumor_map': [[Data(x=[17016, 2048], edge_index=[2, 83338], y=[17016], pos=[17016, 2], train_mask=[17016], val_mask=[17016], test_mask=[17016])]],\n",
       " '367_A2b_ASAP_tumor_map': [[Data(x=[11172, 2048], edge_index=[2, 54330], y=[11172], pos=[11172, 2], train_mask=[11172], val_mask=[11172], test_mask=[11172])]],\n",
       " '368_A1b_ASAP_tumor_map': [[Data(x=[29007, 2048], edge_index=[2, 142163], y=[29007], pos=[29007, 2], train_mask=[29007], val_mask=[29007], test_mask=[29007])]],\n",
       " '368_A1c_ASAP_tumor_map': [[Data(x=[31870, 2048], edge_index=[2, 156436], y=[31870], pos=[31870, 2], train_mask=[31870], val_mask=[31870], test_mask=[31870])]],\n",
       " '368_A1d_ASAP_tumor_map': [[Data(x=[34134, 2048], edge_index=[2, 168360], y=[34134], pos=[34134, 2], train_mask=[34134], val_mask=[34134], test_mask=[34134])]],\n",
       " '369_A1b_ASAP_tumor_map': [[Data(x=[14550, 2048], edge_index=[2, 70924], y=[14550], pos=[14550, 2], train_mask=[14550], val_mask=[14550], test_mask=[14550])]],\n",
       " '369_A1c_ASAP_tumor_map': [[Data(x=[12994, 2048], edge_index=[2, 63080], y=[12994], pos=[12994, 2], train_mask=[12994], val_mask=[12994], test_mask=[12994])]],\n",
       " '369_A2b_ASAP_tumor_map': [[Data(x=[14285, 2048], edge_index=[2, 69153], y=[14285], pos=[14285, 2], train_mask=[14285], val_mask=[14285], test_mask=[14285])]],\n",
       " '370_A1b_ASAP_tumor_map': [[Data(x=[10352, 2048], edge_index=[2, 50610], y=[10352], pos=[10352, 2], train_mask=[10352], val_mask=[10352], test_mask=[10352])]],\n",
       " '370_A2a_ASAP_tumor_map': [[Data(x=[8894, 2048], edge_index=[2, 43366], y=[8894], pos=[8894, 2], train_mask=[8894], val_mask=[8894], test_mask=[8894])]],\n",
       " '370_A2b_ASAP_tumor_map': [[Data(x=[9622, 2048], edge_index=[2, 47192], y=[9622], pos=[9622, 2], train_mask=[9622], val_mask=[9622], test_mask=[9622])]],\n",
       " '37_A2d_ASAP_tumor_map': [[Data(x=[15415, 2048], edge_index=[2, 73359], y=[15415], pos=[15415, 2], train_mask=[15415], val_mask=[15415], test_mask=[15415])]],\n",
       " '61_A1a_ASAP_tumor_map': [[Data(x=[10242, 2048], edge_index=[2, 49648], y=[10242], pos=[10242, 2], train_mask=[10242], val_mask=[10242], test_mask=[10242])]],\n",
       " '61_B1a_ASAP_tumor_map': [[Data(x=[9546, 2048], edge_index=[2, 46092], y=[9546], pos=[9546, 2], train_mask=[9546], val_mask=[9546], test_mask=[9546])]],\n",
       " '70_A2b_ASAP_tumor_map': [[Data(x=[10278, 2048], edge_index=[2, 49952], y=[10278], pos=[10278, 2], train_mask=[10278], val_mask=[10278], test_mask=[10278])]],\n",
       " '7_A1c_ASAP_tumor_map': [[Data(x=[18496, 2048], edge_index=[2, 90860], y=[18496], pos=[18496, 2], train_mask=[18496], val_mask=[18496], test_mask=[18496])]],\n",
       " '7_A1d_ASAP_tumor_map': [[Data(x=[16841, 2048], edge_index=[2, 82713], y=[16841], pos=[16841, 2], train_mask=[16841], val_mask=[16841], test_mask=[16841])]],\n",
       " '7_A1e_ASAP_tumor_map': [[Data(x=[14432, 2048], edge_index=[2, 70866], y=[14432], pos=[14432, 2], train_mask=[14432], val_mask=[14432], test_mask=[14432])]]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sophie_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "972b76c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sophie_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "709d206b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ids = []\n",
    "for id in sophie_data:\n",
    "    dataset_ids.append(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58c6f509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8276a878",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids, test_ids = train_test_split(dataset_ids, train_size = .9, test_size = .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7f17a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85 10\n"
     ]
    }
   ],
   "source": [
    "print(len(train_ids), len(test_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06014a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids, val_ids = train_test_split(train_ids, train_size = .9, test_size = .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c1aa26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76 9\n"
     ]
    }
   ],
   "source": [
    "print(len(train_ids), len(val_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b353ca6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76 10 9\n"
     ]
    }
   ],
   "source": [
    "print(len(train_ids), len(test_ids), len(val_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "413779e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here collect all of the graphs - expect sophie's data set doesn't have test sets, only test masks\n",
    "\n",
    "train_dataset = []\n",
    "\n",
    "for id in train_ids:\n",
    "    train_dataset.append(sophie_data[id][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "275d7ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = []\n",
    "\n",
    "for id in val_ids:\n",
    "    val_dataset.append(sophie_data[id][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "06ee169c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = []\n",
    "\n",
    "for id in test_ids:\n",
    "    test_dataset.append(sophie_data[id][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6a029f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dartfs-hpc/rc/home/9/f003xr9/anaconda3/envs/jupyter_ultimate/lib/python3.7/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=5)\n",
    "val_loader = DataLoader(val_dataset, batch_size=5)\n",
    "test_loader = DataLoader(test_dataset, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2e2b7d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 2 2\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader), len(val_loader), len(test_loader))\n",
    "num_epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "66dca1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 2048\n",
    "\n",
    "# device_ids = [0, 1]\n",
    "model = simple_GNN(2048)\n",
    "# model= nn.DataParallel(model, device_ids = device_ids)\n",
    "model = model.to(device)\n",
    "\n",
    "#loss and optimizer \n",
    "# loss_fn = torchvision.ops.focal_loss.sigmoid_focal_loss\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "#optim and scheduler\n",
    "opt = optim.Adam(model.parameters(), lr=1e-5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(opt, factor = 0.1, patience = 5, verbose = True)\n",
    "softmax = nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "993ad0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossess = []\n",
    "rocs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ceb07e",
   "metadata": {},
   "source": [
    "# Experiment notes\n",
    "- So 2 layers seems to work well with fairly small embedding sizes\n",
    "- increasing embed size doesn't seem to improve performance \n",
    "- 1e-5 works well with CE\n",
    "- simple NN baseline easily achieves .70 AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9811ab2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:04<00:00,  3.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :0. Epoch loss: 0.566635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  6.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :0. Validation AUC-ROC: 0.472387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:04<00:00,  3.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :1. Epoch loss: 0.475673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  6.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :1. Validation AUC-ROC: 0.474952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:04<00:00,  3.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :2. Epoch loss: 0.463837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  6.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :2. Validation AUC-ROC: 0.471819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:04<00:00,  3.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :3. Epoch loss: 0.450095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :3. Validation AUC-ROC: 0.489778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:04<00:00,  3.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :4. Epoch loss: 0.433686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  6.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :4. Validation AUC-ROC: 0.506980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:04<00:00,  3.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :5. Epoch loss: 0.414155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :5. Validation AUC-ROC: 0.535790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:04<00:00,  3.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :6. Epoch loss: 0.393314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  6.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :6. Validation AUC-ROC: 0.563334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:04<00:00,  3.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :7. Epoch loss: 0.374326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  6.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :7. Validation AUC-ROC: 0.577998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:04<00:00,  3.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :8. Epoch loss: 0.360694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  6.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :8. Validation AUC-ROC: 0.581829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:04<00:00,  3.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :9. Epoch loss: 0.351305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  6.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :9. Validation AUC-ROC: 0.589235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:04<00:00,  3.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :10. Epoch loss: 0.345530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  6.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :10. Validation AUC-ROC: 0.595017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:04<00:00,  3.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :11. Epoch loss: 0.341768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  6.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :11. Validation AUC-ROC: 0.596454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:04<00:00,  3.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :12. Epoch loss: 0.338881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  6.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :12. Validation AUC-ROC: 0.601472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|██████████████████████████████████████████████████████████████████████████████████████████████▌                                                                         | 9/16 [00:02<00:01,  3.80it/s]"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    #training portion\n",
    "    model.train()\n",
    "    epoch_loss = []\n",
    "    for data in tqdm(train_loader):\n",
    "        #get graph and the relevant stuff\n",
    "        graph = data\n",
    "        x = data.x\n",
    "        edge_index = data.edge_index\n",
    "        y = data.y\n",
    "        batch = data.batch \n",
    "        \n",
    "        #move to device\n",
    "        x = x.to(device)\n",
    "        edge_index = edge_index.to(device)\n",
    "        y = y.to(device)\n",
    "        batch = batch.to(device)\n",
    "        #get predictions \n",
    "        logits = model(x, edge_index, batch) #for CE - CE takes logics \n",
    "#         scores = softmax(model(x, edge_index, batch))[:, 1] # for FL - takes the class prob\n",
    "        loss = loss_fn(logits, y) #for CE\n",
    "#         loss = loss_fn(scores, y.float()).sum() #for focal loss\n",
    "        epoch_loss.append(loss.item())\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    \n",
    "    #now find the average training loss for this epoch \n",
    "    epoch_loss = sum(epoch_loss)/len(epoch_loss)\n",
    "    lossess.append(epoch_loss) #append to master array \n",
    "    print(\"Epoch :%d. Epoch loss: %f\" %(epoch, epoch_loss)) \n",
    "    \n",
    "    scheduler.step(epoch_loss) #show the scheduler the epoch loss and adjust lr accordingly\n",
    "    \n",
    "    \n",
    "    #validation portion\n",
    "    probabilities = torch.Tensor([])\n",
    "    ground_truth = torch.Tensor([])\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(val_loader):\n",
    "            #get graph\n",
    "            graph = data\n",
    "            x = graph.x \n",
    "            edge_index = graph.edge_index\n",
    "            y = graph.y \n",
    "            batch = graph.batch\n",
    "            \n",
    "            #move to device\n",
    "            x = x.to(device)\n",
    "            edge_index = edge_index.to(device)\n",
    "            y = y.to(device)\n",
    "            batch = batch.to(device)\n",
    "            \n",
    "            #find the probs\n",
    "            scores = softmax(model(x, edge_index, batch))\n",
    "\n",
    "            #move to cpu\n",
    "            scores = scores.detach().cpu()\n",
    "            y = y.detach().cpu()\n",
    "\n",
    "            #concat them \n",
    "            probabilities = torch.cat((probabilities, scores))\n",
    "            ground_truth = torch.cat((ground_truth, y))\n",
    "    roc = roc_auc_score(ground_truth, probabilities[:, 1])\n",
    "    rocs.append(roc) #add to ROC master array \n",
    "    print(\"Epoch :%d. Validation AUC-ROC: %f\" %(epoch, roc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5d6c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test portion\n",
    "    \n",
    "probabilities = torch.Tensor([])\n",
    "ground_truth = torch.Tensor([])\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(test_loader):\n",
    "        #get graph\n",
    "        graph = data\n",
    "        x = graph.x \n",
    "        edge_index = graph.edge_index\n",
    "        y = graph.y \n",
    "        batch = graph.batch\n",
    "        #move to device\n",
    "        x = x.to(device)\n",
    "        edge_index = edge_index.to(device)\n",
    "        y = y.to(device)\n",
    "        batch = batch.to(device)\n",
    "        #find the probs\n",
    "        scores = softmax(model(x, edge_index, batch))\n",
    "        \n",
    "        #move to cpu\n",
    "        scores = scores.detach().cpu()\n",
    "        y = y.detach().cpu()\n",
    "        \n",
    "        #concat them \n",
    "        probabilities = torch.cat((probabilities, scores))\n",
    "        ground_truth = torch.cat((ground_truth, y))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "988ba80b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8690, 0.1310],\n",
       "        [0.8424, 0.1576],\n",
       "        [0.8374, 0.1626],\n",
       "        ...,\n",
       "        [0.8075, 0.1925],\n",
       "        [0.7344, 0.2656],\n",
       "        [0.6710, 0.3290]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f1f72d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48975056626792746"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict the whole test cohort AUC-ROC\n",
    "\n",
    "roc_auc_score(ground_truth, probabilities[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "60edaaab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#from sophie's code - viz. the curve \n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# fpr and tpr of all thresohlds\n",
    "true = ground_truth\n",
    "preds = probabilities[:, 1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(true, preds)\n",
    "\n",
    "#get the metrics \n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "#plot\n",
    "plt.title('Test Cohort-wide AUC-ROC')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddd2b8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Dec 24 02:12:11 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:18:00.0 Off |                    0 |\n",
      "| N/A   37C    P0    54W / 300W |   3046MiB / 32768MiB |      0%   E. Process |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  Off  | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    52W / 300W |    780MiB / 32768MiB |      0%   E. Process |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  Off  | 00000000:86:00.0 Off |                    0 |\n",
      "| N/A   30C    P0    41W / 300W |      3MiB / 32768MiB |      0%   E. Process |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  Off  | 00000000:AF:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    39W / 300W |      3MiB / 32768MiB |      0%   E. Process |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     18039      C   ...nda3/envs/hiss/bin/python     3043MiB |\n",
      "|    1   N/A  N/A     47354      C   ...pyter_ultimate/bin/python      777MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6d91140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a925531",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_ultimate",
   "language": "python",
   "name": "jupyter_ultimate"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
