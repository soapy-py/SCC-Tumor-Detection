{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8956b385",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/users/Gokul_Srinivasan/anaconda3/envs/jupyter-ultimate/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch \n",
    "from tqdm import tqdm \n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob, os, pickle\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "import dgl\n",
    "from torch_geometric.utils import dropout_edge\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torch.optim as optim\n",
    "import torchvision.ops.focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6ecc5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F \n",
    "from torch.nn import Linear, BatchNorm1d, ModuleList\n",
    "from torch_geometric.nn import TransformerConv, TopKPooling, GATConv, SAGEConv\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf50a1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jan  9 13:11:29 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:18:00.0 Off |                    0 |\n",
      "| N/A   35C    P0    40W / 300W |      3MiB / 32768MiB |      0%   E. Process |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  Off  | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   29C    P0    41W / 300W |      3MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  Off  | 00000000:86:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    53W / 300W |   3478MiB / 32768MiB |      0%   E. Process |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  Off  | 00000000:AF:00.0 Off |                    0 |\n",
      "| N/A   36C    P0    53W / 300W |    884MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    2   N/A  N/A     33513      C   ...pyter-ultimate/bin/python     3475MiB |\n",
      "|    3   N/A  N/A     33513      C   ...pyter-ultimate/bin/python      881MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "336bf912",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bbd19dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda76be4",
   "metadata": {},
   "source": [
    "# Need to define the data class \n",
    "- Here focus mainly on the get() method. We don't need to process anything\n",
    "- We also return masks for each graph, that will help with training \n",
    "- Actually, no masks. Inductive training.\n",
    "- We are no longer using this data class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e61c0402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class WSI_Graph_Class(Dataset):\n",
    "    \n",
    "#     def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n",
    "#         super().__init__(None, transform, pre_transform)\n",
    "#         self.root_dir = root\n",
    "#         self.WSI_df = pd.read_csv(root) #get the WSI metadata\n",
    "#         self.masks = {} #map node num -> train/val/test masks\n",
    "#         self.create_all_masks()\n",
    "        \n",
    "#     def create_all_masks(self):\n",
    "        \n",
    "#         for idx in tqdm(range(len(self.WSI_df[\"sample_id\"]))):\n",
    "#             path = self.WSI_df[\"path\"].iloc[idx]\n",
    "            \n",
    "#             #this is the graph. We also need to return the training/validation/testing masks \n",
    "#             data = torch.load(path)\n",
    "#             nodes = [i for i in range(data.x.shape[0])] #node 0 is in 0th pos, 1 in 1, and so on \n",
    "            \n",
    "#             #all of the masks \n",
    "#             train_mask = [False] * len(nodes)\n",
    "#             val_mask = [False] * len(nodes)\n",
    "#             test_mask = [False] * len(nodes)\n",
    "#             self.create_mask(nodes, train_mask, val_mask, test_mask)\n",
    "#             #now add them to dictionary\n",
    "#             self.masks[idx] = [train_mask, val_mask, test_mask]\n",
    "        \n",
    "        \n",
    "#     def create_mask(self, nodes, train_mask, val_mask, test_mask):        \n",
    "#         #create train/test/val nodes (75/25)\n",
    "#         train, test = train_test_split(nodes)\n",
    "#         test, val = train_test_split(test)\n",
    "        \n",
    "#         #now create masks\n",
    "#         for i in range(len(nodes)):\n",
    "#             if i in train: \n",
    "#                 train_mask[i] = True \n",
    "                \n",
    "#         for i in range(len(nodes)):\n",
    "#             if nodes[i] in val: \n",
    "#                 val_mask[i] = True \n",
    "                \n",
    "#         for i in range(len(nodes)):\n",
    "#             if nodes[i] in test: \n",
    "#                 test_mask[i] = True \n",
    "                \n",
    "#     #just pass here, we aren't going to return any raw file names\n",
    "#     def raw_file_names(self):\n",
    "#         pass \n",
    "#     #here we can return each of the WSI \n",
    "#     def processed_file_names(self):\n",
    "#         return list(self.WSI_df[\"sample_id\"])\n",
    "    \n",
    "#     def len(self):\n",
    "#         return len(self.processed_file_names())\n",
    "    \n",
    "#     #return the graph class for that idx \n",
    "#     def get(self, idx):\n",
    "#         path = self.WSI_df[\"path\"].iloc[idx]\n",
    "#         #this is the graph. We also need to return the training/validation/testing masks \n",
    "#         data = torch.load(path)\n",
    "#         masks = self.masks[idx]\n",
    "#         train_mask = masks[0]\n",
    "#         val_mask = masks[1]\n",
    "#         test_mask = masks[2]\n",
    "#         return (data, torch.tensor(train_mask), torch.tensor(val_mask), torch.tensor(test_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34847690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root = \"/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/users/Gokul_Srinivasan/SCC-Tumor-Detection/Gokul_files/graph_data/metadata.csv\"\n",
    "\n",
    "# dataset = WSI_Graph_Class(root = root, transform = None, pre_transform = None, pre_filter = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9030ed",
   "metadata": {},
   "source": [
    "# Define Model \n",
    "- This mainly draws upon HIV project code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8392f1d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2b6f5fc05730>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# class GNN(torch.nn.Module):\n",
    "#     def __init__(self, feature_size):\n",
    "#         super(GNN, self).__init__()\n",
    "#         num_classes = 2\n",
    "#         embedding_size = 2048 # from resnet  \n",
    "\n",
    "#         #define the GNN layers \n",
    "\n",
    "#         #layer 1\n",
    "#         #the first graph attention layer which will create 3*embed size embeddings for each node. This will also take care of all the message passing and aggregation\n",
    "#         self.conv1 = GATConv(feature_size, embedding_size, heads=3, dropout = 0.3)\n",
    "#         #reduce the dimensionality back\n",
    "#         self.head_transform1 = Linear(embedding_size*3, embedding_size)\n",
    "#         self.pool1 = TopKPooling(embedding_size, ratio=0.8)\n",
    "\n",
    "#         #layer 2\n",
    "#         self.conv2 = GATConv(embedding_size, embedding_size, heads=3, dropout = 0.3)\n",
    "#         self.head_transform2 = Linear(embedding_size*3, embedding_size)\n",
    "#         self.pool2 = TopKPooling(embedding_size, ratio=0.5)\n",
    "\n",
    "#         #layer 3\n",
    "#         self.conv3 = GATConv(embedding_size, embedding_size, heads=3, dropout = 0.3)\n",
    "#         self.head_transform3 = Linear(embedding_size*3, embedding_size)\n",
    "#         self.pool3 = TopKPooling(embedding_size, ratio=0.2)\n",
    "\n",
    "\n",
    "#         #linear layers - these need to be modified to match the output size? Or maybe not\n",
    "#         self.linear1 = Linear(embedding_size*2, embedding_size)\n",
    "#         self.linear2 = Linear(embedding_size, 2)\n",
    "\n",
    "#     def forward(self, x, edge_attr, edge_index, batch_index):\n",
    "#         #block 1 \n",
    "#         x = self.conv1(x, edge_index)\n",
    "#         x = self.head_transform1(x)\n",
    "\n",
    "#         x, edge_index, edge_attr, batch_index, _, _ = self.pool1(x, edge_index, None, batch_index)\n",
    "#         #graph rep. \n",
    "#         x1 = torch.cat([gmp(x, batch_index), gap(x, batch_index)], dim=1)\n",
    "#         #block 2 \n",
    "#         x = self.conv2(x, edge_index)\n",
    "#         x = self.head_transform2(x)\n",
    "\n",
    "#         x, edge_index, edge_attr, batch_index, _, _ = self.pool2(x, edge_index, None, batch_index)\n",
    "#         #graph rep. \n",
    "#         x2 = torch.cat([gmp(x, batch_index), gap(x, batch_index)], dim=1)\n",
    "#         #block 3\n",
    "#         x = self.conv3(x, edge_index)\n",
    "#         x = self.head_transform3(x)\n",
    "\n",
    "#         x, edge_index, edge_attr, batch_index, _, _ = self.pool3(x, edge_index, None, batch_index)\n",
    "#         #graph rep. \n",
    "#         x3 = torch.cat([gmp(x, batch_index), gap(x, batch_index)], dim=1)\n",
    "#         #element wise addition , and each is 2048 \n",
    "#         x = x1 + x2 + x3\n",
    "#         #output block \n",
    "#         x = self.linear1(x).relu()\n",
    "#         x = F.dropout(x, p=0.5)\n",
    "#         x = self.linear2(x)\n",
    "\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "04c946ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "class simple_GNN(torch.nn.Module):\n",
    "    def __init__(self, feature_size):\n",
    "        super(simple_GNN, self).__init__()\n",
    "        \n",
    "        self.num_classes = 3 # 0 = bengign, 1 = scc, 2 = inflamm\n",
    "        self.embedding_size = 2048 # this is what we want the embedding to be\n",
    "        \n",
    "        self.linear1 = Linear(self.embedding_size, 128)\n",
    "        #define the GNN layers \n",
    "        \n",
    "        self.drop_edge = lambda edge_index: dropout_edge(edge_index,p=0.3)[0]\n",
    "        self.layer_norm1 = nn.LayerNorm(128)\n",
    "        self.layer_norm2 = nn.LayerNorm(256)\n",
    "        #layer 1\n",
    "        #the first graph attention layer which will create 3*embed size embeddings for each node. This will also take care of all the message passing and aggregation\n",
    "        self.conv1 = GATConv(128, 128, heads=3, dropout = 0.3)\n",
    "        #reduce the dimensionality back\n",
    "        self.head_transform1 = Linear(128*3, 128)\n",
    "        \n",
    "        #layer 2\n",
    "        self.conv2 = GATConv(128, 128, heads=3, dropout = 0.3)\n",
    "        self.head_transform2 = Linear(128*3, 128)\n",
    "\n",
    "        #layer 3\n",
    "        self.conv3 = GATConv(128, 256, heads=3, dropout = 0.3)\n",
    "        self.head_transform3 = Linear(256*3, 256)\n",
    "        \n",
    "        #layer 4\n",
    "        self.conv4 = GATConv(256, 256, heads=3, dropout = 0.3)\n",
    "        self.head_transform4 = Linear(256*3, 256)\n",
    "        \n",
    "        #linear layers - these need to be modified to match the output size? Or maybe not\n",
    "        self.linear2 = Linear(128, 64) \n",
    "        self.linear3 = Linear(64, self.num_classes) #prediction for each class\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = x \n",
    "        edge_index = edge_index\n",
    "        batch = batch \n",
    "        # downsize the embeddings\n",
    "        x = self.linear1(x).relu()\n",
    "        \n",
    "        #block 1 \n",
    "        x = self.conv1(x, edge_index) #this is does all the aggregation and message passing\n",
    "        x = self.head_transform1(x)       \n",
    "        x = self.layer_norm1(x)\n",
    "        #block 2\n",
    "#         edge_index = self.drop_edge(edge_index)\n",
    "        x = self.conv2(x, edge_index) \n",
    "        x = self.head_transform2(x)      \n",
    "        x = self.layer_norm1(x)\n",
    "\n",
    "#         #block 3\n",
    "# #         edge_index = self.drop_edge(edge_index)\n",
    "#         x = self.conv3(x, edge_index) #this is does all the aggregation and message passing\n",
    "#         x = self.head_transform3(x)   \n",
    "#         x = self.layer_norm2(x)\n",
    "\n",
    "#         #block 4\n",
    "# #         edge_index = self.drop_edge(edge_index)\n",
    "#         x = self.conv4(x, edge_index) \n",
    "#         x = self.head_transform4(x)   \n",
    "        \n",
    "        #output block \n",
    "        x = self.linear2(x).relu()\n",
    "        x = F.dropout(x, p=0.5)\n",
    "        x = self.linear3(x)\n",
    "        \n",
    "#         print(\"Inside model, after all computations\", torch.cuda.memory_summary(device=None, abbreviated=False)) #bulk of the memory is used here, somehow\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02ee440a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sage_GNN(torch.nn.Module):\n",
    "    def __init__(self, feature_size):\n",
    "        super(sage_GNN, self).__init__()\n",
    "        \n",
    "        self.num_classes = 2 #scc or normal\n",
    "        self.embedding_size = 2048 # this is what we want the embedding to be\n",
    "        \n",
    "        self.linear1 = Linear(2048, 512)\n",
    "\n",
    "        #define the GNN layers \n",
    "    \n",
    "        #layer 1\n",
    "        self.conv1 = SAGEConv(512, 128)\n",
    "        \n",
    "        #layer 2\n",
    "        self.conv2 = SAGEConv(128, 128)\n",
    "           \n",
    "        #layer 3\n",
    "        self.conv3 = SAGEConv(128,128)\n",
    "\n",
    "        self.linear2 = Linear(128, 64) \n",
    "        self.linear3 = Linear(64, 2)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.linear1(x).relu()\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "018eedc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class simple_NN(torch.nn.Module):\n",
    "    def __init__(self, embedding_size):\n",
    "        super(simple_NN, self).__init__()\n",
    "        \n",
    "\n",
    "        self.linear = Linear(2048, 512) \n",
    "        self.linear2 = Linear(512, 64)\n",
    "        self.linear3 = Linear(64, 2)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        \n",
    "        x = F.relu(self.linear(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = F.dropout(x, p=0.5)\n",
    "        x = self.linear3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f0ef05",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ade768a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_features = 2048\n",
    "\n",
    "# # device_ids = [0, 1]\n",
    "# model = simple_GNN(2048)\n",
    "# # model= nn.DataParallel(model, device_ids = device_ids)\n",
    "# model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd55029e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6345fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #loss and optimizer \n",
    "# import torch.optim as optim\n",
    "# import torchvision.ops.focal_loss\n",
    "\n",
    "# # loss_fn = torchvision.ops.focal_loss.sigmoid_focal_loss\n",
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "# opt = optim.Adam(model.parameters(), lr=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e2eb630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #prepare training \n",
    "# from torch_geometric.data import DataLoader\n",
    "\n",
    "# # train_loader = DataLoader(training_data, batch_size=1, shuffle=True)\n",
    "# # val_loader = DataLoader(val_data, batch_size=1, shuffle=True)\n",
    "# # test_loader = DataLoader(testing_data, batch_size=1, shuffle=True)\n",
    "\n",
    "# # num_epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f30c1a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# softmax = nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28544066",
   "metadata": {},
   "source": [
    "# Inductive Model Training on Gokul Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01188559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(num_epochs):\n",
    "#     #training portion\n",
    "#     model.train()\n",
    "#     epoch_loss = []\n",
    "#     for data in tqdm(train_loader):\n",
    "#         #get graph and the relevant stuff\n",
    "#         graph = data[0]\n",
    "#         x = data[0].x\n",
    "#         edge_index = data[0].edge_index\n",
    "#         y = data[0].y\n",
    "        \n",
    "#         #move to device\n",
    "#         x = x.to(device)\n",
    "#         edge_index = edge_index.to(device)\n",
    "#         y = y.to(device)\n",
    "\n",
    "#         #get predictions \n",
    "#         logits = model(x, edge_index)\n",
    "#         loss = loss_fn(logits, y) #for CE\n",
    "\n",
    "#         epoch_loss.append(loss.item())\n",
    "\n",
    "#         opt.zero_grad()\n",
    "#         loss.backward()\n",
    "#         opt.step()\n",
    "#     #now find the average training loss for this epoch \n",
    "#     epoch_loss = sum(epoch_loss)/len(epoch_loss)\n",
    "#     print(\"Epoch :%d. Epoch loss: %f\" %(epoch, epoch_loss))    \n",
    "#     #validation portion\n",
    "#     validation_correct = 0\n",
    "#     validation_total = 0\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         for data in tqdm(val_loader):\n",
    "#             #get graph\n",
    "#             graph = data[0]\n",
    "#             x = data[0].x\n",
    "#             edge_index = data[0].edge_index\n",
    "#             y = data[0].y\n",
    "        \n",
    "#             #move to device\n",
    "#             x = x.to(device)\n",
    "#             edge_index = edge_index.to(device)\n",
    "#             y = y.to(device)\n",
    "\n",
    "#             #get predictions \n",
    "#             logits = model(x, edge_index)\n",
    "#             #get them into label predictions\n",
    "#             _, indices = torch.max(logits, dim=1)\n",
    "# #             print(indices)\n",
    "#             validation_correct += sum(indices == y).item()\n",
    "#             validation_total += len(y)\n",
    "# #             print(\"Accuracy on this graph's val set\", sum(indices == y).item()/len(y))\n",
    "# #             print(\"SCC percent\", sum(y == 1).item()/len(y))\n",
    "    \n",
    "#     print(\"Epoch :%d. Validation accuracy: %f\" %(epoch, validation_correct/validation_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1172f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  #test portion\n",
    "# test_correct = 0\n",
    "# test_total = 0\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     for data in tqdm(data_loader):\n",
    "#         #get graph\n",
    "#         graph = data[0]\n",
    "#         x = graph.x \n",
    "#         edge_index = graph.edge_index\n",
    "#         y = graph.y \n",
    "#         #move to device\n",
    "#         x = x.to(device)\n",
    "#         edge_index = edge_index.to(device)\n",
    "#         y = y.to(device)\n",
    "#         #get masks\n",
    "#         test_mask = data[3].T.reshape([data[3].T.shape[0]])\n",
    "\n",
    "#         #get predictions \n",
    "#         logits = model(x, edge_index)\n",
    "#         #get them into label predictions\n",
    "#         _, indices = torch.max(logits, dim=1)\n",
    "#         print(1 in indices)\n",
    "#         test_correct += sum(indices[test_mask] == y[test_mask]).item()\n",
    "#         test_total += sum(test_mask == True).item()\n",
    "\n",
    "# print(\"Test accuracy: %f\" %(test_correct/test_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e20b47",
   "metadata": {},
   "source": [
    "# Training With Sophie Data\n",
    "- Here, use inductive training \n",
    "- split the ids themselves into different categories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c48c729",
   "metadata": {},
   "outputs": [],
   "source": [
    "sophie_data = pd.read_pickle(\"/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/users/Sophie_Chen/graph_dataset/graph_dataset_modified.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64f48ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = []\n",
    "test_ids = []\n",
    "val_ids = []\n",
    "\n",
    "for id in sophie_data:\n",
    "    if \"train\" in sophie_data[id]:\n",
    "        train_ids.append(id)\n",
    "    elif \"test\" in sophie_data[id]:\n",
    "        test_ids.append(id)\n",
    "    elif \"val\" in sophie_data[id]:\n",
    "        val_ids.append(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f1596a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/users/Gokul_Srinivasan/SCC-Tumor-Detection/Gokul_files/Graph_Data/\"\n",
    "\n",
    "train_dataset = []\n",
    "test_dataset = []\n",
    "val_dataset = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5591f49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 62/62 [00:06<00:00, 10.24it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [00:01<00:00, 11.90it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 18/18 [00:01<00:00, 10.58it/s]\n"
     ]
    }
   ],
   "source": [
    "for id in tqdm(train_ids):\n",
    "    train_dataset.append(torch.load(save_dir + id +\".pt\"))\n",
    "    \n",
    "for id in tqdm(test_ids):\n",
    "    test_dataset.append(torch.load(save_dir + id +\".pt\"))\n",
    "\n",
    "for id in tqdm(val_ids):\n",
    "    val_dataset.append(torch.load(save_dir + id +\".pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0345a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[41295, 2048], edge_index=[2, 326540], y=[41295])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a029f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/users/Gokul_Srinivasan/anaconda3/envs/jupyter-ultimate/lib/python3.7/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e2b7d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62 18 15\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader), len(val_loader), len(test_loader))\n",
    "num_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "66dca1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 2048\n",
    "\n",
    "# device_ids = [0, 1]\n",
    "model = simple_GNN(2048)\n",
    "# model= nn.DataParallel(model, device_ids = device_ids)\n",
    "model = model.to(device)\n",
    "\n",
    "#loss and optimizer \n",
    "# loss_fn = torchvision.ops.focal_loss.sigmoid_focal_loss\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "#optim and scheduler\n",
    "opt = optim.Adam(model.parameters(), lr=1e-5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(opt, factor = 0.1, patience = 5, verbose = True)\n",
    "softmax = nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "993ad0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossess = []\n",
    "validation_aucs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "180f312c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# code from: https://stackoverflow.com/questions/39685740/calculate-sklearn-roc-auc-score-for-multi-class\n",
    "\n",
    "def roc_auc_score_multiclass(actual_class, pred_class, average = \"macro\"):\n",
    "\n",
    "    #creating a set of all the unique classes using the actual class list\n",
    "    unique_class = set([0,1,2])\n",
    "    roc_auc_dict = {}\n",
    "\n",
    "    for per_class in tqdm(unique_class):\n",
    "        #creating a list of all the classes except the current class \n",
    "        other_class = [x for x in unique_class if x != per_class]\n",
    "\n",
    "        #marking the current class as 1 and all other classes as 0\n",
    "        new_actual_class = [0 if x in other_class else 1 for x in actual_class]\n",
    "        new_pred_class = [0 if x in other_class else 1 for x in pred_class]\n",
    "\n",
    "        #using the sklearn metrics method to calculate the roc_auc_score\n",
    "        roc_auc = roc_auc_score(new_actual_class, new_pred_class, average = average)\n",
    "        roc_auc_dict[per_class] = roc_auc\n",
    "\n",
    "    return roc_auc_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ceb07e",
   "metadata": {},
   "source": [
    "# Experiment notes\n",
    "- So 2 layers seems to work well with fairly small embedding sizes\n",
    "- increasing embed size doesn't seem to improve performance \n",
    "- 1e-5 works well with CE\n",
    "- simple NN baseline easily achieves .70 AUC\n",
    "- So far, best performance has been found with layer size = 256, and 3 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9811ab2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                               | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :0. Epoch loss: 0.836680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                                                                 | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|████████████████████████████████████████████████████████▎                                                                                                                | 1/3 [00:06<00:13,  6.85s/it]\u001b[A\n",
      " 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                        | 2/3 [00:11<00:05,  5.33s/it]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:15<00:00,  5.15s/it]\u001b[A\n",
      "  0%|▎                                                                                                                                                                    | 1/500 [00:20<2:49:54, 20.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0\n",
      "{0: 0.528258794409841, 1: 0.5334483934406621, 2: 0.49987062564022583}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|▋                                                                                                                                                                    | 2/500 [00:24<1:29:19, 10.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :1. Epoch loss: 0.677719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▉                                                                                                                                                                    | 3/500 [00:28<1:03:08,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :2. Epoch loss: 0.621884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|█▎                                                                                                                                                                     | 4/500 [00:32<50:47,  6.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :3. Epoch loss: 0.591677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|█▋                                                                                                                                                                     | 5/500 [00:36<43:50,  5.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :4. Epoch loss: 0.571721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|██                                                                                                                                                                     | 6/500 [00:39<39:45,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :5. Epoch loss: 0.557661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|██▎                                                                                                                                                                    | 7/500 [00:43<37:24,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :6. Epoch loss: 0.546715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|██▋                                                                                                                                                                    | 8/500 [00:47<35:28,  4.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :7. Epoch loss: 0.538385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|███                                                                                                                                                                    | 9/500 [00:51<34:04,  4.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :8. Epoch loss: 0.530673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|███▎                                                                                                                                                                  | 10/500 [00:55<33:32,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :9. Epoch loss: 0.523861\n",
      "Epoch :10. Epoch loss: 0.517765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                                                                 | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|████████████████████████████████████████████████████████▎                                                                                                                | 1/3 [00:06<00:13,  6.88s/it]\u001b[A\n",
      " 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                        | 2/3 [00:11<00:05,  5.49s/it]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:15<00:00,  5.28s/it]\u001b[A\n",
      "  2%|███▌                                                                                                                                                                | 11/500 [01:16<1:14:45,  9.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 10\n",
      "{0: 0.7617424886495542, 1: 0.8137432294783499, 2: 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|███▉                                                                                                                                                                | 12/500 [01:20<1:02:21,  7.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :11. Epoch loss: 0.511730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|████▎                                                                                                                                                                 | 13/500 [01:24<52:47,  6.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :12. Epoch loss: 0.506705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|████▋                                                                                                                                                                 | 14/500 [01:28<46:24,  5.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :13. Epoch loss: 0.502346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|████▉                                                                                                                                                                 | 15/500 [01:31<41:30,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :14. Epoch loss: 0.497730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|█████▎                                                                                                                                                                | 16/500 [01:35<38:01,  4.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :15. Epoch loss: 0.494202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|█████▋                                                                                                                                                                | 17/500 [01:39<35:53,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :16. Epoch loss: 0.489540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|█████▉                                                                                                                                                                | 18/500 [01:43<34:23,  4.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :17. Epoch loss: 0.485661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|██████▎                                                                                                                                                               | 19/500 [01:47<33:03,  4.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :18. Epoch loss: 0.482000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|██████▋                                                                                                                                                               | 20/500 [01:50<32:13,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :19. Epoch loss: 0.478611\n",
      "Epoch :20. Epoch loss: 0.474859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                                                                 | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|████████████████████████████████████████████████████████▎                                                                                                                | 1/3 [00:06<00:13,  6.64s/it]\u001b[A\n",
      " 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                        | 2/3 [00:11<00:05,  5.35s/it]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:15<00:00,  5.15s/it]\u001b[A\n",
      "  4%|██████▉                                                                                                                                                             | 21/500 [02:11<1:11:21,  8.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 20\n",
      "{0: 0.7770867702557109, 1: 0.8330991965587675, 2: 0.5010012278694805}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|███████▎                                                                                                                                                              | 22/500 [02:15<59:07,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :21. Epoch loss: 0.472181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|███████▋                                                                                                                                                              | 23/500 [02:19<50:42,  6.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :22. Epoch loss: 0.468660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|███████▉                                                                                                                                                              | 24/500 [02:23<44:31,  5.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :23. Epoch loss: 0.466067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|████████▎                                                                                                                                                             | 25/500 [02:26<39:51,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :24. Epoch loss: 0.462461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|████████▋                                                                                                                                                             | 26/500 [02:30<36:49,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :25. Epoch loss: 0.459882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|████████▉                                                                                                                                                             | 27/500 [02:34<35:03,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :26. Epoch loss: 0.457295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|█████████▎                                                                                                                                                            | 28/500 [02:38<33:51,  4.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :27. Epoch loss: 0.454908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|█████████▋                                                                                                                                                            | 29/500 [02:42<32:31,  4.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :28. Epoch loss: 0.451995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|█████████▉                                                                                                                                                            | 30/500 [02:46<31:44,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :29. Epoch loss: 0.449421\n",
      "Epoch :30. Epoch loss: 0.447202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                                                                 | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|████████████████████████████████████████████████████████▎                                                                                                                | 1/3 [00:06<00:13,  6.58s/it]\u001b[A\n",
      " 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                        | 2/3 [00:11<00:05,  5.37s/it]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:15<00:00,  5.19s/it]\u001b[A\n",
      "  6%|██████████▏                                                                                                                                                         | 31/500 [03:06<1:10:17,  8.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 30\n",
      "{0: 0.7842373511650612, 1: 0.8362038282937058, 2: 0.5268075171945424}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|██████████▌                                                                                                                                                           | 32/500 [03:10<57:47,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :31. Epoch loss: 0.444948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|██████████▉                                                                                                                                                           | 33/500 [03:14<49:35,  6.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :32. Epoch loss: 0.442547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|███████████▎                                                                                                                                                          | 34/500 [03:18<43:41,  5.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :33. Epoch loss: 0.440849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|███████████▌                                                                                                                                                          | 35/500 [03:21<39:11,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :34. Epoch loss: 0.438142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|███████████▉                                                                                                                                                          | 36/500 [03:25<36:10,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :35. Epoch loss: 0.436413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|████████████▎                                                                                                                                                         | 37/500 [03:29<34:28,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :36. Epoch loss: 0.434512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|████████████▌                                                                                                                                                         | 38/500 [03:33<33:08,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :37. Epoch loss: 0.432398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|████████████▉                                                                                                                                                         | 39/500 [03:37<31:51,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :38. Epoch loss: 0.430854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|█████████████▎                                                                                                                                                        | 40/500 [03:41<31:17,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :39. Epoch loss: 0.428869\n",
      "Epoch :40. Epoch loss: 0.426534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                                                                 | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|████████████████████████████████████████████████████████▎                                                                                                                | 1/3 [00:06<00:13,  6.74s/it]\u001b[A\n",
      " 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                        | 2/3 [00:11<00:05,  5.35s/it]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:15<00:00,  5.20s/it]\u001b[A\n",
      "  8%|█████████████▍                                                                                                                                                      | 41/500 [04:01<1:09:08,  9.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 40\n",
      "{0: 0.7895628105155985, 1: 0.8369310827416582, 2: 0.5536559360087847}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|█████████████▉                                                                                                                                                        | 42/500 [04:05<57:45,  7.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :41. Epoch loss: 0.424547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|██████████████▎                                                                                                                                                       | 43/500 [04:09<48:59,  6.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :42. Epoch loss: 0.422301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|██████████████▌                                                                                                                                                       | 44/500 [04:13<42:51,  5.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :43. Epoch loss: 0.419945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|██████████████▉                                                                                                                                                       | 45/500 [04:17<38:47,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :44. Epoch loss: 0.418980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███████████████▎                                                                                                                                                      | 46/500 [04:21<35:59,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :45. Epoch loss: 0.417090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███████████████▌                                                                                                                                                      | 47/500 [04:25<33:55,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :46. Epoch loss: 0.415189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|███████████████▉                                                                                                                                                      | 48/500 [04:29<32:18,  4.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :47. Epoch loss: 0.413410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████████████▎                                                                                                                                                     | 49/500 [04:32<31:29,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :48. Epoch loss: 0.412212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████████████▌                                                                                                                                                     | 50/500 [04:36<30:42,  4.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :49. Epoch loss: 0.410288\n",
      "Epoch :50. Epoch loss: 0.408859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                                                                 | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|████████████████████████████████████████████████████████▎                                                                                                                | 1/3 [00:06<00:13,  6.90s/it]\u001b[A\n",
      " 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                        | 2/3 [00:11<00:05,  5.36s/it]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:15<00:00,  5.21s/it]\u001b[A\n",
      " 10%|████████████████▋                                                                                                                                                   | 51/500 [04:57<1:07:22,  9.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 50\n",
      "{0: 0.7867774756247603, 1: 0.8315516720581189, 2: 0.5645470173841974}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█████████████████▎                                                                                                                                                    | 52/500 [05:01<56:24,  7.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :51. Epoch loss: 0.407409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█████████████████▌                                                                                                                                                    | 53/500 [05:05<47:49,  6.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :52. Epoch loss: 0.405213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█████████████████▉                                                                                                                                                    | 54/500 [05:09<41:58,  5.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :53. Epoch loss: 0.403960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|██████████████████▎                                                                                                                                                   | 55/500 [05:13<38:10,  5.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :54. Epoch loss: 0.402375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|██████████████████▌                                                                                                                                                   | 56/500 [05:16<35:19,  4.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :55. Epoch loss: 0.400618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|██████████████████▉                                                                                                                                                   | 57/500 [05:20<33:05,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :56. Epoch loss: 0.398975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|███████████████████▎                                                                                                                                                  | 58/500 [05:24<31:54,  4.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :57. Epoch loss: 0.397576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|███████████████████▌                                                                                                                                                  | 59/500 [05:28<30:56,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :58. Epoch loss: 0.397163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|███████████████████▉                                                                                                                                                  | 60/500 [05:32<29:53,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :59. Epoch loss: 0.395036\n",
      "Epoch :60. Epoch loss: 0.393430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                                                                 | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|████████████████████████████████████████████████████████▎                                                                                                                | 1/3 [00:06<00:13,  6.94s/it]\u001b[A\n",
      " 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                        | 2/3 [00:11<00:05,  5.48s/it]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:15<00:00,  5.29s/it]\u001b[A\n",
      " 12%|████████████████████                                                                                                                                                | 61/500 [05:53<1:06:33,  9.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 60\n",
      "{0: 0.7799482853184118, 1: 0.8232923058285146, 2: 0.5689798804852056}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|████████████████████▌                                                                                                                                                 | 62/500 [05:57<55:01,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :61. Epoch loss: 0.391840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|████████████████████▉                                                                                                                                                 | 63/500 [06:01<46:47,  6.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :62. Epoch loss: 0.390225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█████████████████████▏                                                                                                                                                | 64/500 [06:05<41:32,  5.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :63. Epoch loss: 0.388090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█████████████████████▌                                                                                                                                                | 65/500 [06:08<37:27,  5.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :64. Epoch loss: 0.386563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█████████████████████▉                                                                                                                                                | 66/500 [06:12<34:33,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :65. Epoch loss: 0.385127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|██████████████████████▏                                                                                                                                               | 67/500 [06:16<32:40,  4.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :66. Epoch loss: 0.383103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|██████████████████████▌                                                                                                                                               | 68/500 [06:20<31:12,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :67. Epoch loss: 0.381299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|██████████████████████▉                                                                                                                                               | 69/500 [06:24<29:54,  4.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :68. Epoch loss: 0.380339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|███████████████████████▏                                                                                                                                              | 70/500 [06:28<29:12,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :69. Epoch loss: 0.378559\n",
      "Epoch :70. Epoch loss: 0.377115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                                                                 | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|████████████████████████████████████████████████████████▎                                                                                                                | 1/3 [00:06<00:13,  6.74s/it]\u001b[A\n",
      " 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                        | 2/3 [00:11<00:05,  5.40s/it]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:15<00:00,  5.23s/it]\u001b[A\n",
      " 14%|███████████████████████▎                                                                                                                                            | 71/500 [06:49<1:04:50,  9.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 70\n",
      "{0: 0.7740583709909353, 1: 0.8157905938650454, 2: 0.5716674041504111}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|███████████████████████▉                                                                                                                                              | 72/500 [06:52<53:31,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :71. Epoch loss: 0.375283\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(num_epochs)):\n",
    "    #training portion\n",
    "    model.train()\n",
    "    epoch_loss = []\n",
    "    for data in train_loader:\n",
    "        #get graph and the relevant stuff\n",
    "        graph = data\n",
    "        x = data.x\n",
    "        edge_index = data.edge_index\n",
    "        y = data.y\n",
    "        batch = data.batch \n",
    "        \n",
    "        #move to device\n",
    "        x = x.to(device)\n",
    "        edge_index = edge_index.to(device)\n",
    "        y = y.to(device)\n",
    "        batch = batch.to(device)\n",
    "        #get predictions \n",
    "        logits = model(x, edge_index, batch) #for CE - CE takes logics \n",
    "#         scores = softmax(model(x, edge_index, batch))[:, 1] # for FL - takes the class prob\n",
    "        loss = loss_fn(logits, y) #for CE\n",
    "#         loss = loss_fn(scores, y.float()).sum() #for focal loss\n",
    "        epoch_loss.append(loss.item())\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    \n",
    "    #now find the average training loss for this epoch \n",
    "    epoch_loss = sum(epoch_loss)/len(epoch_loss)\n",
    "    lossess.append(epoch_loss) #append to master array \n",
    "    print(\"Epoch :%d. Epoch loss: %f\" %(epoch, epoch_loss)) \n",
    "    \n",
    "    scheduler.step(epoch_loss) #show the scheduler the epoch loss and adjust lr accordingly\n",
    "    \n",
    "    \n",
    "    #model in test mode \n",
    "    if epoch % 10 == 0:\n",
    "        model.eval()\n",
    "        predictions = torch.Tensor([])\n",
    "        ground_truth = torch.Tensor([])\n",
    "        #here, we can collect the AUC for each class\n",
    "        with torch.no_grad():\n",
    "            for data in val_loader:\n",
    "                #get graph\n",
    "                graph = data\n",
    "                x = graph.x \n",
    "                edge_index = graph.edge_index\n",
    "                y = graph.y \n",
    "                batch = graph.batch\n",
    "\n",
    "                #move to device\n",
    "                x = x.to(device)\n",
    "                edge_index = edge_index.to(device)\n",
    "                y = y.to(device)\n",
    "                batch = batch.to(device)\n",
    "\n",
    "                #find the probs\n",
    "                scores = softmax(model(x, edge_index, batch))\n",
    "                scores = torch.argmax(scores, dim=1) #transform into indices\n",
    "\n",
    "                #move to cpu\n",
    "                scores = scores.detach().cpu()\n",
    "                y = y.detach().cpu()\n",
    "\n",
    "                #concat them \n",
    "                predictions = torch.cat((predictions, scores))\n",
    "                ground_truth = torch.cat((ground_truth, y))\n",
    "\n",
    "        aucs = roc_auc_score_multiclass(ground_truth, predictions)\n",
    "        validation_aucs.append(aucs) #add these aucs\n",
    "        print(\"Epoch : \"+ str(epoch))\n",
    "        print(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5d6c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test portion - still need to modify\n",
    "    \n",
    "predictions = torch.Tensor([])\n",
    "ground_truth = torch.Tensor([])\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(test_loader):\n",
    "        #get graph\n",
    "        graph = data\n",
    "        x = graph.x \n",
    "        edge_index = graph.edge_index\n",
    "        y = graph.y \n",
    "        batch = graph.batch\n",
    "        #move to device\n",
    "        x = x.to(device)\n",
    "        edge_index = edge_index.to(device)\n",
    "        y = y.to(device)\n",
    "        batch = batch.to(device)\n",
    "        #find the probs\n",
    "        scores = softmax(model(x, edge_index, batch))\n",
    "        \n",
    "        #move to cpu\n",
    "        scores = scores.detach().cpu()\n",
    "        y = y.detach().cpu()\n",
    "        \n",
    "        #concat them \n",
    "        probabilities = torch.cat((probabilities, scores))\n",
    "        ground_truth = torch.cat((ground_truth, y))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988ba80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f72d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict the whole test cohort AUC-ROC\n",
    "\n",
    "roc_auc_score(ground_truth, probabilities[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60edaaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sophie's code - viz. the curve \n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# fpr and tpr of all thresohlds\n",
    "true = ground_truth\n",
    "preds = probabilities[:, 1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(true, preds)\n",
    "\n",
    "#get the metrics \n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "#plot\n",
    "plt.title('Test Cohort-wide AUC-ROC')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd2b8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d91140",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a925531",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-ultimate",
   "language": "python",
   "name": "jupyter-ultimate"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
