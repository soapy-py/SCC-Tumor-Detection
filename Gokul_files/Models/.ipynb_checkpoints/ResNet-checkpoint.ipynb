{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d15890bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch \n",
    "from tqdm import tqdm \n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob, os, pickle\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from PIL import Image\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "521ac4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ac8507b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=3)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839e1e49",
   "metadata": {},
   "source": [
    "# Sophie's Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5a4ae13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_df = pd.read_csv(\"/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/users/Sophie_Chen/file_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8310da88",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(columns=[\"ID\", \"x\", \"y\", \"patch_size\", \"annotations\", \"y_true\", \"inflamm\", \"scc\", \"patch_idx\"])\n",
    "test_df = pd.DataFrame(columns=[\"ID\", \"x\", \"y\", \"patch_size\", \"annotations\", \"y_true\", \"inflamm\", \"scc\", \"patch_idx\"])\n",
    "val_df = pd.DataFrame(columns=[\"ID\", \"x\", \"y\", \"patch_size\", \"annotations\", \"y_true\", \"inflamm\", \"scc\", \"patch_idx\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "86f1d3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "95it [00:39,  2.40it/s]\n"
     ]
    }
   ],
   "source": [
    "for idx, row in tqdm(s_df.iterrows()):\n",
    "    if row[\"set\"] == \"train\":\n",
    "        WSI_df = pd.read_pickle(row[\"patch_info_loc\"])\n",
    "        patch_idx = [int(i) for i in range(len(WSI_df))]\n",
    "        WSI_df[\"patch_idx\"] = patch_idx\n",
    "        train_df = train_df.append(WSI_df)\n",
    "        \n",
    "    elif row[\"set\"] == \"test\":\n",
    "        WSI_df = pd.read_pickle(row[\"patch_info_loc\"])\n",
    "        patch_idx = [int(i) for i in range(len(WSI_df))]\n",
    "        WSI_df[\"patch_idx\"] = patch_idx\n",
    "        test_df = test_df.append(WSI_df)\n",
    "        \n",
    "    elif row[\"set\"] == \"val\":\n",
    "        WSI_df = pd.read_pickle(row[\"patch_info_loc\"])\n",
    "        patch_idx = [int(i) for i in range(len(WSI_df))]\n",
    "        WSI_df[\"patch_idx\"] = patch_idx\n",
    "        val_df = val_df.append(WSI_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c231ddc0",
   "metadata": {},
   "source": [
    "# Create Train/Test/Validation split \n",
    "- The patches that fall into the train, val, and test sets need to be from entirely distinct patient samples/WSI samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "46f32ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #write a different data loader class \n",
    "# class Patch_Class():\n",
    "#     def __init__(self, csv_path, root_dir, samples, transform=None):\n",
    "#         self.samples = samples # this will contain the WSI samples that we want to include in the dataset\n",
    "        \n",
    "#         self.patch_frame = pd.read_csv(csv_path) #get the metadata \n",
    "#         #adjust the metadata so that it only contains data from the samples we want\n",
    "#         self.patch_frame = self.patch_frame[self.patch_frame[\"ID\"].isin(self.samples)]\n",
    "        \n",
    "#         self.root_dir = root_dir\n",
    "#         self.transform = transform\n",
    "        \n",
    "#         #we also need to build the patch dictionary, which maps sample_id to patch_id to status \n",
    "#         self.patch_dict = {}\n",
    "#         self.build_dictionary()\n",
    "        \n",
    "#         #here, we also need to load in all of the distinct np arrays for each directory\n",
    "#         self.data_dict = {}\n",
    "#         self.build_data()\n",
    "        \n",
    "#     def build_data(self):\n",
    "#         #go through each sub dir in the main dir \n",
    "#         for s_dir in tqdm(os.listdir(self.root_dir)):\n",
    "#             #again, only build data for the relevant samples\n",
    "#             if s_dir != \"metadata.csv\" and s_dir in self.samples:\n",
    "#                 data = np.load(self.root_dir + s_dir +\"/data.npy\")\n",
    "#                 self.data_dict[s_dir] = data #map the sample_id to the npy data \n",
    "                \n",
    "#     def build_dictionary(self):\n",
    "#         for sample in self.samples:\n",
    "#             #now, for each sample, make the dictionary\n",
    "#             self.patch_dict[sample] = {}\n",
    "#         for id, group in tqdm(self.patch_frame.groupby(\"ID\")):\n",
    "#             #only build dic for the samples that are needed\n",
    "#             if id in self.samples:\n",
    "#                 for idx, group2 in group.groupby(\"patch_index\"):\n",
    "#                     self.patch_dict[id][idx] = (group2[\"scc\"] == True)\n",
    "            \n",
    "#     def __len__(self):\n",
    "#         return len(self.patch_frame)\n",
    "\n",
    "#     def __getitem__(self, index):        \n",
    "#         #1 is the file id\n",
    "#         sample_id = self.patch_frame.iloc[index, 1]\n",
    "#         patch_id = self.patch_frame.iloc[index, 8]\n",
    "#         #get the image as a numpy array \n",
    "#         img = self.data_dict[sample_id][patch_id]\n",
    "        \n",
    "#         #turn the array into a PIL image, so that it can be resized and transformed\n",
    "# #         img = Image.fromarray(img.astype('uint8'), 'RGB') #this here takes a lot of time, and it considerably slows training\n",
    "        \n",
    "#         #get y_label and one hot encode it\n",
    "# #         ohe = [0, 0]\n",
    "#         y_label = int(list(self.patch_dict[sample_id][patch_id])[0])\n",
    "# #         ohe[y_label] = 1\n",
    "#         y_label = torch.tensor(y_label)\n",
    "\n",
    "#         if self.transform: \n",
    "#             img = self.transform(img)\n",
    "#         return (img, y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1b02bf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform the function according to the pytorch docs\n",
    "from torchvision import transforms\n",
    "#add some image transforms \n",
    "# img_size = 224\n",
    "\n",
    "augmentations = transforms.RandomApply(torch.nn.ModuleList(\n",
    "            [transforms.RandomRotation((0,315)),\n",
    "            transforms.ColorJitter(brightness=.3, contrast=.3),\n",
    "            transforms.RandomSolarize(.3),\n",
    "            transforms.RandomInvert(), \n",
    "            transforms.RandomAdjustSharpness(2),\n",
    "            ]), p=0.2)\n",
    "\n",
    "preprocess_augmentation = transforms.Compose([\n",
    "    #these are the random transforms I got from my other derm project\n",
    "    augmentations, \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "#it doesn't make sense to do this because the val/test sets also use preprocess. So we need a unique one for train. \n",
    "preprocess_normal = transforms.Compose([\n",
    "#     transforms.Resize((img_size, img_size)),\n",
    "    #these are the random transforms I got from my other derm project\n",
    "#     augmentations, \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7bc44bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write a different data loader class \n",
    "class Patch_Class():\n",
    "    def __init__(self, set_type, slides_df, meta_df, transform=None):\n",
    "        self.transform = transform\n",
    "        self.set_type = set_type\n",
    "        \n",
    "        self.slides_df= slides_df  #get patch data\n",
    "        self.meta_df = meta_df #metadata\n",
    "        self.data_dic = {} #get the mapping between WSI id and np array\n",
    "        \n",
    "        self.build_dic()\n",
    "\n",
    "    def build_dic(self):\n",
    "        for idx, row in tqdm(self.meta_df.iterrows()):\n",
    "            if row[\"set\"] == self.set_type:\n",
    "                self.data_dic[row[\"IDs\"]] = np.load(row[\"npy_loc\"])\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.slides_df)\n",
    "\n",
    "    def __getitem__(self, index):        \n",
    "        #1 is the file id\n",
    "        sample_id = self.slides_df.iloc[index, 0] \n",
    "        sample_id = sample_id.split(\"_\", 2)\n",
    "        sample_id = sample_id[0] + \"_\" + sample_id[1] #edit the sample_id to cut off the suffix  \n",
    "        \n",
    "        patch_id = self.slides_df.iloc[index, 8]\n",
    "        y_label = self.slides_df.iloc[index, 7]\n",
    "        \n",
    "        #get the image as a numpy array \n",
    "        img = self.data_dic[sample_id][patch_id]\n",
    "        \n",
    "        #turn the array into a PIL image, so that it can be resized and transformed\n",
    "#         img = Image.fromarray(img.astype('uint8'), 'RGB') #this here takes a lot of time, and it considerably slows training\n",
    "        \n",
    "        #get y_label and one hot encode it\n",
    "#         ohe = [0, 0]\n",
    "#         ohe[y_label] = 1\n",
    "        y_label = torch.tensor(y_label)\n",
    "        if self.transform: \n",
    "            img = self.transform(img)\n",
    "        return (img, y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "16f940f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "95it [11:01,  6.96s/it]\n",
      "95it [04:05,  2.58s/it]\n",
      "95it [03:16,  2.07s/it]\n"
     ]
    }
   ],
   "source": [
    "train_data = Patch_Class(\"train\", train_df, s_df, transform=preprocess_normal)\n",
    "val_data = Patch_Class(\"val\", val_df, s_df, transform=preprocess_normal)\n",
    "test_data = Patch_Class(\"test\", test_df, s_df, transform=preprocess_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "20b4d0c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "287995"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a8339f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # the directories we need\n",
    "\n",
    "# path = \"/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/users/Gokul_Srinivasan/SCC-Tumor-Detection/Gokul_files/data/metadata.csv\"\n",
    "\n",
    "# root_dir = \"/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/users/Gokul_Srinivasan/SCC-Tumor-Detection/Gokul_files/data/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "94ac5602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #get all of the sample names \n",
    "# samples = []\n",
    "# for f in os.listdir(root_dir):\n",
    "#     if f != \"metadata.csv\":\n",
    "#         samples.append(f)\n",
    "\n",
    "# #split the sample names into train/test ~75/25\n",
    "# train, test = torch.utils.data.random_split(samples, [21, 9])\n",
    "\n",
    "# #further split train into train/validation\n",
    "# train, val = torch.utils.data.random_split(train, [18, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "164d0582",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 18/18 [00:37<00:00,  2.10s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31/31 [00:18<00:00,  1.69it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:06<00:00,  2.21s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31/31 [00:02<00:00, 13.01it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:14<00:00,  1.64s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31/31 [00:15<00:00,  1.95it/s]\n"
     ]
    }
   ],
   "source": [
    "# # get all of the different kinds of patches \n",
    "\n",
    "# train_patches = Patch_Class(path, root_dir, samples=set(train), transform = preprocess_normal)\n",
    "# val_patches = Patch_Class(path, root_dir, samples=set(val), transform = preprocess_normal)\n",
    "# test_patches = Patch_Class(path, root_dir, samples=set(test), transform = preprocess_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9d024524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[ 1.7352,  1.3413,  0.9474,  ..., -0.4397, -0.1999,  0.2282],\n",
      "         [ 1.4783,  1.1872,  0.9132,  ..., -0.5424, -0.4226, -0.0801],\n",
      "         [ 1.2557,  1.0673,  0.9474,  ..., -0.6452, -0.6452, -0.3883],\n",
      "         ...,\n",
      "         [ 2.1119,  1.3927,  1.1358,  ...,  0.2282,  0.2282,  0.3138],\n",
      "         [ 1.8379,  1.0331,  1.0673,  ...,  0.1254,  0.1597,  0.2967],\n",
      "         [ 1.8037,  0.9474,  1.0844,  ...,  0.0569,  0.1426,  0.2967]],\n",
      "\n",
      "        [[ 0.7654,  0.3627,  0.0126,  ..., -0.9503, -0.5301, -0.0224],\n",
      "         [ 0.5028,  0.2052, -0.0224,  ..., -1.0728, -0.8102, -0.3725],\n",
      "         [ 0.2927,  0.1001, -0.0224,  ..., -1.2304, -1.0903, -0.7752],\n",
      "         ...,\n",
      "         [ 0.9230,  0.2402,  0.0476,  ..., -0.2675, -0.2150, -0.1275],\n",
      "         [ 0.6954, -0.0924,  0.0126,  ..., -0.3725, -0.2850, -0.1450],\n",
      "         [ 0.6604, -0.1800,  0.0301,  ..., -0.4426, -0.3025, -0.1450]],\n",
      "\n",
      "        [[ 2.0997,  1.6988,  1.3328,  ...,  0.4962,  0.8274,  1.2805],\n",
      "         [ 1.8383,  1.5420,  1.2980,  ...,  0.3742,  0.5659,  0.9319],\n",
      "         [ 1.5768,  1.3851,  1.2631,  ...,  0.2348,  0.3045,  0.6008],\n",
      "         ...,\n",
      "         [ 2.1520,  1.4548,  1.2805,  ...,  1.0365,  1.0017,  1.0539],\n",
      "         [ 1.9080,  1.1062,  1.2282,  ...,  0.9319,  0.9319,  1.0017],\n",
      "         [ 1.8731,  1.0191,  1.2457,  ...,  0.8622,  0.8797,  1.0017]]]), tensor(1))\n",
      "122513\n"
     ]
    }
   ],
   "source": [
    "# print(test_patches.__getitem__(231))\n",
    "\n",
    "# print(len(test_patches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fff3dcb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36206 122513\n"
     ]
    }
   ],
   "source": [
    "# print(len(val_patches), len(test_patches))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674d68da",
   "metadata": {},
   "source": [
    "# Create the Dataloader\n",
    "- also subset the datasets because they're big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8b092c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221056\n",
      "57599\n",
      "42960\n"
     ]
    }
   ],
   "source": [
    "#trim all datasets untill they are 1/10th of the size \n",
    "\n",
    "train_dataset, discard = torch.utils.data.random_split(train_data, [int(len(train_data)*.2), int(len(train_data)*.8)+1])\n",
    "print(len(train_dataset))\n",
    "\n",
    "val_dataset, discard = torch.utils.data.random_split(val_data, [int(len(val_data)*.2), int(len(val_data)*.8)])\n",
    "print(len(val_dataset))\n",
    "\n",
    "test_dataset, discard = torch.utils.data.random_split(test_data, [int(len(test_data)*.2), int(len(test_data)*.8)+1])\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0f7e08dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset = val_dataset, batch_size = batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafc3421",
   "metadata": {},
   "source": [
    "# Load Model\n",
    "- Also change the architecture slightly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f810af2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.hub.list(\"pytorch/vision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f925da1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /dartfs-hpc/rc/home/9/f003xr9/.cache/torch/hub/pytorch_vision_main\n",
      "/dartfs-hpc/rc/home/9/f003xr9/anaconda3/envs/jupyter_ultimate/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "/dartfs-hpc/rc/home/9/f003xr9/anaconda3/envs/jupyter_ultimate/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision', 'resnet50', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a9006ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 0\n",
      "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "Layer: 1\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Layer: 2\n",
      "ReLU(inplace=True)\n",
      "Layer: 3\n",
      "MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "Layer: 4\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "Layer: 5\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "Layer: 6\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (4): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (5): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "Layer: 7\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "Layer: 8\n",
      "AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "Layer: 9\n",
      "Linear(in_features=2048, out_features=1000, bias=True)\n"
     ]
    }
   ],
   "source": [
    "#visualize the layers \n",
    "ct = 0\n",
    "for child in model.children():\n",
    "    print(\"Layer: %d\" %(ct))\n",
    "    print(child)\n",
    "    ct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "21e169b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) 0\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) 1\n",
      "ReLU(inplace=True) 2\n",
      "MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False) 3\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ") 4\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ") 5\n"
     ]
    }
   ],
   "source": [
    "#we can also set the first, say, n layers to be frozen, and leave the remaining layers unfrozen, as follows \n",
    "thresh = 5\n",
    "ct = 0\n",
    "#here we freeze up to and including the 6th layer\n",
    "for child in model.children():\n",
    "    if ct <= thresh:\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = False\n",
    "        print(child, ct)\n",
    "        ct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "7277af15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=100, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=100, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change the model architecture a bit (for vision transformer)\n",
    "model.fc = nn.Sequential(nn.Linear(2048, 100), \n",
    "                         nn.ReLU(), \n",
    "                         nn.Dropout(p=.5), \n",
    "                         nn.Linear(100,2))\n",
    "model\n",
    "\n",
    "model.train()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a264ea7",
   "metadata": {},
   "source": [
    "# Model Training \n",
    "- Still need to implement some standard data augmentation (i.e., rotation, flip, contrast, etc...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d30698f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy on training to see how good our model is\n",
    "def check_accuracy(loader, model):\n",
    "    model.eval() #put model in testing\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    correct = {0:0, 1:0}\n",
    "    total = {0:0, 1:0}\n",
    "    with torch.no_grad():\n",
    "        for x, y, name in tqdm(loader):\n",
    "            #put batches on gpu \n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "\n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)\n",
    "            for i,j in zip(predictions, y):\n",
    "                if i.item() == j.item():\n",
    "                    correct[i.item()] +=1\n",
    "                total[j.item()] += 1\n",
    "                num_correct += (predictions == y).sum()\n",
    "                num_samples += predictions.size(0)\n",
    "\n",
    "        print(\n",
    "              f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}\"\n",
    "          )\n",
    "        acc = num_correct/num_samples\n",
    "        #find the accuracies for each class \n",
    "        return acc, correct, total\n",
    "\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "482a4999",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparams\n",
    "learning_rate = 5e-4\n",
    "num_epochs =10 #20 works well - it seems as tho it is a local min "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5a9877ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = torch.cuda.amp.GradScaler()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b13ba56",
   "metadata": {},
   "source": [
    "Some notes\n",
    "1. Might need to figure out another loss that works better with one hot encoding \n",
    "2. Also might need to figure out how to calc AUC-ROC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "fa1c5899",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1727it [06:15,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at epoch 0 is 0.08519738383718443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 336/336 [01:20<00:00,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9314291936069221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1727it [06:30,  4.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at epoch 1 is 0.06697121650286851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 336/336 [01:19<00:00,  4.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9365089553897008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1727it [06:13,  4.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at epoch 2 is 0.05122723638823717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 336/336 [01:21<00:00,  4.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9384073592666874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1727it [06:20,  4.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at epoch 3 is 0.04097246917338905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 336/336 [01:19<00:00,  4.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9311293110079684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1727it [06:20,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at epoch 4 is 0.0336022137879428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 336/336 [01:21<00:00,  4.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9176489188893133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1727it [06:14,  4.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at epoch 5 is 0.02912683103268089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 336/336 [01:18<00:00,  4.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9372679341774706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1727it [06:11,  4.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at epoch 6 is 0.026002670632331235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 336/336 [01:20<00:00,  4.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9275486708308134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1727it [06:10,  4.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at epoch 7 is 0.022954573203363582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 336/336 [01:18<00:00,  4.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9261726101758245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1727it [06:10,  4.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at epoch 8 is 0.02149840118552245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 336/336 [01:19<00:00,  4.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9314586874645769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1727it [06:12,  4.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at epoch 9 is 0.01957459131026016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 336/336 [01:17<00:00,  4.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9331096971609403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Loss and optimizer\n",
    "import torch.optim as optim  # For all Optimization algorithms, SGD, Adam, etc.\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterion = tgm.losses.FocalLoss(alpha=0.5, gamma=2.0, reduction='mean') #experimenting with focal loss \n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=.1, patience=5, verbose=True)\n",
    "#arrays to track the training loss and validation loss \n",
    "training_loss = []\n",
    "validation_auc= []\n",
    "\n",
    "# Train Network\n",
    "for epoch in range(num_epochs):\n",
    "    losses = []\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    #train part \n",
    "    for batch_idx, (data, targets) in tqdm(enumerate(train_loader)):\n",
    "        # Get data to cuda if possible\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "        \n",
    "        # forward\n",
    "        with torch.cuda.amp.autocast():\n",
    "            scores = model(data)\n",
    "            loss = criterion(scores, targets)\n",
    "            # print(\"Batch: %d. Loss: %f\" %(batch_idx, loss))\n",
    "\n",
    "        losses.append(loss.item()) # add loss\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        # gradient descent or adam step\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "    \n",
    "    mean_loss = sum(losses)/len(losses)\n",
    "    training_loss.append(mean_loss)\n",
    "    scheduler.step(mean_loss)\n",
    "\n",
    "    print(f\"Cost at epoch {epoch} is {sum(losses)/len(losses)}\")\n",
    "    \n",
    "    #model in test mode \n",
    "    model.eval()\n",
    "    probabilities = torch.Tensor([])\n",
    "    ground_truth = torch.Tensor([])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(test_loader):\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "            #find the probs\n",
    "            scores = softmax(model(x))\n",
    "\n",
    "            #move to cpu\n",
    "            scores = scores.detach().cpu()\n",
    "            y = y.detach().cpu()\n",
    "\n",
    "            #concat them \n",
    "            probabilities = torch.cat((probabilities, scores))\n",
    "            ground_truth = torch.cat((ground_truth, y))\n",
    "\n",
    "        #calc total acc here \n",
    "        auc = roc_auc_score(ground_truth, probabilities[:, 1])\n",
    "        print(auc)\n",
    "        validation_auc.append(auc)\n",
    "    #put the model back in train mode\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c93bae4",
   "metadata": {},
   "source": [
    "# Find/Calc/and Make AUC-ROC plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e2bb5e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "softmax = nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "706a797d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 336/336 [01:19<00:00,  4.25it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "probabilities = torch.Tensor([])\n",
    "ground_truth = torch.Tensor([])\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in tqdm(test_loader):\n",
    "        x = x.to(device=device)\n",
    "        y = y.to(device=device)\n",
    "        #find the probs\n",
    "        scores = softmax(model(x))\n",
    "        \n",
    "        #move to cpu\n",
    "        scores = scores.detach().cpu()\n",
    "        y = y.detach().cpu()\n",
    "        \n",
    "        #concat them \n",
    "        probabilities = torch.cat((probabilities, scores))\n",
    "        ground_truth = torch.cat((ground_truth, y))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6b7c8745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.933109699559205"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict the whole test cohort AUC-ROC\n",
    "\n",
    "roc_auc_score(ground_truth, probabilities[:, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "18d4bf5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#from sophie's code - viz. the curve \n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# fpr and tpr of all thresohlds\n",
    "true = ground_truth\n",
    "preds = probabilities[:, 1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(true, preds)\n",
    "\n",
    "#get the metrics \n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "#plot\n",
    "plt.title('Test Cohort-wide AUC-ROC')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6913543a",
   "metadata": {},
   "source": [
    "# Save Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768fafe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = \"/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/users/Gokul_Srinivasan/SCC-Tumor-Detection/Gokul_files/Saved_Models/resnet50.pt\"\n",
    "# torch.save(model.state_dict(), PATH) # here is how we save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2f486bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Dec 18 14:40:31 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:18:00.0 Off |                    0 |\n",
      "| N/A   37C    P0    55W / 300W |   3758MiB / 32768MiB |      0%   E. Process |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  Off  | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    51W / 300W |    754MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  Off  | 00000000:86:00.0 Off |                    0 |\n",
      "| N/A   27C    P0    39W / 300W |      3MiB / 32768MiB |      0%   E. Process |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  Off  | 00000000:AF:00.0 Off |                    0 |\n",
      "| N/A   30C    P0    40W / 300W |      3MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A    104863      C   ...pyter_ultimate/bin/python     3755MiB |\n",
      "|    1   N/A  N/A    104270      C   ...pyter_ultimate/bin/python      751MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f59d0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_ultimate",
   "language": "python",
   "name": "jupyter_ultimate"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
