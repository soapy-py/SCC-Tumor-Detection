{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d15890bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch \n",
    "from tqdm import tqdm \n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob, os, pickle\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from PIL import Image\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "521ac4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ac8507b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c231ddc0",
   "metadata": {},
   "source": [
    "# Create Train/Test/Validation split \n",
    "- The patches that fall into the train, val, and test sets need to be from entirely distinct patient samples/WSI samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "46f32ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write a different data loader class \n",
    "class Patch_Class():\n",
    "    def __init__(self, csv_path, root_dir, samples, transform=None):\n",
    "        self.samples = samples # this will contain the WSI samples that we want to include in the dataset\n",
    "        \n",
    "        self.patch_frame = pd.read_csv(csv_path) #get the metadata \n",
    "        #adjust the metadata so that it only contains data from the samples we want\n",
    "        self.patch_frame = self.patch_frame[self.patch_frame[\"ID\"].isin(self.samples)]\n",
    "        \n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        #we also need to build the patch dictionary, which maps sample_id to patch_id to status \n",
    "        self.patch_dict = {}\n",
    "        self.build_dictionary()\n",
    "        \n",
    "        #here, we also need to load in all of the distinct np arrays for each directory\n",
    "        self.data_dict = {}\n",
    "        self.build_data()\n",
    "        \n",
    "    def build_data(self):\n",
    "        #go through each sub dir in the main dir \n",
    "        for s_dir in tqdm(os.listdir(self.root_dir)):\n",
    "            #again, only build data for the relevant samples\n",
    "            if s_dir != \"metadata.csv\" and s_dir in self.samples:\n",
    "                data = np.load(self.root_dir + s_dir +\"/data.npy\")\n",
    "                self.data_dict[s_dir] = data #map the sample_id to the npy data \n",
    "                \n",
    "    def build_dictionary(self):\n",
    "        for sample in self.samples:\n",
    "            #now, for each sample, make the dictionary\n",
    "            self.patch_dict[sample] = {}\n",
    "        for id, group in tqdm(self.patch_frame.groupby(\"ID\")):\n",
    "            #only build dic for the samples that are needed\n",
    "            if id in self.samples:\n",
    "                for idx, group2 in group.groupby(\"patch_index\"):\n",
    "                    self.patch_dict[id][idx] = (group2[\"scc\"] == True)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.patch_frame)\n",
    "\n",
    "    def __getitem__(self, index):        \n",
    "        #1 is the file id\n",
    "        sample_id = self.patch_frame.iloc[index, 1]\n",
    "        patch_id = self.patch_frame.iloc[index, 8]\n",
    "        #get the image as a numpy array \n",
    "        img = self.data_dict[sample_id][patch_id]\n",
    "        \n",
    "        #turn the array into a PIL image, so that it can be resized and transformed\n",
    "#         img = Image.fromarray(img.astype('uint8'), 'RGB') #this here takes a lot of time, and it considerably slows training\n",
    "        \n",
    "        #get y_label and one hot encode it\n",
    "#         ohe = [0, 0]\n",
    "        y_label = int(list(self.patch_dict[sample_id][patch_id])[0])\n",
    "#         ohe[y_label] = 1\n",
    "        y_label = torch.tensor(y_label)\n",
    "\n",
    "        if self.transform: \n",
    "            img = self.transform(img)\n",
    "        return (img, y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "91573600",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform the function according to the pytorch docs\n",
    "from torchvision import transforms\n",
    "#add some image transforms \n",
    "# img_size = 224\n",
    "\n",
    "augmentations = transforms.RandomApply(torch.nn.ModuleList(\n",
    "            [transforms.RandomRotation((0,315)),\n",
    "            transforms.ColorJitter(brightness=.3, contrast=.3),\n",
    "            transforms.RandomSolarize(.3),\n",
    "            transforms.RandomInvert(), \n",
    "            transforms.RandomAdjustSharpness(2),\n",
    "            ]), p=0.2)\n",
    "\n",
    "preprocess_augmentation = transforms.Compose([\n",
    "    #these are the random transforms I got from my other derm project\n",
    "    augmentations, \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "#it doesn't make sense to do this because the val/test sets also use preprocess. So we need a unique one for train. \n",
    "preprocess_normal = transforms.Compose([\n",
    "#     transforms.Resize((img_size, img_size)),\n",
    "    #these are the random transforms I got from my other derm project\n",
    "#     augmentations, \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a8339f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the directories we need\n",
    "\n",
    "path = \"/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/users/Gokul_Srinivasan/SCC-Tumor-Detection/Gokul_files/data/metadata.csv\"\n",
    "\n",
    "root_dir = \"/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/users/Gokul_Srinivasan/SCC-Tumor-Detection/Gokul_files/data/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "94ac5602",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all of the sample names \n",
    "samples = []\n",
    "for f in os.listdir(root_dir):\n",
    "    if f != \"metadata.csv\":\n",
    "        samples.append(f)\n",
    "\n",
    "#split the sample names into train/test ~75/25\n",
    "train, test = torch.utils.data.random_split(samples, [21, 9])\n",
    "\n",
    "#further split train into train/validation\n",
    "train, val = torch.utils.data.random_split(train, [18, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "164d0582",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 18/18 [00:37<00:00,  2.10s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31/31 [00:18<00:00,  1.69it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:06<00:00,  2.21s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31/31 [00:02<00:00, 13.01it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:14<00:00,  1.64s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31/31 [00:15<00:00,  1.95it/s]\n"
     ]
    }
   ],
   "source": [
    "# get all of the different kinds of patches \n",
    "\n",
    "train_patches = Patch_Class(path, root_dir, samples=set(train), transform = preprocess_normal)\n",
    "val_patches = Patch_Class(path, root_dir, samples=set(val), transform = preprocess_normal)\n",
    "test_patches = Patch_Class(path, root_dir, samples=set(test), transform = preprocess_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9d024524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[ 1.7352,  1.3413,  0.9474,  ..., -0.4397, -0.1999,  0.2282],\n",
      "         [ 1.4783,  1.1872,  0.9132,  ..., -0.5424, -0.4226, -0.0801],\n",
      "         [ 1.2557,  1.0673,  0.9474,  ..., -0.6452, -0.6452, -0.3883],\n",
      "         ...,\n",
      "         [ 2.1119,  1.3927,  1.1358,  ...,  0.2282,  0.2282,  0.3138],\n",
      "         [ 1.8379,  1.0331,  1.0673,  ...,  0.1254,  0.1597,  0.2967],\n",
      "         [ 1.8037,  0.9474,  1.0844,  ...,  0.0569,  0.1426,  0.2967]],\n",
      "\n",
      "        [[ 0.7654,  0.3627,  0.0126,  ..., -0.9503, -0.5301, -0.0224],\n",
      "         [ 0.5028,  0.2052, -0.0224,  ..., -1.0728, -0.8102, -0.3725],\n",
      "         [ 0.2927,  0.1001, -0.0224,  ..., -1.2304, -1.0903, -0.7752],\n",
      "         ...,\n",
      "         [ 0.9230,  0.2402,  0.0476,  ..., -0.2675, -0.2150, -0.1275],\n",
      "         [ 0.6954, -0.0924,  0.0126,  ..., -0.3725, -0.2850, -0.1450],\n",
      "         [ 0.6604, -0.1800,  0.0301,  ..., -0.4426, -0.3025, -0.1450]],\n",
      "\n",
      "        [[ 2.0997,  1.6988,  1.3328,  ...,  0.4962,  0.8274,  1.2805],\n",
      "         [ 1.8383,  1.5420,  1.2980,  ...,  0.3742,  0.5659,  0.9319],\n",
      "         [ 1.5768,  1.3851,  1.2631,  ...,  0.2348,  0.3045,  0.6008],\n",
      "         ...,\n",
      "         [ 2.1520,  1.4548,  1.2805,  ...,  1.0365,  1.0017,  1.0539],\n",
      "         [ 1.9080,  1.1062,  1.2282,  ...,  0.9319,  0.9319,  1.0017],\n",
      "         [ 1.8731,  1.0191,  1.2457,  ...,  0.8622,  0.8797,  1.0017]]]), tensor(1))\n",
      "122513\n"
     ]
    }
   ],
   "source": [
    "print(test_patches.__getitem__(231))\n",
    "\n",
    "print(len(test_patches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fff3dcb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36206 122513\n"
     ]
    }
   ],
   "source": [
    "print(len(val_patches), len(test_patches))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674d68da",
   "metadata": {},
   "source": [
    "# Create the Dataloader\n",
    "- also subset the datasets because they're big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8b092c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195854\n",
      "7241\n",
      "85759\n"
     ]
    }
   ],
   "source": [
    "#trim all datasets untill they are 1/10th of the size \n",
    "\n",
    "train_dataset, discard = torch.utils.data.random_split(train_patches, [int(len(train_patches)*.7), int(len(train_patches)*.3)+1])\n",
    "print(len(train_dataset))\n",
    "\n",
    "val_dataset, discard = torch.utils.data.random_split(val_patches, [int(len(val_patches)*.2), int(len(val_patches)*.8)+1])\n",
    "print(len(val_dataset))\n",
    "\n",
    "test_dataset, discard = torch.utils.data.random_split(test_patches, [int(len(test_patches)*.7), int(len(test_patches)*.3)+1])\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0f7e08dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset = val_dataset, batch_size = batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafc3421",
   "metadata": {},
   "source": [
    "# Load Model\n",
    "- Also change the architecture slightly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f810af2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.hub.list(\"pytorch/vision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f925da1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /dartfs-hpc/rc/home/9/f003xr9/.cache/torch/hub/pytorch_vision_main\n",
      "/dartfs-hpc/rc/home/9/f003xr9/anaconda3/envs/jupyter_ultimate/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "/dartfs-hpc/rc/home/9/f003xr9/anaconda3/envs/jupyter_ultimate/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision', 'resnet50', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a9006ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 0\n",
      "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "Layer: 1\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Layer: 2\n",
      "ReLU(inplace=True)\n",
      "Layer: 3\n",
      "MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "Layer: 4\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "Layer: 5\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "Layer: 6\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (4): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (5): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "Layer: 7\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "Layer: 8\n",
      "AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "Layer: 9\n",
      "Linear(in_features=2048, out_features=1000, bias=True)\n"
     ]
    }
   ],
   "source": [
    "#visualize the layers \n",
    "ct = 0\n",
    "for child in model.children():\n",
    "    print(\"Layer: %d\" %(ct))\n",
    "    print(child)\n",
    "    ct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "21e169b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) 0\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) 1\n",
      "ReLU(inplace=True) 2\n",
      "MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False) 3\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ") 4\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ") 5\n"
     ]
    }
   ],
   "source": [
    "#we can also set the first, say, n layers to be frozen, and leave the remaining layers unfrozen, as follows \n",
    "thresh = 5\n",
    "ct = 0\n",
    "#here we freeze up to and including the 6th layer\n",
    "for child in model.children():\n",
    "    if ct <= thresh:\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = False\n",
    "        print(child, ct)\n",
    "        ct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7277af15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=100, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=100, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change the model architecture a bit (for vision transformer)\n",
    "model.fc = nn.Sequential(nn.Linear(2048, 100), \n",
    "                         nn.ReLU(), \n",
    "                         nn.Dropout(p=.5), \n",
    "                         nn.Linear(100,2))\n",
    "model\n",
    "\n",
    "model.train()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a264ea7",
   "metadata": {},
   "source": [
    "# Model Training \n",
    "- Still need to implement some standard data augmentation (i.e., rotation, flip, contrast, etc...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d30698f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy on training to see how good our model is\n",
    "def check_accuracy(loader, model):\n",
    "    model.eval() #put model in testing\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    correct = {0:0, 1:0}\n",
    "    total = {0:0, 1:0}\n",
    "    with torch.no_grad():\n",
    "        for x, y, name in tqdm(loader):\n",
    "            #put batches on gpu \n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "\n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)\n",
    "            for i,j in zip(predictions, y):\n",
    "                if i.item() == j.item():\n",
    "                    correct[i.item()] +=1\n",
    "                total[j.item()] += 1\n",
    "                num_correct += (predictions == y).sum()\n",
    "                num_samples += predictions.size(0)\n",
    "\n",
    "        print(\n",
    "              f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}\"\n",
    "          )\n",
    "        acc = num_correct/num_samples\n",
    "        #find the accuracies for each class \n",
    "        return acc, correct, total\n",
    "\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "482a4999",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparams\n",
    "learning_rate = 5e-4\n",
    "num_epochs =10 #20 works well - it seems as tho it is a local min "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b13ba56",
   "metadata": {},
   "source": [
    "Some notes\n",
    "1. Might need to figure out another loss that works better with one hot encoding \n",
    "2. Also might need to figure out how to calc AUC-ROC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fa1c5899",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1531it [07:35,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at epoch 0 is 0.2973250522187611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 57/57 [00:08<00:00,  6.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7685402631759644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1531it [07:35,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at epoch 1 is 0.25101639744524545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 57/57 [00:08<00:00,  6.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7447866797447205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1531it [07:34,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at epoch 2 is 0.22507667499165532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 57/57 [00:08<00:00,  6.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8259909152984619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1531it [07:34,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at epoch 3 is 0.19669104275031465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 57/57 [00:08<00:00,  6.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.818671464920044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1531it [07:35,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at epoch 4 is 0.1607950032633321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 57/57 [00:08<00:00,  6.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7887032628059387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1531it [07:34,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at epoch 5 is 0.1262654923681221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 57/57 [00:08<00:00,  6.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7634304761886597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1531it [07:34,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at epoch 6 is 0.09826891671362498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 57/57 [00:08<00:00,  6.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7993371486663818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1531it [07:34,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at epoch 7 is 0.08052691652553289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 57/57 [00:08<00:00,  6.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7572158575057983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1531it [07:34,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at epoch 8 is 0.06972874697008256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 57/57 [00:08<00:00,  6.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7962988615036011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "257it [01:16,  3.36it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/scratch/ipykernel_112443/2282586577.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# print(\"Batch: %d. Loss: %f\" %(batch_idx, loss))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Loss and optimizer\n",
    "import torch.optim as optim  # For all Optimization algorithms, SGD, Adam, etc.\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterion = tgm.losses.FocalLoss(alpha=0.5, gamma=2.0, reduction='mean') #experimenting with focal loss \n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=.1, patience=5, verbose=True)\n",
    "\n",
    "#arrays to track the training loss and validation loss \n",
    "training_loss = []\n",
    "validation_acc = []\n",
    "\n",
    "# Train Network\n",
    "for epoch in range(num_epochs):\n",
    "    losses = []\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    #train part \n",
    "    for batch_idx, (data, targets) in tqdm(enumerate(train_loader)):\n",
    "        # Get data to cuda if possible\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "        # forward\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores, targets)\n",
    "        # print(\"Batch: %d. Loss: %f\" %(batch_idx, loss))\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # gradient descent or adam step\n",
    "        optimizer.step()\n",
    "    mean_loss = sum(losses)/len(losses)\n",
    "    training_loss.append(mean_loss)\n",
    "    scheduler.step(mean_loss)\n",
    "\n",
    "    print(f\"Cost at epoch {epoch} is {sum(losses)/len(losses)}\")\n",
    "    \n",
    "    #model in test mode \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        acc = 0\n",
    "        for x, y in tqdm(val_loader):\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "\n",
    "            scores = model(x)\n",
    "            #find the test loss\n",
    "            loss = criterion(scores, y)\n",
    "\n",
    "\n",
    "            #find the test accuracy \n",
    "            _, predictions = scores.max(1)\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "        #calc total acc here \n",
    "        acc = (num_correct/num_samples).item()\n",
    "        print(acc)\n",
    "        validation_acc.append(acc)\n",
    "    #put the model back in train mode\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c93bae4",
   "metadata": {},
   "source": [
    "# Find/Calc/and Make AUC-ROC plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e2bb5e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "softmax = nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "706a797d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 670/670 [02:25<00:00,  4.59it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "probabilities = torch.Tensor([])\n",
    "ground_truth = torch.Tensor([])\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in tqdm(test_loader):\n",
    "        x = x.to(device=device)\n",
    "        y = y.to(device=device)\n",
    "        #find the probs\n",
    "        scores = softmax(model(x))\n",
    "        \n",
    "        #move to cpu\n",
    "        scores = scores.detach().cpu()\n",
    "        y = y.detach().cpu()\n",
    "        \n",
    "        #concat them \n",
    "        probabilities = torch.cat((probabilities, scores))\n",
    "        ground_truth = torch.cat((ground_truth, y))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6b7c8745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9232591235635024"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict the whole test cohort AUC-ROC\n",
    "\n",
    "roc_auc_score(ground_truth, probabilities[:, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "18d4bf5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#from sophie's code - viz. the curve \n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# fpr and tpr of all thresohlds\n",
    "true = ground_truth\n",
    "preds = probabilities[:, 1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(true, preds)\n",
    "\n",
    "#get the metrics \n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "#plot\n",
    "plt.title('Test Cohort-wide AUC-ROC')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6913543a",
   "metadata": {},
   "source": [
    "# Save Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768fafe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = \"/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/users/Gokul_Srinivasan/SCC-Tumor-Detection/Gokul_files/Saved_Models/resnet50.pt\"\n",
    "# torch.save(model.state_dict(), PATH) # here is how we save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2f486bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Dec 18 14:40:31 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:18:00.0 Off |                    0 |\n",
      "| N/A   37C    P0    55W / 300W |   3758MiB / 32768MiB |      0%   E. Process |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  Off  | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    51W / 300W |    754MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  Off  | 00000000:86:00.0 Off |                    0 |\n",
      "| N/A   27C    P0    39W / 300W |      3MiB / 32768MiB |      0%   E. Process |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  Off  | 00000000:AF:00.0 Off |                    0 |\n",
      "| N/A   30C    P0    40W / 300W |      3MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A    104863      C   ...pyter_ultimate/bin/python     3755MiB |\n",
      "|    1   N/A  N/A    104270      C   ...pyter_ultimate/bin/python      751MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f59d0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_ultimate",
   "language": "python",
   "name": "jupyter_ultimate"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
