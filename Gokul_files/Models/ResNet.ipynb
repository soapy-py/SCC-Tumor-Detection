{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d15890bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch \n",
    "from tqdm import tqdm \n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob, os, pickle\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from PIL import Image\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "521ac4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac8507b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839e1e49",
   "metadata": {},
   "source": [
    "# Sophie's Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a4ae13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_df = pd.read_csv(\"/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/users/Sophie_Chen/file_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8310da88",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(columns=[\"ID\", \"x\", \"y\", \"patch_size\", \"annotations\", \"y_true\", \"inflamm\", \"scc\", \"patch_idx\"])\n",
    "test_df = pd.DataFrame(columns=[\"ID\", \"x\", \"y\", \"patch_size\", \"annotations\", \"y_true\", \"inflamm\", \"scc\", \"patch_idx\"])\n",
    "val_df = pd.DataFrame(columns=[\"ID\", \"x\", \"y\", \"patch_size\", \"annotations\", \"y_true\", \"inflamm\", \"scc\", \"patch_idx\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86f1d3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "95it [00:37,  2.54it/s]\n"
     ]
    }
   ],
   "source": [
    "for idx, row in tqdm(s_df.iterrows()):\n",
    "    if row[\"set\"] == \"train\":\n",
    "        WSI_df = pd.read_pickle(row[\"patch_info_loc\"])\n",
    "        patch_idx = [int(i) for i in range(len(WSI_df))]\n",
    "        WSI_df[\"patch_idx\"] = patch_idx\n",
    "        train_df = train_df.append(WSI_df)\n",
    "        \n",
    "    elif row[\"set\"] == \"test\":\n",
    "        WSI_df = pd.read_pickle(row[\"patch_info_loc\"])\n",
    "        patch_idx = [int(i) for i in range(len(WSI_df))]\n",
    "        WSI_df[\"patch_idx\"] = patch_idx\n",
    "        test_df = test_df.append(WSI_df)\n",
    "        \n",
    "    elif row[\"set\"] == \"val\":\n",
    "        WSI_df = pd.read_pickle(row[\"patch_info_loc\"])\n",
    "        patch_idx = [int(i) for i in range(len(WSI_df))]\n",
    "        WSI_df[\"patch_idx\"] = patch_idx\n",
    "        val_df = val_df.append(WSI_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c231ddc0",
   "metadata": {},
   "source": [
    "# Create Train/Test/Validation split \n",
    "- The patches that fall into the train, val, and test sets need to be from entirely distinct patient samples/WSI samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46f32ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #write a different data loader class \n",
    "# class Patch_Class():\n",
    "#     def __init__(self, csv_path, root_dir, samples, transform=None):\n",
    "#         self.samples = samples # this will contain the WSI samples that we want to include in the dataset\n",
    "        \n",
    "#         self.patch_frame = pd.read_csv(csv_path) #get the metadata \n",
    "#         #adjust the metadata so that it only contains data from the samples we want\n",
    "#         self.patch_frame = self.patch_frame[self.patch_frame[\"ID\"].isin(self.samples)]\n",
    "        \n",
    "#         self.root_dir = root_dir\n",
    "#         self.transform = transform\n",
    "        \n",
    "#         #we also need to build the patch dictionary, which maps sample_id to patch_id to status \n",
    "#         self.patch_dict = {}\n",
    "#         self.build_dictionary()\n",
    "        \n",
    "#         #here, we also need to load in all of the distinct np arrays for each directory\n",
    "#         self.data_dict = {}\n",
    "#         self.build_data()\n",
    "        \n",
    "#     def build_data(self):\n",
    "#         #go through each sub dir in the main dir \n",
    "#         for s_dir in tqdm(os.listdir(self.root_dir)):\n",
    "#             #again, only build data for the relevant samples\n",
    "#             if s_dir != \"metadata.csv\" and s_dir in self.samples:\n",
    "#                 data = np.load(self.root_dir + s_dir +\"/data.npy\")\n",
    "#                 self.data_dict[s_dir] = data #map the sample_id to the npy data \n",
    "                \n",
    "#     def build_dictionary(self):\n",
    "#         for sample in self.samples:\n",
    "#             #now, for each sample, make the dictionary\n",
    "#             self.patch_dict[sample] = {}\n",
    "#         for id, group in tqdm(self.patch_frame.groupby(\"ID\")):\n",
    "#             #only build dic for the samples that are needed\n",
    "#             if id in self.samples:\n",
    "#                 for idx, group2 in group.groupby(\"patch_index\"):\n",
    "#                     self.patch_dict[id][idx] = (group2[\"scc\"] == True)\n",
    "            \n",
    "#     def __len__(self):\n",
    "#         return len(self.patch_frame)\n",
    "\n",
    "#     def __getitem__(self, index):        \n",
    "#         #1 is the file id\n",
    "#         sample_id = self.patch_frame.iloc[index, 1]\n",
    "#         patch_id = self.patch_frame.iloc[index, 8]\n",
    "#         #get the image as a numpy array \n",
    "#         img = self.data_dict[sample_id][patch_id]\n",
    "        \n",
    "#         #turn the array into a PIL image, so that it can be resized and transformed\n",
    "# #         img = Image.fromarray(img.astype('uint8'), 'RGB') #this here takes a lot of time, and it considerably slows training\n",
    "        \n",
    "#         #get y_label and one hot encode it\n",
    "# #         ohe = [0, 0]\n",
    "#         y_label = int(list(self.patch_dict[sample_id][patch_id])[0])\n",
    "# #         ohe[y_label] = 1\n",
    "#         y_label = torch.tensor(y_label)\n",
    "\n",
    "#         if self.transform: \n",
    "#             img = self.transform(img)\n",
    "#         return (img, y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b02bf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform the function according to the pytorch docs\n",
    "from torchvision import transforms\n",
    "#add some image transforms \n",
    "# img_size = 224\n",
    "\n",
    "augmentations = transforms.RandomApply(torch.nn.ModuleList(\n",
    "            [transforms.RandomRotation((0,315)),\n",
    "            transforms.ColorJitter(brightness=.3, contrast=.3),\n",
    "            transforms.RandomSolarize(.3),\n",
    "            transforms.RandomInvert(), \n",
    "            transforms.RandomAdjustSharpness(2),\n",
    "            ]), p=0.2)\n",
    "\n",
    "preprocess_augmentation = transforms.Compose([\n",
    "    #these are the random transforms I got from my other derm project\n",
    "    augmentations, \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "#it doesn't make sense to do this because the val/test sets also use preprocess. So we need a unique one for train. \n",
    "preprocess_normal = transforms.Compose([\n",
    "#     transforms.Resize((img_size, img_size)),\n",
    "    #these are the random transforms I got from my other derm project\n",
    "#     augmentations, \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bc44bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write a different data loader class \n",
    "class Patch_Class():\n",
    "    def __init__(self, set_type, slides_df, meta_df, transform=None):\n",
    "        self.transform = transform\n",
    "        self.set_type = set_type\n",
    "        \n",
    "        self.slides_df= slides_df  #get patch data\n",
    "        self.meta_df = meta_df #metadata\n",
    "        self.data_dic = {} #get the mapping between WSI id and np array\n",
    "        \n",
    "        self.build_dic()\n",
    "\n",
    "    def build_dic(self):\n",
    "        for idx, row in tqdm(self.meta_df.iterrows()):\n",
    "            if row[\"set\"] == self.set_type:\n",
    "                self.data_dic[row[\"IDs\"]] = np.load(row[\"npy_loc\"])\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.slides_df)\n",
    "\n",
    "    def __getitem__(self, index):        \n",
    "        #1 is the file id\n",
    "        sample_id = self.slides_df.iloc[index, 0] \n",
    "        sample_id = sample_id.split(\"_\", 2)\n",
    "        sample_id = sample_id[0] + \"_\" + sample_id[1] #edit the sample_id to cut off the suffix  \n",
    "        \n",
    "        patch_id = self.slides_df.iloc[index, 8]\n",
    "        y_label = self.slides_df.iloc[index, 7]\n",
    "        \n",
    "        #get the image as a numpy array \n",
    "        img = self.data_dic[sample_id][patch_id]\n",
    "        \n",
    "        #turn the array into a PIL image, so that it can be resized and transformed\n",
    "#         img = Image.fromarray(img.astype('uint8'), 'RGB') #this here takes a lot of time, and it considerably slows training\n",
    "        \n",
    "        #get y_label and one hot encode it\n",
    "#         ohe = [0, 0]\n",
    "#         ohe[y_label] = 1\n",
    "        y_label = torch.tensor(y_label)\n",
    "        if self.transform: \n",
    "            img = self.transform(img)\n",
    "        return (img, y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16f940f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "95it [16:17, 10.29s/it]\n",
      "95it [04:21,  2.75s/it]\n",
      "95it [03:18,  2.09s/it]\n"
     ]
    }
   ],
   "source": [
    "train_data = Patch_Class(\"train\", train_df, s_df, transform=preprocess_normal)\n",
    "val_data = Patch_Class(\"val\", val_df, s_df, transform=preprocess_normal)\n",
    "test_data = Patch_Class(\"test\", test_df, s_df, transform=preprocess_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20b4d0c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "287995"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8339f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # the directories we need\n",
    "\n",
    "# path = \"/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/users/Gokul_Srinivasan/SCC-Tumor-Detection/Gokul_files/data/metadata.csv\"\n",
    "\n",
    "# root_dir = \"/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/users/Gokul_Srinivasan/SCC-Tumor-Detection/Gokul_files/data/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94ac5602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #get all of the sample names \n",
    "# samples = []\n",
    "# for f in os.listdir(root_dir):\n",
    "#     if f != \"metadata.csv\":\n",
    "#         samples.append(f)\n",
    "\n",
    "# #split the sample names into train/test ~75/25\n",
    "# train, test = torch.utils.data.random_split(samples, [21, 9])\n",
    "\n",
    "# #further split train into train/validation\n",
    "# train, val = torch.utils.data.random_split(train, [18, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "164d0582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get all of the different kinds of patches \n",
    "\n",
    "# train_patches = Patch_Class(path, root_dir, samples=set(train), transform = preprocess_normal)\n",
    "# val_patches = Patch_Class(path, root_dir, samples=set(val), transform = preprocess_normal)\n",
    "# test_patches = Patch_Class(path, root_dir, samples=set(test), transform = preprocess_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d024524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(test_patches.__getitem__(231))\n",
    "\n",
    "# print(len(test_patches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fff3dcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(val_patches), len(test_patches))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674d68da",
   "metadata": {},
   "source": [
    "# Create the Dataloader\n",
    "- also subset the datasets because they're big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b092c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221056\n",
      "57599\n",
      "42960\n"
     ]
    }
   ],
   "source": [
    "#trim all datasets untill they are 1/10th of the size \n",
    "\n",
    "train_dataset, discard = torch.utils.data.random_split(train_data, [int(len(train_data)*.2), int(len(train_data)*.8)+1])\n",
    "print(len(train_dataset))\n",
    "\n",
    "val_dataset, discard = torch.utils.data.random_split(val_data, [int(len(val_data)*.2), int(len(val_data)*.8)])\n",
    "print(len(val_dataset))\n",
    "\n",
    "test_dataset, discard = torch.utils.data.random_split(test_data, [int(len(test_data)*.2), int(len(test_data)*.8)+1])\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f7e08dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset = val_dataset, batch_size = batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafc3421",
   "metadata": {},
   "source": [
    "# Load Model\n",
    "- Also change the architecture slightly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f810af2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.hub.list(\"pytorch/vision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f925da1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /dartfs-hpc/rc/home/9/f003xr9/.cache/torch/hub/pytorch_vision_main\n",
      "/dartfs-hpc/rc/home/9/f003xr9/anaconda3/envs/jupyter_ultimate/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "/dartfs-hpc/rc/home/9/f003xr9/anaconda3/envs/jupyter_ultimate/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision', 'resnet50', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a9006ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 0\n",
      "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "Layer: 1\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Layer: 2\n",
      "ReLU(inplace=True)\n",
      "Layer: 3\n",
      "MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "Layer: 4\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "Layer: 5\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "Layer: 6\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (4): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (5): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "Layer: 7\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "Layer: 8\n",
      "AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "Layer: 9\n",
      "Linear(in_features=2048, out_features=1000, bias=True)\n"
     ]
    }
   ],
   "source": [
    "#visualize the layers \n",
    "ct = 0\n",
    "for child in model.children():\n",
    "    print(\"Layer: %d\" %(ct))\n",
    "    print(child)\n",
    "    ct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "21e169b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) 0\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) 1\n",
      "ReLU(inplace=True) 2\n",
      "MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False) 3\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ") 4\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ") 5\n"
     ]
    }
   ],
   "source": [
    "#we can also set the first, say, n layers to be frozen, and leave the remaining layers unfrozen, as follows \n",
    "thresh = 5\n",
    "ct = 0\n",
    "#here we freeze up to and including the 6th layer\n",
    "for child in model.children():\n",
    "    if ct <= thresh:\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = False\n",
    "        print(child, ct)\n",
    "        ct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7277af15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=100, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=100, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change the model architecture a bit (for vision transformer)\n",
    "model.fc = nn.Sequential(nn.Linear(2048, 100), \n",
    "                         nn.ReLU(), \n",
    "                         nn.Dropout(p=.5), \n",
    "                         nn.Linear(100,2))\n",
    "model\n",
    "\n",
    "model.train()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a264ea7",
   "metadata": {},
   "source": [
    "# Model Training \n",
    "- Still need to implement some standard data augmentation (i.e., rotation, flip, contrast, etc...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d30698f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy on training to see how good our model is\n",
    "def check_accuracy(loader, model):\n",
    "    model.eval() #put model in testing\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    correct = {0:0, 1:0}\n",
    "    total = {0:0, 1:0}\n",
    "    with torch.no_grad():\n",
    "        for x, y, name in tqdm(loader):\n",
    "            #put batches on gpu \n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "\n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)\n",
    "            for i,j in zip(predictions, y):\n",
    "                if i.item() == j.item():\n",
    "                    correct[i.item()] +=1\n",
    "                total[j.item()] += 1\n",
    "                num_correct += (predictions == y).sum()\n",
    "                num_samples += predictions.size(0)\n",
    "\n",
    "        print(\n",
    "              f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}\"\n",
    "          )\n",
    "        acc = num_correct/num_samples\n",
    "        #find the accuracies for each class \n",
    "        return acc, correct, total\n",
    "\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "482a4999",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparams\n",
    "learning_rate = 5e-4\n",
    "num_epochs =2 #20 works well - it seems as tho it is a local min "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5a9877ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "softmax = nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b13ba56",
   "metadata": {},
   "source": [
    "Some notes\n",
    "1. Might need to figure out another loss that works better with one hot encoding \n",
    "2. Also might need to figure out how to calc AUC-ROC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fa1c5899",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1727it [06:02,  4.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at epoch 0 is 0.15390736565692756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 336/336 [01:18<00:00,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9328128313099315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1727it [05:50,  4.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at epoch 1 is 0.12532120393227827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 336/336 [01:17<00:00,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9350766945528175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Loss and optimizer\n",
    "import torch.optim as optim  # For all Optimization algorithms, SGD, Adam, etc.\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterion = tgm.losses.FocalLoss(alpha=0.5, gamma=2.0, reduction='mean') #experimenting with focal loss \n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=.1, patience=5, verbose=True)\n",
    "#arrays to track the training loss and validation loss \n",
    "training_loss = []\n",
    "validation_auc= []\n",
    "\n",
    "# Train Network\n",
    "for epoch in range(num_epochs):\n",
    "    losses = []\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    #train part \n",
    "    for batch_idx, (data, targets) in tqdm(enumerate(train_loader)):\n",
    "        # Get data to cuda if possible\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "        \n",
    "        # forward\n",
    "        with torch.cuda.amp.autocast():\n",
    "            scores = model(data)\n",
    "            loss = criterion(scores, targets)\n",
    "            # print(\"Batch: %d. Loss: %f\" %(batch_idx, loss))\n",
    "\n",
    "        losses.append(loss.item()) # add loss\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        # gradient descent or adam step\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "    \n",
    "    mean_loss = sum(losses)/len(losses)\n",
    "    training_loss.append(mean_loss)\n",
    "    scheduler.step(mean_loss)\n",
    "\n",
    "    print(f\"Cost at epoch {epoch} is {sum(losses)/len(losses)}\")\n",
    "    \n",
    "    #model in test mode \n",
    "    model.eval()\n",
    "    probabilities = torch.Tensor([])\n",
    "    ground_truth = torch.Tensor([])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(test_loader):\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "            #find the probs\n",
    "            scores = softmax(model(x))\n",
    "\n",
    "            #move to cpu\n",
    "            scores = scores.detach().cpu()\n",
    "            y = y.detach().cpu()\n",
    "\n",
    "            #concat them \n",
    "            probabilities = torch.cat((probabilities, scores))\n",
    "            ground_truth = torch.cat((ground_truth, y))\n",
    "\n",
    "        #calc total acc here \n",
    "        auc = roc_auc_score(ground_truth, probabilities[:, 1])\n",
    "        print(auc)\n",
    "        validation_auc.append(auc)\n",
    "    #put the model back in train mode\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c93bae4",
   "metadata": {},
   "source": [
    "# Find/Calc/and Make AUC-ROC plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "706a797d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 336/336 [01:17<00:00,  4.33it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "probabilities = torch.Tensor([])\n",
    "ground_truth = torch.Tensor([])\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in tqdm(test_loader):\n",
    "        x = x.to(device=device)\n",
    "        y = y.to(device=device)\n",
    "        #find the probs\n",
    "        scores = softmax(model(x))\n",
    "        \n",
    "        #move to cpu\n",
    "        scores = scores.detach().cpu()\n",
    "        y = y.detach().cpu()\n",
    "        \n",
    "        #concat them \n",
    "        probabilities = torch.cat((probabilities, scores))\n",
    "        ground_truth = torch.cat((ground_truth, y))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6b7c8745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06492330665034625\n",
      "0.9350766945528175\n"
     ]
    }
   ],
   "source": [
    "#predict the whole test cohort AUC-ROC\n",
    "\n",
    "print(roc_auc_score(ground_truth, probabilities[:, 0]))\n",
    "print(roc_auc_score(ground_truth, probabilities[:, 1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "18d4bf5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAA8nUlEQVR4nO3dd3hUZfbA8e8RCKGzFFGaoHQVUBGxy2IBC+rasOvqj7VgwUXFtqhYUNS1gYiouBZQWVQsCDZEYRVRQToiUkKTIp0ASc7vj3NjhphMJmVyZ5LzeZ55pt25c3IZ7rnv+957XlFVnHPOufzsFXYAzjnnEpsnCuecc1F5onDOOReVJwrnnHNReaJwzjkXlScK55xzUXmicHEjIveKyGthx5EXERkmIvdEeV9FpEVpxlSWicgVIvJ12HG4ovFEkUREZGvELUtEdkQ8v7gI65skIlcXsExKsMP/WUS2icgSEXlJRJoV+Q8pIhEZKSIPlMS6VPUaVR1YEuvKi4icECSb2/J4PS2P5ff4txCRViLytoisE5FNIvKTiNwiIhXy+b5JIpIe/BbWichYEdk31zLtRGRcsL4tIvKFiByVa5mE+fcuDhHpIyLTRWSniIwMO55k54kiiahq9ewbsAw4I+K11+P0tWOAnsBFQC2gA/A90C1O35en/HaQCexyYENwXygicgDwLbAcOFhVawHnAZ2AGlE+2if4bbQAqgOP5VrnFGAW0BxoCLwDTBSRIyPWkRD/3iVgJfAA8FLYgZQJquq3JLwBS4ATg8d7Af2BX4D1wFtAneC9VOC14PWNwHdAA+BBIBNIB7YCz+bxHScCO4AmUeJoCIzDdoqLgP+LeO/eIJb/AFuAOUCniPfbApOCuOYAPSPeGwk8B3wEbAN6A7uBXUG87+cRS2oQb73g+d1ABlAzeP4A8GTE+h+I+OytwCpsB/N3QIEWwXuVsZ3uMmANMAyoEmWbVA3+3l5BvJF/8wlAWh6fmQRcHTx+DfiwkL+HPz4fPL8OmBPx/FXgozw+9xwwOdZ/7xjiaAKMBdYGv7lng9evAL6OWO4pLBFuxhLRsRHvdQamB++tAZ6I9lsuIJ4HgJFh/39N9pu3KMqGG4GzgOOxHffvwJDgvcuxI8MmQF3gGmCHqt4FfEVwFKqqffJY74nANFVdHuW7RwFpwfeeCzwkIpFHnz2B0UBtLKE8CyAilYD3gYnA3sANwOsi0jrisxdhCa0GlmxeBx4N4j0jdyCqmo7tPI4PXjoOWAocHfH8y9yfE5HuQD/gJKBl8HdHegRoBXTEjtYbAf/Kd4vAOVgyexuYAFwWZdm8nIgd2ReJiNQF/oYl7mwnBfHk9hZwtIhUJYZ/bxHpLyIf5PNeBeADbJs3w7bT6HxW9R22PesAbwBvi0hq8N5TwFOqWhM4IIgR8vkt5xerKzmeKMqGfwB3qWqaqu7EjuTPFZGK2FF4XezoOFNVv1fVzTGuty52lJ0nEWkCHAPcrqrpqjoDGAFcGrHY16r6kapmYke1HYLXu2DdI4NUdZeqfo7tZC6M+Ox7qjpFVbOCJBCLL4Hjg7+9PfB08DwVOBxLjrmdD7ysqrNVdRu2/bL/RgH+D+irqhtUdQvwENZayM/lwJvB3/wGcGGQGGMVdbtH8bSIbALWAfWw5JutXj7rXIXtB/4Sy/eq6iBVPT2ftztjBwy3quq24DeR5wC2qr6mqutVNUNVH8dabdkHCbuBFiJST1W3quo3Ea8X9bfsisETRdmwH/COiGwUkY3APKxbqQG2c54AjBaRlSLyaCF2WuuBfaO83xDI3nlmW4odSWZbHfF4O5Aa7MQbAstVNSvKZ6O1ZBCRiyMG88cHL3+Jde8civXHf4K1MLoAi1R1XT5/R+R3LY14XB/rSvo+Yvt+HLyeV0xNgK5Y6wfgPazL5LTgeQaQ1/avhO0IoYDtHpyxlf133xnx1o1q4xntsR1/44j31uWzzn2BLKwVWtC/d0GaAEtVNaOgBUXknyIyLxhY34i1FOoFb1+FteDmi8h3IpKdmIrzW3bF4ImibFgO9FDV2hG3VFVdoaq7VfU+VW0HHAWcTk5XSEGlgz8FOotI43zeXwnUEZHIAdamwIoYYl4JNBGRyN9g7s/mjm+P56r6uuYM5vcIXp6KHZmeDXypqnOD9Z5GHt1OgVXYTi4yjmzrsO6NAyO2bS21QeO8XIr9v3pfRFYDi7FEkb3NlwH1ROSPzwetlv3ISVCfYt1XeVI7Yyv7734oj/dnYX3zQ4J1Z6/zvDxWdz7wP1XdTsH/3gVZDjQNDgTyJSLHArcH3/0XVa0NbAIkiP9nVb0Q65J8BBgjItUK+C27OPJEUTYMAx4Ukf0ARKS+iJwZPO4qIgcH/cebsaPWzOBza4D981upqn6KHZG/IyKHiUhFEakhIteIyN+DvuypwMMikioi7bGjwVjOwPoWG6S+TUQqicgJwBnk36ddYLxBzNuxwdHryUkMU7HuufwSxVvAFcHpo1WBARHrywJeAP4tInsDiEgjETkln3VdBtyH9b9n384BThORuqq6DPvbHxGR6iJSGRtIzwCyu1gGAEeJyGAR2Sf4zhYi8pqI1I7290d4BdvR9gye3xes80ERqRP8O94QxHt78LdG/feO4TunYUl3kIhUC34TR+exXI3g710LVBSRfwE1s98UkUtEpH6w7TcGL2cW8FveQxB7KlABqBDEEjWBufx5oigbnsIGiieKyBZsh3NE8N4+2MDoZqxL6kvszJHsz50rIr+LyNP5rPtc7MyjN7GjvtnYaZqfBu9fiA1crsROtxygqp8UFLCq7sJ2Yj2wo/ahwGWqOj/Kx14E2gVdQO9GWe5LrCtnWsTzGsDkfGIZDzwJfI4NAH+ea5Hbg9e/EZHN2N/eOtcyiEgXbFsMUdXVEbdxweezx18uwHbii7AWVDfg1OxxGFX9BTgyWNecYNzhv9iZQJHdfPkKtu/TwD3B85+x8aQO2Blzq7AEdoqqTon4aNR/bxG5M6KbL/d3ZmLJvgXWckoL/tbcJgDjgYVYKyqdPbv+ugd/91bsN9or2DbRfsu53Y21BPsDlwSP785nWVcAUfWJi5xzzuXPWxTOOeeiiluiELvs/zcRmZ3P+yIiT4vIIrHyBIfGKxbnnHNFF88WxUisrzE/PbCLm1piV90+F8dYnHPOFVHcEoWqTsbKOuTnTOA/ar4BakuuImbOOefCF+bpYo3Y80yHtOC1P10ZKiK9sVYH1apVO6xNmzalEqBzruRlZUFmpt1nZUFGcHmeqt1274a99sp5nt97O3fuudzu4HJFkT9/dudOqFgx5/Xs782+yqQsn9OzD6vYl9X8SNY6Vc3zQtGChJkoJI/X8vznUtXhwHCATp066fTp0+MZl3PlWmYm7NgBmzfDqlWwZQukp0NaGqSk2E531y5YsgRq1rTnO3faMhs3wty5ULu2PV+yBCpVss9m5nnFQ9GlpFgcjRrZ45QUWLsWmjeHypUtMUTe1qyBli1zlt21y2KrXz9nmQoVcu43bYImTWyZ7Nu2bVCvniUokfzvo70HlqiqVMlZNvsG0Z8X6jVVZC+hyifjqPLVRGq8MmQpRRRmokhjz6thG2Pn4jvnCqAK27fbbfNm2ymnp8O6dbYTWhrsEtaty9nR//wz/OUvlgTmz7ed+cyZ9tru3bbj3Lix8LGI2I65cmVbV40asHAhtGkDhx4KGzbASSdZHK1bQ9WqlmCqVYPUVPvuyJ19hQo564vc0WfvxCtXts/9cc2529Pvv0O/frD//nDXXXBVT7u9MqTgz+YjzEQxDugjIqOxi8M2qWpRCqE5lzR27YLffrOj25XBYVH2EfmWLbB1q+1ka9SwHfqWLfY8+wg/OynsKETN1NRUu6Wk2E67TRuoXt2SSNeuFtP+++fsmHfssKPyatVyjrb33deOgFNSLLaUFFu+ShU70vaddoJ45x247jprWt1dctcXxi1RiMgorDhbPbEZvQYQFENT1WHY1Z+nYlenbgeujFcszhWVqu1cV660o+0NG3J27MuX2850505Yv9524tu3WxJYvtx2xunpsGCBHUHv2GGJIFb16tnRd506dtTdpQvsvbft9CtXtm6QAw6wLo2UFNupp6bajr1BA/vOvfe2ZV0Zt2YN3HADvP02dOwIH35ozbkSErdEERT1iva+YvV4nCs1qnaUnpYGy5bZbeNGmD3bXt+1y/rYa9WyFvyaNZYIYlW1qu2s99nHEkebNtCuna2rXTtb7z772I48e+ee3ZVSrZrt3KtWtW4W52K2fLklhwcfhFtvtWZeCfIiWa5MyMy0Lp3Nm2H1atvB//CDvbdmjXXfTJ2a/+dTgylz2rSBxo3tyP+YY2yn3qiRdbEccADUrZtzRF+pknXDRPanO1dqli6F99+HPn2gUyc76qlbNy5f5T9tl9B277Yzb3791Q6aVq2yRPDbbzY4m5Fhr//2W/7r2HdfO9vlrLOsddC1q7223352q1PHjuL38oI2LhlkZcFzz0H//vb8nHPsBx2nJAGeKFyC2LXLun/+9z/46itrGUyalPegbXYffGqq7eR79rSj/kqVoFkz67Zp1coGaGvV8oFWV4YsWABXXw1ffw2nnALPP29JIs48UbhSk5EBv/wCP/5og7xz5lh30Jo11mLIipjrrnZt6N7djvQPPNASwCGH2P+JmjV95+/Koe3brT80MxNGjoTLLiu1/wieKFyJ2r3bEsC8eXZWzqJFdhA0b549zuuiq8MPhwsusIRw0EHWTVSlSunH7lxCWrjQ/lNUrQqvvmpnNe2zT6mG4InCFdmKFfDf/1oS2LrVWgeLF++5TIUK1gXUqhWcfbb93lu2tNM2GzSwloNzLg/p6TBwIDzyiLUgLrnEmtkh8EThCpSVZQc1aWl26uhnn8GUKXbtQKSuXe3WurV1EzVrBk2b2mmgzrlCmDIFrrrKmuNXXgmnnRZqOJ4o3B527bLTSr//HqZNg2++sbPu0tNzlqlSxVoIl19uXUbt2+ecXuqcK6aBA2HAADvKmjABTj457Ig8UZRnqnam0YQJ8OmnVv9n2bKcSpq1a8Pxx8Opp1oroVEju9izYUMfTHauxKnaf6yOHe0q6wcftMv7E4AninJm2zYYN866PCdNshYEWLmIffaBiy6y002POsoSgycE5+Jswwbo2xdatIB77oEzzrBbAvFEUcZlZlr30auvWuvhu+8sOdSoYWcbnXoqXHyxXXjmnCtlY8bA9ddbsrjnnrCjyZcnijIoI8Oux3nzTRg7Nueq5X33tRbtSSfBiSd6PSHnQrNqlZXeGDsWDjsMJk6EDh3CjipfnijKiN9+s7IvI0daksh2zDHw6KOWHBo2DC0851yklSttcPCRR+CWWxK+UFhiR+ei2rwZnn7aEsPEiTmD0KedZl1KF1wQ1/IvzrnCWLLEjuZuuMFaEcuX20xPScATRZJRtQvcnn8eXnopZ36DW26BM8+0IpJVq4Ybo3MuQmYmDBkCd95plSfPO8/OHEmSJAGeKJLGsmXw1ltw//02b0KFCpYYrrsOTjjBxxucS0jz5lkRv6lT7arq558v9fIbJcETRQJbutTOVnrnnZy5FfbdF/7v/+Cmm+x6HOdcgtq+HY47zkob/Oc/VoIjSc8390SRYHbsgI8+gtdftwQB1p15773WgujQIWl/a86VD/Pn2xWqVavaf+QOHaywWRLzRJEg5s6FoUPtd7Vxo82jcOWVcPvt9ptzziW4HTvsiO6xx+CVV6wFkQDlN0qCJ4oQZWZa6+GJJ+wq6YoVrdVw6aV21lIJT3vrnIuXyZNtLOLnn+3+9NPDjqhEeaIIwe7ddsbSo49aWe66de2EiGuvtfmanXNJ5L77rCXRvLkVTevWLeyISpwnilKUlgb/+pfN4bB5M7RrB6NGWW0lP6XVuSSTXcSvUyer1TRwIFSrFnZUceGJohQsWQIPP2xXTe/aBeeea7MYnnaanVbtnEsi69ZZYmjZ0o78Tjst9Pki4s13U3G0aRPcfTe0aQMjRliCWLAA3n7bikN6knAuiajaxUzt2sHo0eXqP7C3KOIgM9Ouf7jjDli92g42Hn/cz15yLmmtXGlXt773nnU1ffqpzdhVTniiKGHjx1s5jfnz4YADbEbDo44KOyrnXLGsXg2ffw6DB8PNNyd8Eb+SVn7aTnG2ebMdcJx6qnVhvvCCnSnnScK5JLV4MTz5pD0+9FCro9OvX7lLEuAtihKxapWNOXz/vU0CNHQo1KwZdlTOuSLJzLSyzHfdZRcz9epl9Zlq1w47stB4i6KYJkyAzp2t9teoUfDaa54knEtac+bA0Udb//Ff/2rPk7CIX0nzFkURqdoZck89ZWfJffGFJQznXJLavh2OP96ujXjjDWtJeGE1wBNFkWzebGVc3n/frocYOrTMXmfjXNk3dy60bWtXvY4ebUX86tcPO6qE4l1PhbRxI5xyCnzwgc0NMXKkJwnnktL27XDrrXDwwdZnDDaZvCeJP/EWRSH88oud1fTLLzktU+dcEpo0ySZ2WbQI/vEPq6Pj8uUtihgtWGBjXKtXw7hxniScS1oDBkDXrjbQ+PnnMGyY1fV3+fJEEYNNm6xqcHq6DVqfemrYETnnCk3V7jt3hn/+E376yRKGK1BcE4WIdBeRBSKySET65/F+LRF5X0RmisgcEbkynvEUxdq10KOHtVBHjbLrbpxzSWTtWrjoIhtUBKup89hjXrK5EOKWKESkAjAE6AG0Ay4UkXa5FrsemKuqHYATgMdFJCVeMRXW8uXQpQtMn25jXT16hB2Rcy5mqjaY2LYtjBkDKQmza0k68RzM7gwsUtXFACIyGjgTmBuxjAI1RESA6sAGICOOMcUsM9PGupYvt8mrunQJOyLnXMzS0mwmsA8+gCOOgBdfhAMPDDuqpBXPrqdGwPKI52nBa5GeBdoCK4FZwE2qmpV7RSLSW0Smi8j0tWvXxiveP6jC5ZfbVdcPPuhJwrmks3atHeE98YRV5vQkUSzxTBR5XdKouZ6fAswAGgIdgWdF5E8FMFR1uKp2UtVO9UvhHOe+feH11+Hvf7fTrJ1zSWDRIvj3v+3xIYdYd0DfvlChQrhxlQHxTBRpQJOI542xlkOkK4GxahYBvwJt4hhTgV5+2cpynHeeTTbknEtwGRk2OH3wwTZ/9Zo19roXXSsx8UwU3wEtRaR5MEDdCxiXa5llQDcAEWkAtAYWxzGmqL79Fq6+2kqDv/yyl3lxLuHNmmX/YW+9FU4+2Yr4NWgQdlRlTtwGs1U1Q0T6ABOACsBLqjpHRK4J3h8GDARGisgsrKvqdlVdF6+Yotm1C/72N6hb106D9bIcziW47dvtOoi99rIaTeef70d3cRLXEh6q+hHwUa7XhkU8XgmcHM8YYvXIIzbb4dix0LRp2NE45/I1e7YNTletCm++aUX86tULO6oyza/Mxmo3DRpkV1yffXbY0Tjn8rRtm80T0b59ThG/bt08SZSCcl8UMCsLrrzSTox4/vmwo3HO5emzz+zCpl9/tTmHzzwz7IjKlXLfonjuOfjqK3j4YWjcOOxonHN/cs89Vv67YkX48ksYMsTPaCpl5TpRrFhhv8FOnewgxTmXQLKCa2+POgpuuw1mzoTjjgs3pnKq3CaKrCw491yrCPvCC36yhHMJ47ffrI7/fffZ8x497GyTKlXCjascK7eJYtIk+OYbKyjZsWPY0TjnULVB6rZt4Z13vLprAimXiSIjw67sr1vXLrBzzoVs+XKb9OXSS6F1a/jxR7j99rCjcoFyedbTU0/ZnCVvvAG1a4cdjXOO9euteN9TT8H113t9pgRT7hJFZqYVlDziCJ/O1LlQLVxo8wr362f9v8uXQ40aYUfl8lDuup7ef9+uwL7hBh/Adi4UGRk2ON2+vdXxzy7i50kiYZW7RPHII9CkiVWHdc6VspkzrTnfv7+VQpg714v4JYFy1fU0d66d6XTffT4ronOlbvt2K7lRsaJNTXrOOWFH5GJUrhLFsGHW3eRnOjlXin76yeaKqFoV3n7bivjVqRN2VK4Qyk3X044dMHIk9OwJDRuGHY1z5cDWrXDTTTZQ/eqr9lrXrp4kklC5aVG89x5s2WJ1xZxzcfbJJ9C7NyxZAn36eFnmJFcuWhQ7dtgV2M2awSmnhB2Nc2XcXXfZbHOVK1vFzWee8TOaklzMiUJEknbOt+efh3nzbBC7YrlpQzlXyrKL+B1zDNxxB8yYYY9d0iswUYjIUSIyF5gXPO8gIkPjHlkJGjPGznK65JKwI3GuDFq92ips3nuvPe/RAx56CFJTQw3LlZxYWhT/Bk4B1gOo6kwgaWr9bt4M06bBBRfY1LrOuRKiameItGsHH3zgc0SUYTF1xKjqctnzMubM+IRT8iZPht274fLLw47EuTJk6VIbrJ440bqXRoywYn6uTIrlGHu5iBwFqIikiEg/gm6oZPDcc1C9ul0M6pwrIRs3wnffwbPP2qxzniTKtFgSxTXA9UAjIA3oCCTFfHBZWTB+vB3wVK8edjTOJbkFC2DwYHvcoQMsW2aVXr1Pt8yL5V+4taperKoNVHVvVb0EaBvvwErC1KnWjXrWWWFH4lwS273bJpXv0AEGDbIZ6MCPvsqRWBLFMzG+lnA++8zuzz033DicS1o//mj9tnfeCWecYQXT9t477KhcKct3MFtEjgSOAuqLyC0Rb9UEkmJWkbFj7YSMunXDjsS5JLR9O5x0ElSqBP/9L/ztb2FH5EISrUWRAlTHkkmNiNtmIOGP0TMzYfFiaNEi7EicSzI//mh9tlWr2kVIc+d6kijn8m1RqOqXwJciMlJVl5ZiTCXi88+tJtnFF4cdiXNJYssWu6J6yBB45RW47DI44YSwo3IJIJbrKLaLyGDgQOCPSy1V9a9xi6oEvPaatZh79gw7EueSwMcfwz/+YdOR3nSTtyDcHmIZzH4dmA80B+4DlgDfxTGmEvHWW1YE0KsIOFeAO+6wshvVqsGUKfDkk35Gk9tDLC2Kuqr6oojcFNEd9WW8AyuO33+H9HQ48MCwI3EugWVmQoUK1r1UsSLcfbdVfHUul1gSxe7gfpWInAasBBrHL6TimzLF7q+/Ptw4nEtIq1bZf44DD4SBA632vtffd1HE0vX0gIjUAv4J9ANGADfHM6ji+ugju+/SJdw4nEsoqvDyy3bO+Pjx8Je/hB2RSxIFtihU9YPg4SagK4CIHB3PoIpr/nybG9u7WZ0LLFli0zt++ikce6wV8WvVKuyoXJKIdsFdBeB8rMbTx6o6W0ROB+4EqgCHlE6IhbdqFRx+eNhROJdANm2CH36AoUPt7Cavz+QKIdqv5UXgaqAu8LSIvAw8BjyqqjElCRHpLiILRGSRiPTPZ5kTRGSGiMwpiUHyZcusReFlO1y5N3eu1WaCnCJ+117rScIVWrSup05Ae1XNEpFUYB3QQlVXx7LioEUyBDgJqzr7nYiMU9W5EcvUBoYC3VV1mYgUu4jMV1/Z/XFJM7WScyVs1y549FEbqK5RA/7+d6vPVC1pZzN2IYt2aLFLVbMAVDUdWBhrkgh0Bhap6mJV3QWMBs7MtcxFwFhVXRZ8z2+FWH+ePv0U6tSBww4r7pqcS0LTp1u/6z332EVzXsTPlYBoLYo2IvJT8FiAA4LnAqiqti9g3Y2A5RHP04Dc0we1AiqJyCSsjtRTqvqf3CsSkd5Ab4CmTZtG/dKZM6FjRzst3LlyZds2O801NRXee8/LErgSE213Wtw5JySP1zSP7z8M6IYNkP9PRL5R1YV7fEh1ODAcoFOnTrnX8YdNmyxR9OtXrLidSy4//GBHR9WqwTvvQPv2ULt22FG5MiTfridVXRrtFsO604AmEc8bYxfr5V7mY1XdpqrrgMlAh8L+EdlmzrRZ7Y49tqhrcC6JbN4M111n/ayvvWavHXecJwlX4uJ5+sN3QEsRaS4iKUAvYFyuZd4DjhWRiiJSFeuaKvJ83N9/b/cHH1zUNTiXJD76yK6sfv55uOUWOOecsCNyZVjcevJVNUNE+gATsImOXlLVOSJyTfD+MFWdJyIfAz8BWcAIVZ1d1O/87DNo2RL2268k/gLnEtTtt9tZTe3a2XwRR+Qe+nOuZMWUKESkCtBUVRcUZuWq+hHwUa7XhuV6PhgYXJj15mfGDC+f78ooVetXrVABunWzAes77/Qifq5UFNj1JCJnADOAj4PnHUUkdxdS6H77DVassHE858qUFSvgrLNgwAB7fvLJcN99niRcqYlljOJe7JqIjQCqOgNoFq+Aiir7QjsvBOjKDFV44QXrYpo4EerVCzsiV07F0vWUoaqbRPI62zVxzJlj936hnSsTfv0VrroKvvjC+lNfeMEngHehiSVRzBaRi4AKItISuBGYGt+wCm/KFKhf36sUuDJi61b46Sc7q+nqq70+kwtVLL++G7D5sncCb2Dlxm+OY0xFsm2blbVxLmnNng0PPWSPDz7Yivj17u1JwoUull9ga1W9S1UPD253B7WfEsovv/gZTy5J7dplg9OHHgr//redmQFQtWq4cTkXiCVRPCEi80VkoIgk5CzUO3fC6tV+/YRLQt99ZwNr994L553nRfxcQoplhruuIrIPNonRcBGpCbypqg/EPboYzZxp961bhxuHc4WybRt07w5VqsC4cXDGGWFH5FyeYur8VNXVqvo0cA12TcW/4hlUYc0OruU+9NBw43AuJtOn28Vz1apZldc5czxJuIQWywV3bUXkXhGZDTyLnfHUOO6RFcInn0ClSrD//mFH4lwUmzbZNKSHH55TxO+YY6BWrXDjcq4AsZwe+zIwCjhZVXNXf00Iixdb671ChbAjcS4f778P11xjg2n9+vlcvS6pxDJGkfDXOovYNRTOJaRbb4XHHrNTXt9911oUziWRfBOFiLylqueLyCz2nHAo1hnuSs3ChXDkkWFH4VwEVcjMtKkWTz4Zata0qq8pKWFH5lyhRWtR3BTcn14agRRHZqZ387oEkpYG115rFSoffBBOOsluziWpaDPcrQoeXpfH7HbXlU54Bdu1yyb6OjAhr/Bw5UpWlpXcaNcOPv8c9tkn7IicKxGxnB6b16FQj5IOpKg2bLB7v4jVhWrxYvjrX23AunNnmDULbrgh7KicKxHRxiiuxVoO+4vITxFv1QCmxDuwWGVXO/A6Ty5U27bZVdUjRsDf/25nWDhXRkQbo3gDGA88DPSPeH2Lqm6Ia1SFkH2xnXc9uVI3a5ZdMHf33XZG09Kldp62c2VMtK4nVdUlwPXAlogbIlIn/qHFZvFiu99333DjcOXIzp3wr39ZKYCnn85p1nqScGVUQS2K04HvsdNjI9vSCiTEddDbttl9kybhxuHKiW++sQmF5s6FSy+1aq9164YdlXNxlW+iUNXTg/vmpRdO4S1fDk2b+lXZrhRs2wannWY1mj76CHokzDkdzsVVLLWejhaRasHjS0TkCRFpGv/QYjNnDlSvHnYUrkz79tucIn7vv28/Ok8SrhyJ5fTY54DtItIBuA1YCrwa16gKYdUq7xp2cbJxo01D2qVLThG/o47yU+xcuRNLoshQVQXOBJ5S1aewU2QTQkoK1EmYoXVXZrz7rl04N3Kkld4477ywI3IuNLEkii0icgdwKfChiFQAKsU3rNiowtq1dmaicyXmllvg7LNtprlvv4VBg7zZ6sq1WMqMXwBcBPxdVVcH4xOD4xtWbFavhvR0aJ7Qw+0uKUQW8Tv1VDuT6bbbbKIT58q5AlsUqroaeB2oJSKnA+mq+p+4RxaD+fPt3kuMu2JZtszOZhowwJ6feCLcdZcnCecCsZz1dD4wDTgPmzf7WxFJiFlXtmyx+wMOCDcOl6SysmDoULus/8svoWHDsCNyLiHF0vV0F3C4qv4GICL1gU+BMfEMLBbZF8R6i8IV2qJFVpPpq6+sBPjw4dCsWdhROZeQYkkUe2UnicB6YhsEj7sVK+zeE4UrtPR0m/Hq5Zfh8su9iJ9zUcSSKD4WkQnYvNlgg9sfxS+k2C1dajWevMS4i8mMGVbEb8AAOOggWLIEUlPDjsq5hBfLYPatwPNAe6ADMFxVb493YLFYtw4aNAg7Cpfw0tNtcLpTJ3juuZw+S08SzsUk2nwULYHHgAOAWUA/VV1RWoHFYv16qF077ChcQps61Yr4zZ9vXUxPPOFXaDpXSNFaFC8BHwDnYBVknymViAphyxZPFC6KbdvgjDNg+3b4+GO7ytqThHOFFm2MooaqvhA8XiAiP5RGQIUxd65fle3y8L//wRFHWBG/Dz6w8Qivz+RckUVrUaSKyCEicqiIHApUyfW8QCLSXUQWiMgiEekfZbnDRSSzsNdn1KgBO3YU5hOuTPv9dzvl9aij4NWgbuWRR3qScK6YorUoVgFPRDxfHfFcgb9GW3FQE2oIcBKQBnwnIuNUdW4eyz0CTChM4KpW3LN168J8ypVZY8fC9ddb8a877oALLgg7IufKjGgTF3Ut5ro7A4tUdTGAiIzGKtDOzbXcDcB/gcMLs/LslsTOncWM0iW/vn3hySehY0ebUOiQQ8KOyLkyJZbrKIqqEbA84nkacETkAiLSCDgba53kmyhEpDfQG6BpU5szafNme69Fi5IL2CWRyCJ+p59ulV779fP6TM7FQTyvsM7rUlfN9fxJ4HZVzYy2IlUdrqqdVLVT/eAy7A0b7L1atYodp0s2S5ZA9+5wzz32vFs3627yJOFcXMQzUaQBTSKeNwZW5lqmEzBaRJYA5wJDReSsWFa+apXd+9mO5UhWFjzzjJ3FNHUq7Ldf2BE5Vy4U2PUkIgJcDOyvqvcH81Hso6rTCvjod0BLEWkOrAB6YfNa/EFV/5hJQkRGAh+o6ruxBJ6REfwB8ew8c4nj55/hyithyhRrTQwb5onCuVISS4tiKHAkcGHwfAt2NlNUqpoB9MHOZpoHvKWqc0TkGhG5pojx/iF7MLteveKuySWFXbvgl1/gP/+xAWtPEs6VmliOx49Q1UNF5EcAVf1dRFJiWbmqfkSuAoKqOiyfZa+IZZ3Z0tLs3meoLMN+/NGK+N17r80ZsWQJVK4cdlTOlTuxtCh2B9c6KPwxH0VWXKOKQXaXU7Vq4cbh4iA93QanDz8cnn/ero0ATxLOhSSWRPE08A6wt4g8CHwNPBTXqGKQPQ2qD2aXMV9/DR06wKBBcNllVqfFJxxxLlQFdj2p6usi8j3QDTvl9SxVnRf3yGLkLYoyZOtWOPNMqFkTJk60meecc6GL5aynpsB24P3I11R1WTwDK8jy5dCqVZgRuBLz9ddWn6l6dfjwQzv9tXr1sKNyzgVi6Xr6ECs3/iHwGbAYGB/PoGKxYgU0ahR2FK5Y1q+37qVjj80p4teliycJ5xJMLF1PexTyDirH/iNuEcVo61ZPFElLFcaMgT597BL7e+6BXr3Cjso5l49CX5mtqj9QyAJ+8ZCW5nNlJ62+feH886FJE5g+He6/389oci6BxTJGcUvE072AQ4G1cYsoRrt3+74lqaja5fSVKkHPntCwIdxyi19a71wSiKVFUSPiVhkbqzgznkEVZPdum92yYcMwo3Ax+/VXOPnknCJ+f/0r3HabJwnnkkTU/6nBhXbVVfXWUoonJlu3hh2Bi0lmJjz7LNx5J1SoAOedF3ZEzrkiyDdRiEhFVc2IddrT0pRd56lx43DjcFEsXAhXXGHzV/foYVdYN2lS4Mecc4knWotiGjYeMUNExgFvA9uy31TVsXGOLV8bN9q9j1EksIwMWLoUXnsNLroIJK/pSZxzySCWTuI6wHpsFjrFrs5WILREkT0XRWpqWBG4PE2fbkX8Bg6Edu1g8WLP5s6VAdESxd7BGU+zyUkQ2XLPVFeq0tPtfu+9w4zC/WHHDhgwAB5/HPbZB2680eozeZJwrkyIdtZTBaB6cKsR8Tj7FprsMQqvFZcAvvwS2reHwYPhqqtgzhz/h3GujInWolilqveXWiSFsCyoMuVzUYRs61b429+gdm347DM77dU5V+ZESxQJO/pYqZLd16gRbhzl1ldfwdFHW02m8eNtUiEv4+tcmRWt66lbqUVRSAsX2n2tWuHGUe6sWweXXALHHZdTxK9zZ08SzpVx+bYoVHVDaQZSGNlnO/lYaSlRhbfeghtugN9/t4FrL+LnXLmRlDUU5s2DevXCjqIcuekmeOYZm5r0s8/g4IML/oxzrsxIykRRowZs2RJ2FGWcqhXVSkmBs8+G/faDm2+2UhzOuXKl0GXGE8HPP9v1XC5OfvkFunWDu++25127wj//6UnCuXIqKRNFVpYXBoyLzEx44gnrWvr+e2jdOuyInHMJICm7njZutO5yV4Lmz4fLL4dp0+CMM+C553wKQecckKQtil9/hQYNwo6ijMnKgpUrYdQoq9fkScI5F0jKFgXklPFwxTBtmiWFBx+0QZ9ffrHBa+eci5B0LYqsLLtv1SrcOJLa9u3Qrx8ceSS88gqsDWa29SThnMtD0iaKqlXDjSNpffGFDVY//jj83/95ET/nXIGSruspM9Puvc5TEWzdatOR1q5tCeOEE8KOyDmXBJKuRZGdKGrWDDeOpDJpkjXFsov4/fSTJwnnXMySLlFkZNi9z6wZg7Vr4cIL7YK5116z1w4/3PvtnHOFknRdTxrMrefd6lGo2mmuN95otU4GDvQifs65Iku6RJE9mO2VraO44QYYMgS6dIEXX/R6J865Ykm6RLF7t937mZy5ZGVZv1xKCpx7LrRoYQnD6zM554oprmMUItJdRBaIyCIR6Z/H+xeLyE/BbaqIdChonXsFEftZTxF+/tmmIb3rLnt+wgle6dU5V2LilihEpAIwBOgBtAMuFJHcfSC/AserantgIDC8oPVmdz15iwJrQTz2GLRvDzNmQNu2YUfknCuD4tn11BlYpKqLAURkNHAmMDd7AVWdGrH8N0DjglaaPZhd7me3mzcPLrsMpk+HM8+EoUOhYcOwo3LOlUHx7HpqBCyPeJ4WvJafq4Dxeb0hIr1FZLqITN+0yYo8eYsCWLMG3nwT3nnHk4RzLm7imSjyutJB81xQpCuWKG7P631VHa6qnVS1U/XqVYCcebPLlW++gTvusMdt21oRv/PP94tKnHNxFc9EkQY0iXjeGFiZeyERaQ+MAM5U1fUFrVQVKlYsZ/vGbdugb1846ih4/fWcIn6VKoUbl3OuXIhnovgOaCkizUUkBegFjItcQESaAmOBS1V1YSwrVS1n3U6ffgoHHQRPPgnXXedF/JxzpS5ug9mqmiEifYAJQAXgJVWdIyLXBO8PA/4F1AWGijURMlS1U/T1lqMD6a1b7YrqOnVg8mQ49tiwI3LOlUOimuewQcKqXbuTikzn99/DjiSOPv8cjj/eroP4/nu7srpKlbCjcs4lMRH5vqAD8fwkXVHAihVtzuwyac0aG5zu1i2niN9hh3mScM6FKukShSoccEDYUZQwVXj1VWs5ZE9NetFFYUflnHNAEtZ6KpOD2ddfD889Z1OTvviiX2HtnEsoSZcodu8uI4PZWVn2x1SuDBdcYMnhuuu8PpNzLuEkZdfThg1hR1FMCxbYYHV2Eb/jj/dKr865hJV0iUIEGkUrBJLIdu+GQYOgQweYPRsOPjjsiJxzrkBJ1/WkmqSTFs2ZA5deCj/+CH/7m00stM8+YUflnHMFSspEkZRjFBUqWJ/ZmDFwzjlhR+OcczFLuq6npEoUU6fC7UGdwzZtYNEiTxLOuaSTdIli50676C6hbd0KN94IxxxjZcDXrbPXEz5w55z7s6RLFBUr5ux3E9LEiVbE79lnoU8fG7SuVy/sqJxzrsiS7hBXFVq0CDuKfGzdChdfDHXrwldfwdFHhx2Rc84VW9K1KFQTcBrUTz6BzEyoXt1aFDNmeJJwzpUZSZcoMjISKFGsWmWD0yefbBMKARxySDmdfs85V1YlXaIAWF/gPHhxpgojR1oRvw8/tIvovIifc66MSroxCkiAMYprr4Xnn7ezmkaMgNatQw7IucS0e/du0tLSSE9PDzuUciM1NZXGjRtTqQSvI0jKRBFKz05kEb+LLoL27eGaa2CvpGyUOVcq0tLSqFGjBs2aNUPK1UT34VBV1q9fT1paGs2bNy+x9SblXi4rq5S/cN48m4b0zjvt+XHHWaVXTxLORZWenk7dunU9SZQSEaFu3bol3oJLyj1dqQ1m794NDz0EHTvC/Pk2UO2cKxRPEqUrHts7Kbue6tYthS+ZMwcuucROdT3vPHjmGWjQoBS+2DnnEou3KPJTsSJs2gRjx8Jbb3mScC6JvfPOO4gI8+fP/+O1SZMmcfrpp++x3BVXXMGYMWMAG4jv378/LVu25KCDDqJz586MHz++2LE8/PDDtGjRgtatWzNhwoQ8l5k5cyZHHnkkBx98MGeccQabN2/e4/1ly5ZRvXp1HnvssWLHEwtPFJG++gr69bPHrVvDwoVw9tlx+jLnXGkZNWoUxxxzDKNHj475M/fccw+rVq1i9uzZzJ49m/fff58tW7YUK465c+cyevRo5syZw8cff8x1111HZmbmn5a7+uqrGTRoELNmzeLss89m8ODBe7zft29fevToUaxYCiMpu56qVi3hFW7ZAv37w9Ch0Ly5Pa5Xz4v4OVeCbr7ZenJLUseO8OST0ZfZunUrU6ZM4YsvvqBnz57ce++9Ba53+/btvPDCC/z6669UDo5MGzRowPnnn1+seN977z169epF5cqVad68OS1atGDatGkceeSReyy3YMECjjvuOABOOukkTjnlFAYOHAjAu+++y/7770+1UpyYJylbFCVaZnz8eDjwQHjuOfslz5rlRfycK0PeffddunfvTqtWrahTpw4//PBDgZ9ZtGgRTZs2pWbNmgUu27dvXzp27Pin26BBg/607IoVK2jSpMkfzxs3bsyKFSv+tNxBBx3EuHHjAHj77bdZvnw5ANu2beORRx5hwIABBcZVkpLykLnEEsWWLXDZZbD33jZ3RJcuJbRi51xuBR35x8uoUaO4+eabAejVqxejRo3i0EMPzffsoMKeNfTvf/875mVVNabve+mll7jxxhu5//776dmzJykpKQAMGDCAvn37Ur169ULFWFxJmSiK1SOkChMmwEknQY0a8OmnNqlQwhSQcs6VlPXr1/P5558ze/ZsRITMzExEhEcffZS6devy+++/77H8hg0bqFevHi1atGDZsmVs2bKFGjVqRP2Ovn378sUXX/zp9V69etG/f/89XmvcuPEfrQOwCxIbNmz4p8+2adOGiRMnArBw4UI+/PBDAL799lvGjBnDbbfdxsaNG9lrr71ITU2lT58+sW2QolLVpLrBYTptmhbNypWqZ52lCqqvvFLElTjnYjV37txQv3/YsGHau3fvPV477rjjdPLkyZqenq7NmjX7I8YlS5Zo06ZNdePGjaqqeuutt+oVV1yhO3fuVFXVlStX6quvvlqseGbPnq3t27fX9PR0Xbx4sTZv3lwzMjL+tNyaNWtUVTUzM1MvvfRSffHFF/+0zIABA3Tw4MF5fk9e2x2YrkXc7yblGEWhqcJLL0HbtvDxx/Doo17Ez7lyYNSoUZyd68zFc845hzfeeIPKlSvz2muvceWVV9KxY0fOPfdcRowYQa1atQB44IEHqF+/Pu3ateOggw7irLPOon79+sWK58ADD+T888+nXbt2dO/enSFDhlChQgXAznSaPn36H3G3atWKNm3a0LBhQ6688spifW9xiebRZ5bIRDrp3LnTadu2EB/6xz9g+HArvTFiBLRsGbf4nHM55s2bR9tC/Wd1JSGv7S4i36tqp6KsLynHKKpUiWGhzEwrwZGaaldYH3II9O7t9Zmcc66QknKvWWD12DlzbIa57CJ+xx7rlV6dc66IknLPme8JSrt2wcCB1npYtAgOP7xU43LO/VmydW8nu3hs76TsesqzRTFrFlx8sd336gVPPw3FHHhyzhVPamoq69ev91LjpUSD+ShSS3jSnqRMFHleR5GSAtu3w3vvQc+epR6Tc+7PGjduTFpaGmvXrg07lHIje4a7kpSUZz1lZU1HBPjySxg3Dh5/3N7MzITgVDPnnHM5inPWU1zHKESku4gsEJFFItI/j/dFRJ4O3v9JRA6Nab1bNtu81SecAO++C+vW2RueJJxzrsTFLVGISAVgCNADaAdcKCLtci3WA2gZ3HoDzxW03lpssiJ+w4fDLbd4ET/nnIuzeLYoOgOLVHWxqu4CRgNn5lrmTOA/wRXm3wC1RWTfaCttxhKoVcuK+D3+eBxqjjvnnIsUz8HsRsDyiOdpwBExLNMIWBW5kIj0xlocADtlzpzZXukVgHrAurCDSBC+LXL4tsjh2yJH66J+MJ6JIq9z4XKPnMeyDKo6HBgOICLTizogU9b4tsjh2yKHb4scvi1yiMj0on42nl1PaUCTiOeNgZVFWMY551yI4pkovgNaikhzEUkBegHjci0zDrgsOPupC7BJVVflXpFzzrnwxK3rSVUzRKQPMAGoALykqnNE5Jrg/WHAR8CpwCJgOxBLLd3hcQo5Gfm2yOHbIodvixy+LXIUeVsk3QV3zjnnSldSFgV0zjlXejxROOeciyphE0W8yn8koxi2xcXBNvhJRKaKSIcw4iwNBW2LiOUOF5FMETm3NOMrTbFsCxE5QURmiMgcEfmytGMsLTH8H6klIu+LyMxgW4Q7t2iciMhLIvKbiMzO5/2i7TeLOtl2PG/Y4PcvwP5ACjATaJdrmVOB8di1GF2Ab8OOO8RtcRTwl+Bxj/K8LSKW+xw7WeLcsOMO8XdRG5gLNA2e7x123CFuizuBR4LH9YENQErYscdhWxwHHArMzuf9Iu03E7VFEZfyH0mqwG2hqlNV9ffg6TfY9ShlUSy/C4AbgP8Cv5VmcKUslm1xETBWVZcBqGpZ3R6xbAsFaohNilEdSxQZpRtm/KnqZOxvy0+R9puJmijyK+1R2GXKgsL+nVdhRwxlUYHbQkQaAWcDw0oxrjDE8rtoBfxFRCaJyPciclmpRVe6YtkWzwJtsQt6ZwE3qWpW6YSXUIq030zUiYtKrPxHGRDz3ykiXbFEcUxcIwpPLNviSeB2Vc0s4zOqxbItKgKHAd2AKsD/ROQbVV0Y7+BKWSzb4hRgBvBX4ADgExH5SlU3xzm2RFOk/WaiJgov/5Ejpr9TRNoDI4Aeqrq+lGIrbbFsi07A6CBJ1ANOFZEMVX23VCIsPbH+H1mnqtuAbSIyGegAlLVEEcu2uBIYpNZRv0hEfgXaANNKJ8SEUaT9ZqJ2PXn5jxwFbgsRaQqMBS4tg0eLkQrcFqraXFWbqWozYAxwXRlMEhDb/5H3gGNFpKKIVMWqN88r5ThLQyzbYhnWskJEGmCVVBeXapSJoUj7zYRsUWj8yn8knRi3xb+AusDQ4Eg6Q8tgxcwYt0W5EMu2UNV5IvIx8BOQBYxQ1TxPm0xmMf4uBgIjRWQW1v1yu6qWufLjIjIKOAGoJyJpwACgEhRvv+klPJxzzkWVqF1PzjnnEoQnCuecc1F5onDOOReVJwrnnHNReaJwzjkXlScKl5CCyq8zIm7Noiy7tQS+b6SI/Bp81w8icmQR1jFCRNoFj+/M9d7U4sYYrCd7u8wOqqHWLmD5jiJyakl8tyu//PRYl5BEZKuqVi/pZaOsYyTwgaqOEZGTgcdUtX0x1lfsmApar4i8AixU1QejLH8F0ElV+5R0LK788BaFSwoiUl1EPguO9meJyJ+qxorIviIyOeKI+9jg9ZNF5H/BZ98WkYJ24JOBFsFnbwnWNVtEbg5eqyYiHwZzG8wWkQuC1yeJSCcRGQRUCeJ4PXhva3D/ZuQRftCSOUdEKojIYBH5TmyegH/EsFn+R1DQTUQ6i81F8mNw3zq4Svl+4IIglguC2F8KvufHvLajc38Sdv10v/ktrxuQiRVxmwG8g1URqBm8Vw+7sjS7Rbw1uP8ncFfwuAJQI1h2MlAteP124F95fN9IgrkrgPOAb7GCerOAalhp6jnAIcA5wAsRn60V3E/Cjt7/iClimewYzwZeCR6nYJU8qwC9gbuD1ysD04HmecS5NeLvexvoHjyvCVQMHp8I/Dd4fAXwbMTnHwIuCR7Xxuo+VQv739tviX1LyBIezgE7VLVj9hMRqQQ8JCLHYeUoGgENgNURn/kOeClY9l1VnSEixwPtgClBeZMU7Eg8L4NF5G5gLVaFtxvwjlpRPURkLHAs8DHwmIg8gnVXfVWIv2s88LSIVAa6A5NVdUfQ3dVecmbkqwW0BH7N9fkqIjIDaAZ8D3wSsfwrItISqwZaKZ/vPxnoKSL9guepQFPKZg0oV0I8UbhkcTE2M9lhqrpbRJZgO7k/qOrkIJGcBrwqIoOB34FPVPXCGL7jVlUdk/1ERE7MayFVXSgih2E1cx4WkYmqen8sf4SqpovIJKzs9QXAqOyvA25Q1QkFrGKHqnYUkVrAB8D1wNNYLaMvVPXsYOB/Uj6fF+AcVV0QS7zOgY9RuORRC/gtSBJdgf1yLyAi+wXLvAC8iE0J+Q1wtIhkjzlUFZFWMX7nZOCs4DPVsG6jr0SkIbBdVV8DHgu+J7fdQcsmL6OxYmzHYoXsCO6vzf6MiLQKvjNPqroJuBHoF3ymFrAiePuKiEW3YF1w2SYAN0jQvBKRQ/L7DueyeaJwyeJ1oJOITMdaF/PzWOYEYIaI/IiNIzylqmuxHecoEfkJSxxtYvlCVf0BG7uYho1ZjFDVH4GDgWlBF9BdwAN5fHw48FP2YHYuE7G5jT9Vm7oTbC6RucAPIjIbeJ4CWvxBLDOxstqPYq2bKdj4RbYvgHbZg9lYy6NSENvs4LlzUfnpsc4556LyFoVzzrmoPFE455yLyhOFc865qDxROOeci8oThXPOuag8UTjnnIvKE4Vzzrmo/h84J0EOhQpgLAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#from sophie's code - viz. the curve \n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# fpr and tpr of all thresohlds\n",
    "true = ground_truth\n",
    "preds = probabilities[:, 1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(true, preds)\n",
    "\n",
    "#get the metrics \n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "#plot\n",
    "plt.title('Test Cohort-wide AUC-ROC: class 1')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "38b28ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fpr and tpr of all thresohlds\n",
    "true = ground_truth\n",
    "preds = probabilities[:, 0]\n",
    "fpr, tpr, threshold = metrics.roc_curve(true, preds)\n",
    "\n",
    "#get the metrics \n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "#plot\n",
    "plt.title('Test Cohort-wide AUC-ROC: class 0')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6913543a",
   "metadata": {},
   "source": [
    "# Save Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768fafe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = \"/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/users/Gokul_Srinivasan/SCC-Tumor-Detection/Gokul_files/Saved_Models/resnet50.pt\"\n",
    "# torch.save(model.state_dict(), PATH) # here is how we save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2f486bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Dec 18 14:40:31 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:18:00.0 Off |                    0 |\n",
      "| N/A   37C    P0    55W / 300W |   3758MiB / 32768MiB |      0%   E. Process |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  Off  | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    51W / 300W |    754MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  Off  | 00000000:86:00.0 Off |                    0 |\n",
      "| N/A   27C    P0    39W / 300W |      3MiB / 32768MiB |      0%   E. Process |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  Off  | 00000000:AF:00.0 Off |                    0 |\n",
      "| N/A   30C    P0    40W / 300W |      3MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A    104863      C   ...pyter_ultimate/bin/python     3755MiB |\n",
      "|    1   N/A  N/A    104270      C   ...pyter_ultimate/bin/python      751MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f59d0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_ultimate",
   "language": "python",
   "name": "jupyter_ultimate"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
