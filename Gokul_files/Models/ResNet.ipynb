{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d15890bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch \n",
    "from tqdm import tqdm \n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob, os, pickle\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from PIL import Image\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "521ac4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c231ddc0",
   "metadata": {},
   "source": [
    "# Create Train/Test/Validation split \n",
    "- The patches that fall into the train, val, and test sets need to be from entirely distinct patient samples/WSI samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46f32ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write a different data loader class \n",
    "class Patch_Class():\n",
    "    def __init__(self, csv_path, root_dir, samples, transform=None):\n",
    "        self.samples = samples # this will contain the WSI samples that we want to include in the dataset\n",
    "        \n",
    "        self.patch_frame = pd.read_csv(csv_path) #get the metadata \n",
    "        #adjust the metadata so that it only contains data from the samples we want\n",
    "        self.patch_frame = self.patch_frame[self.patch_frame[\"ID\"].isin(self.samples)]\n",
    "        \n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        #we also need to build the patch dictionary, which maps sample_id to patch_id to status \n",
    "        self.patch_dict = {}\n",
    "        self.build_dictionary()\n",
    "        \n",
    "        #here, we also need to load in all of the distinct np arrays for each directory\n",
    "        self.data_dict = {}\n",
    "        self.build_data()\n",
    "        \n",
    "    def build_data(self):\n",
    "        #go through each sub dir in the main dir \n",
    "        for s_dir in tqdm(os.listdir(self.root_dir)):\n",
    "            #again, only build data for the relevant samples\n",
    "            if s_dir != \"metadata.csv\" and s_dir in self.samples:\n",
    "                data = np.load(self.root_dir + s_dir +\"/data.npy\")\n",
    "                self.data_dict[s_dir] = data #map the sample_id to the npy data \n",
    "                \n",
    "    def build_dictionary(self):\n",
    "        for sample in self.samples:\n",
    "            #now, for each sample, make the dictionary\n",
    "            self.patch_dict[sample] = {}\n",
    "        for id, group in tqdm(self.patch_frame.groupby(\"ID\")):\n",
    "            #only build dic for the samples that are needed\n",
    "            if id in self.samples:\n",
    "                for idx, group2 in group.groupby(\"patch_index\"):\n",
    "                    self.patch_dict[id][idx] = (group2[\"scc\"] == True)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.patch_frame)\n",
    "\n",
    "    def __getitem__(self, index):        \n",
    "        #1 is the file id\n",
    "        sample_id = self.patch_frame.iloc[index, 1]\n",
    "        patch_id = self.patch_frame.iloc[index, 8]\n",
    "        #get the image as a numpy array \n",
    "        img = self.data_dict[sample_id][patch_id]\n",
    "        \n",
    "        #turn the array into a PIL image, so that it can be resized and transformed\n",
    "        img = Image.fromarray(img.astype('uint8'), 'RGB') #this here takes a lot of time, and it considerably slows training\n",
    "        \n",
    "        #get y_label and one hot encode it\n",
    "#         ohe = [0, 0]\n",
    "        y_label = int(list(self.patch_dict[sample_id][patch_id])[0])\n",
    "#         ohe[y_label] = 1\n",
    "        y_label = torch.tensor(y_label)\n",
    "\n",
    "        if self.transform: \n",
    "            img = self.transform(img)\n",
    "        return (img, y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91573600",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform the function according to the pytorch docs\n",
    "from torchvision import transforms\n",
    "#add some image transforms \n",
    "# img_size = 224\n",
    "\n",
    "augmentations = transforms.RandomApply(torch.nn.ModuleList(\n",
    "            [transforms.RandomRotation((0,315)),\n",
    "            transforms.ColorJitter(brightness=.3, contrast=.3),\n",
    "#             transforms.RandomSolarize(.3),\n",
    "#             transforms.RandomInvert(), \n",
    "#             transforms.RandomAdjustSharpness(2),\n",
    "            ]), p=0.2)\n",
    "\n",
    "#it doesn't make sense to do this because the val/test sets also use preprocess. So we need a unique one for train. \n",
    "preprocess = transforms.Compose([\n",
    "#     transforms.Resize((img_size, img_size)),\n",
    "    #these are the random transforms I got from my other derm project\n",
    "#     augmentations, \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8339f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the directories we need\n",
    "\n",
    "path = \"/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/users/Gokul_Srinivasan/SCC-Tumor-Detection/Gokul_files/data/metadata.csv\"\n",
    "\n",
    "root_dir = \"/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/users/Gokul_Srinivasan/SCC-Tumor-Detection/Gokul_files/data/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94ac5602",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all of the sample names \n",
    "samples = []\n",
    "for f in os.listdir(root_dir):\n",
    "    if f != \"metadata.csv\":\n",
    "        samples.append(f)\n",
    "\n",
    "#split the sample names into train/test ~75/25\n",
    "train, test = torch.utils.data.random_split(samples, [21, 9])\n",
    "\n",
    "#further split train into train/validation\n",
    "train, val = torch.utils.data.random_split(train, [18, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "164d0582",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 18/18 [00:33<00:00,  1.85s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31/31 [00:18<00:00,  1.70it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:08<00:00,  2.89s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31/31 [00:03<00:00,  8.74it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:16<00:00,  1.83s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31/31 [00:08<00:00,  3.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# get all of the different kinds of patches \n",
    "\n",
    "train_patches = Patch_Class(path, root_dir, samples=set(train), transform = preprocess)\n",
    "val_patches = Patch_Class(path, root_dir, samples=set(val), transform = preprocess)\n",
    "test_patches = Patch_Class(path, root_dir, samples=set(test), transform = preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d024524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[ 2.0263,  2.0263,  2.0263,  ...,  0.5878,  0.4851,  0.2796],\n",
      "         [ 2.0263,  2.0263,  2.0263,  ...,  0.0056, -0.0458, -0.1828],\n",
      "         [ 2.0263,  2.0263,  2.0263,  ..., -0.4226, -0.4397, -0.4568],\n",
      "         ...,\n",
      "         [ 2.0092,  2.1462,  1.6838,  ...,  2.0434,  1.3755,  1.0331],\n",
      "         [ 2.0092,  2.1633,  1.5468,  ...,  1.7180,  1.2043,  1.0673],\n",
      "         [ 1.8208,  2.2318,  1.8893,  ...,  1.1187,  0.8789,  0.9474]],\n",
      "\n",
      "        [[ 2.2010,  2.2010,  2.2010,  ...,  0.1527,  0.0476, -0.1625],\n",
      "         [ 2.2010,  2.2010,  2.2010,  ..., -0.4076, -0.5126, -0.6001],\n",
      "         [ 2.2010,  2.2010,  2.2010,  ..., -0.8102, -0.8627, -0.8452],\n",
      "         ...,\n",
      "         [ 2.1835,  2.3235,  1.8508,  ...,  1.4307,  0.6954,  0.2927],\n",
      "         [ 2.1835,  2.3410,  1.7108,  ...,  1.0630,  0.4503,  0.2927],\n",
      "         [ 1.9909,  2.4111,  2.0609,  ...,  0.4328,  0.1176,  0.1702]],\n",
      "\n",
      "        [[ 2.4134,  2.4134,  2.4134,  ...,  1.3677,  1.2631,  1.0539],\n",
      "         [ 2.4134,  2.4134,  2.4134,  ...,  0.8099,  0.7576,  0.6182],\n",
      "         [ 2.4134,  2.4134,  2.4134,  ...,  0.4265,  0.4091,  0.3916],\n",
      "         ...,\n",
      "         [ 2.3960,  2.5354,  2.0648,  ...,  2.3263,  1.6465,  1.2631],\n",
      "         [ 2.3960,  2.5529,  1.9254,  ...,  2.0125,  1.4722,  1.3154],\n",
      "         [ 2.2043,  2.6226,  2.2740,  ...,  1.3851,  1.1411,  1.1934]]]), tensor(0))\n",
      "131817\n"
     ]
    }
   ],
   "source": [
    "print(test_patches.__getitem__(231))\n",
    "\n",
    "print(len(test_patches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fff3dcb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52540 131817\n"
     ]
    }
   ],
   "source": [
    "print(len(val_patches), len(test_patches))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674d68da",
   "metadata": {},
   "source": [
    "# Create the Dataloader\n",
    "- also subset the datasets because they're big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b092c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25415\n",
      "5254\n",
      "13181\n"
     ]
    }
   ],
   "source": [
    "#trim all datasets untill they are 1/10th of the size \n",
    "\n",
    "train_dataset, discard = torch.utils.data.random_split(train_patches, [int(len(train_patches)*.10), int(len(train_patches)*.9)+1])\n",
    "print(len(train_dataset))\n",
    "\n",
    "val_dataset, discard = torch.utils.data.random_split(val_patches, [int(len(val_patches)*.10), int(len(val_patches)*.9)])\n",
    "print(len(val_dataset))\n",
    "\n",
    "test_dataset, discard = torch.utils.data.random_split(test_patches, [int(len(test_patches)*.10), int(len(test_patches)*.9)+1])\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f7e08dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset = val_dataset, batch_size = batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafc3421",
   "metadata": {},
   "source": [
    "# Load Model\n",
    "- Also change the architecture slightly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f810af2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.hub.list(\"pytorch/vision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f925da1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /dartfs-hpc/rc/home/9/f003xr9/.cache/torch/hub/pytorch_vision_main\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision', 'resnet50', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a9006ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 0\n",
      "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "Layer: 1\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Layer: 2\n",
      "ReLU(inplace=True)\n",
      "Layer: 3\n",
      "MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "Layer: 4\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "Layer: 5\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "Layer: 6\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (4): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (5): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "Layer: 7\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "Layer: 8\n",
      "AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "Layer: 9\n",
      "Linear(in_features=2048, out_features=1000, bias=True)\n"
     ]
    }
   ],
   "source": [
    "#visualize the layers \n",
    "ct = 0\n",
    "for child in model.children():\n",
    "    print(\"Layer: %d\" %(ct))\n",
    "    print(child)\n",
    "    ct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "21e169b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) 0\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) 1\n",
      "ReLU(inplace=True) 2\n",
      "MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False) 3\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ") 4\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ") 5\n"
     ]
    }
   ],
   "source": [
    "#we can also set the first, say, n layers to be frozen, and leave the remaining layers unfrozen, as follows \n",
    "thresh = 5\n",
    "ct = 0\n",
    "#here we freeze up to and including the 6th layer\n",
    "for child in model.children():\n",
    "    if ct <= thresh:\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = False\n",
    "        print(child, ct)\n",
    "        ct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7277af15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=100, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=100, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change the model architecture a bit (for vision transformer)\n",
    "model.fc = nn.Sequential(nn.Linear(2048, 100), \n",
    "                         nn.ReLU(), \n",
    "                         nn.Dropout(p=.5), \n",
    "                         nn.Linear(100,2))\n",
    "model\n",
    "\n",
    "model.train()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a264ea7",
   "metadata": {},
   "source": [
    "# Model Training \n",
    "- Still need to implement some standard data augmentation (i.e., rotation, flip, contrast, etc...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d30698f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy on training to see how good our model is\n",
    "def check_accuracy(loader, model):\n",
    "    model.eval() #put model in testing\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    correct = {0:0, 1:0}\n",
    "    total = {0:0, 1:0}\n",
    "    with torch.no_grad():\n",
    "        for x, y, name in tqdm(loader):\n",
    "            #put batches on gpu \n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "\n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)\n",
    "            for i,j in zip(predictions, y):\n",
    "                if i.item() == j.item():\n",
    "                    correct[i.item()] +=1\n",
    "                total[j.item()] += 1\n",
    "                num_correct += (predictions == y).sum()\n",
    "                num_samples += predictions.size(0)\n",
    "\n",
    "        print(\n",
    "              f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}\"\n",
    "          )\n",
    "        acc = num_correct/num_samples\n",
    "        #find the accuracies for each class \n",
    "        return acc, correct, total\n",
    "\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "482a4999",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparams\n",
    "learning_rate = 5e-4\n",
    "num_epochs =10 #20 works well - it seems as tho it is a local min "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b13ba56",
   "metadata": {},
   "source": [
    "Some notes\n",
    "1. Might need to figure out another loss that works better with one hot encoding \n",
    "2. Also might need to figure out how to calc AUC-ROC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fa1c5899",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "398it [01:22,  4.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at epoch 0 is 0.4168923699376571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 83/83 [00:08<00:00,  9.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8661971688270569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "398it [01:23,  4.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at epoch 1 is 0.34443592845495025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 83/83 [00:10<00:00,  7.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8622002601623535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "398it [01:22,  4.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at epoch 2 is 0.3178808263797856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 83/83 [00:09<00:00,  9.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8819946646690369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "398it [01:22,  4.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at epoch 3 is 0.2881076695331976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 83/83 [00:08<00:00,  9.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8821850419044495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "398it [01:23,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at epoch 4 is 0.26456141316486365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 83/83 [00:08<00:00,  9.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8787590265274048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "398it [01:21,  4.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at epoch 5 is 0.2328546630901907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 83/83 [00:08<00:00,  9.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8762847185134888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "398it [01:21,  4.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at epoch 6 is 0.20284595179497897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 83/83 [00:08<00:00,  9.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8791397213935852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "398it [01:23,  4.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at epoch 7 is 0.17702758524697929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 83/83 [00:09<00:00,  9.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8458317518234253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "398it [01:22,  4.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at epoch 8 is 0.14843858619356276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 83/83 [00:09<00:00,  9.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8808526992797852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "398it [01:22,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at epoch 9 is 0.1439855966071163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 83/83 [00:08<00:00,  9.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8831366896629333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Loss and optimizer\n",
    "import torch.optim as optim  # For all Optimization algorithms, SGD, Adam, etc.\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterion = tgm.losses.FocalLoss(alpha=0.5, gamma=2.0, reduction='mean') #experimenting with focal loss \n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=.1, patience=5, verbose=True)\n",
    "\n",
    "#arrays to track the training loss and validation loss \n",
    "training_loss = []\n",
    "validation_acc = []\n",
    "\n",
    "# Train Network\n",
    "for epoch in range(num_epochs):\n",
    "    losses = []\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    #train part \n",
    "    for batch_idx, (data, targets) in tqdm(enumerate(train_loader)):\n",
    "        # Get data to cuda if possible\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "        # forward\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores, targets)\n",
    "        # print(\"Batch: %d. Loss: %f\" %(batch_idx, loss))\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # gradient descent or adam step\n",
    "        optimizer.step()\n",
    "    mean_loss = sum(losses)/len(losses)\n",
    "    training_loss.append(mean_loss)\n",
    "    scheduler.step(mean_loss)\n",
    "\n",
    "    print(f\"Cost at epoch {epoch} is {sum(losses)/len(losses)}\")\n",
    "    \n",
    "    #model in test mode \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        acc = 0\n",
    "        for x, y in tqdm(val_loader):\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "\n",
    "            scores = model(x)\n",
    "            #find the test loss\n",
    "            loss = criterion(scores, y)\n",
    "\n",
    "\n",
    "            #find the test accuracy \n",
    "            _, predictions = scores.max(1)\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "        #calc total acc here \n",
    "        acc = (num_correct/num_samples).item()\n",
    "        print(acc)\n",
    "        validation_acc.append(acc)\n",
    "    #put the model back in train mode\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c93bae4",
   "metadata": {},
   "source": [
    "# Find/Calc/and Make AUC-ROC plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e2bb5e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "softmax = nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "706a797d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 206/206 [00:37<00:00,  5.50it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "probabilities = torch.Tensor([])\n",
    "ground_truth = torch.Tensor([])\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in tqdm(test_loader):\n",
    "        x = x.to(device=device)\n",
    "        y = y.to(device=device)\n",
    "        #find the probs\n",
    "        scores = softmax(model(x))\n",
    "        \n",
    "        #move to cpu\n",
    "        scores = scores.detach().cpu()\n",
    "        y = y.detach().cpu()\n",
    "        \n",
    "        #concat them \n",
    "        probabilities = torch.cat((probabilities, scores))\n",
    "        ground_truth = torch.cat((ground_truth, y))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6b7c8745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9129135045203323"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict the whole test cohort AUC-ROC\n",
    "\n",
    "roc_auc_score(ground_truth, probabilities[:, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "18d4bf5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#from sophie's code - viz. the curve \n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# fpr and tpr of all thresohlds\n",
    "true = ground_truth\n",
    "preds = probabilities[:, 1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(true, preds)\n",
    "\n",
    "#get the metrics \n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "#plot\n",
    "plt.title('Test Cohort-wide AUC-ROC')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6913543a",
   "metadata": {},
   "source": [
    "# Save Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "768fafe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/users/Gokul_Srinivasan/SCC-Tumor-Detection/Gokul_files/Saved_Models/resnet50.pt\"\n",
    "torch.save(model.state_dict(), PATH) # here is how we save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2f486bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Dec 18 14:40:31 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:18:00.0 Off |                    0 |\n",
      "| N/A   37C    P0    55W / 300W |   3758MiB / 32768MiB |      0%   E. Process |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  Off  | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    51W / 300W |    754MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  Off  | 00000000:86:00.0 Off |                    0 |\n",
      "| N/A   27C    P0    39W / 300W |      3MiB / 32768MiB |      0%   E. Process |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  Off  | 00000000:AF:00.0 Off |                    0 |\n",
      "| N/A   30C    P0    40W / 300W |      3MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A    104863      C   ...pyter_ultimate/bin/python     3755MiB |\n",
      "|    1   N/A  N/A    104270      C   ...pyter_ultimate/bin/python      751MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f59d0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_ultimate",
   "language": "python",
   "name": "jupyter_ultimate"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
