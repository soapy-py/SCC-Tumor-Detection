{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18738a30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch \n",
    "import tqdm \n",
    "import glob, os, pickle\n",
    "import time\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import copy\n",
    "import tifffile\n",
    "import torch.nn as nn\n",
    "import matplotlib\n",
    "import fire, math\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets as Datasets, models\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image, ImageFile\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from kornia.losses import DiceLoss\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aad22031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_file, check_size=False, mmap_mode=None):\n",
    "    img_ext=os.path.splitext(image_file)\n",
    "    if img_ext[-1]==\".npy\":\n",
    "        image=np.load(image_file, mmap_mode=mmap_mode)\n",
    "    elif img_ext[-1] in [\".svs\",\".tif\",\".tiff\",\".png\"]:\n",
    "        if check_size:\n",
    "            import openslide\n",
    "            slide=openslide.open_slide(image_file)\n",
    "        image=tifffile.imread(image_file, aszarr=mmap_mode is not None)\n",
    "        if mmap_mode is not None:\n",
    "            import zarr\n",
    "            image=zarr.open(image, mode=mmap_mode)\n",
    "        if check_size and (not (int(slide.properties.get('aperio.AppMag',40))==20 or int(slide.properties.get('openslide.objective-power',40))==20)):\n",
    "            image = cv2.resize(image,None,fx=1/2,fy=1/2,interpolation=cv2.INTER_CUBIC)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fab4fc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PickleDataset(Dataset):\n",
    "    def __init__(self, pkl, transform, label_map):\n",
    "        self.data=pickle.load(open(pkl,'rb'))\n",
    "        self.X,self.targets=self.data['X'],self.data['y']\n",
    "        self.aux_data=self.data.get(\"z\",None)\n",
    "        self.has_aux=(self.aux_data is not None)\n",
    "        if self.has_aux and isinstance(self.aux_data,pd.DataFrame): self.aux_data=self.aux_data.values\n",
    "        if self.has_aux: self.n_aux_features=self.aux_data.shape[1]\n",
    "        self.transform=transform\n",
    "        self.to_pil=lambda x: Image.fromarray(x)\n",
    "        self.label_map=label_map\n",
    "        if self.label_map:\n",
    "            self.targets=pd.Series(self.targets).map(lambda x: self.label_map.get(x,-1)).values\n",
    "            if -1 in self.targets:\n",
    "                remove_bool=(self.targets!=-1)\n",
    "                self.targets=self.targets[remove_bool]\n",
    "                self.X=pd.Series(self.X).iloc[remove_bool].tolist()\n",
    "                if self.has_aux: self.aux_data=self.aux_data[remove_bool]\n",
    "        self.length=len(self.X)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        items=(self.transform(self.to_pil(self.X[idx])), torch.tensor(self.targets[idx]).long())\n",
    "        if self.has_aux: items+=(torch.tensor(self.aux_data[idx]).float(),)\n",
    "        return items\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "class NPYRotatingStack(Dataset):\n",
    "    def __init__(self, patch_dir, transform, sample_frac=1., sample_every=0, target_col={'old_y_true':'y_true'},npy_rotate_sets_pkl=\"\",Set=\"\"):\n",
    "        self.npy_rotate_sets_pkl=npy_rotate_sets_pkl\n",
    "        if npy_rotate_sets_pkl:\n",
    "            self.patch_npy=pd.read_pickle(self.npy_rotate_sets_pkl)\n",
    "            self.patch_pkl=self.patch_npy[self.patch_npy['Set']==Set]['pkl'].values\n",
    "            self.patch_npy=self.patch_npy[self.patch_npy['Set']==Set]['npy'].values\n",
    "        else:\n",
    "            self.patch_npy=np.array(glob.glob(os.path.join(patch_dir,\"*.npy\")))\n",
    "            self.patch_pkl=np.vectorize(lambda x: x.replace(\".npy\",\".pkl\"))(self.patch_npy)\n",
    "        self.sample_every=sample_every\n",
    "        self.sample_frac=sample_frac\n",
    "        if self.sample_frac==1: self.sample_every=0\n",
    "        self.target_col=list(target_col.items())[0]\n",
    "        self.ref_index=None # dictionary\n",
    "        self.data={}\n",
    "        self.cache_npy=None # dictionary keys\n",
    "        self.to_pil=lambda x: Image.fromarray(x)\n",
    "        self.transform=transform\n",
    "        assert self.target_col[1]=='y_true'\n",
    "        self.targets=np.hstack([pd.read_pickle(pkl)[self.target_col[0]].values for pkl in self.patch_pkl])\n",
    "        self.load_image_annot()\n",
    "\n",
    "    def load_image_annot(self):\n",
    "        if self.sample_frac<1.:\n",
    "            idx=np.arange(len(self.patch_npy))\n",
    "            idx=np.random.choice(idx,int(self.sample_frac*len(idx)))\n",
    "            patch_npy=self.patch_npy[idx]\n",
    "            patch_pkl=self.patch_pkl[idx]\n",
    "            remove_npy=np.setdiff1d(self.patch_npy,patch_npy)\n",
    "            for npy in remove_npy:\n",
    "                if isinstance(self.cache_npy,type(None))==False and npy not in self.cache_npy:\n",
    "                    del self.data[npy]\n",
    "            new_data={npy:(dict(patches=load_image(npy),\n",
    "                               patch_info=pd.read_pickle(pkl)) if (self.cache_npy is None or (npy not in self.cache_npy if self.cache_npy is not None else False)) else self.data[npy]) for npy,pkl in zip(patch_npy,patch_pkl)}\n",
    "            self.data.clear()\n",
    "            self.data=new_data\n",
    "            self.cache_npy=sorted(list(self.data.keys()))\n",
    "        else:\n",
    "            self.data={npy:dict(patches=load_image(npy),\n",
    "                               patch_info=pd.read_pickle(pkl)) for npy,pkl in zip(self.patch_npy,self.patch_pkl)}\n",
    "            self.cache_npy=sorted(self.patch_npy)\n",
    "        self.ref_index=np.vstack([np.array(([i]*self.data[npy]['patch_info'].shape[0],list(range(self.data[npy]['patch_info'].shape[0])))).T for i,npy in enumerate(self.cache_npy)])\n",
    "        for npy in self.data: self.data[npy]['patch_info'][self.target_col[1]]=self.data[npy]['patch_info'][self.target_col[0]]\n",
    "        self.length=self.ref_index.shape[0]\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        i,j=self.ref_index[idx]\n",
    "        npy=self.cache_npy[i]\n",
    "        X=self.data[npy]['patches'][j]\n",
    "        y=torch.LongTensor(np.array(self.data[npy]['patch_info'].iloc[j][self.target_col[1]]).reshape(1))\n",
    "        X=self.transform(self.to_pil(X))\n",
    "        return X, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75b9508b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scheduler:\n",
    "    \"\"\"Scheduler class that modulates learning rate of torch optimizers over epochs.\n",
    "    Parameters\n",
    "    ----------\n",
    "    optimizer : type\n",
    "            torch.Optimizer object\n",
    "    opts : type\n",
    "            Options of setting the learning rate scheduler, see default.\n",
    "    Attributes\n",
    "    ----------\n",
    "    schedulers : type\n",
    "            Different types of schedulers to choose from.\n",
    "    scheduler_step_fn : type\n",
    "            How scheduler updates learning rate.\n",
    "    initial_lr : type\n",
    "            Initial set learning rate.\n",
    "    scheduler_choice : type\n",
    "            What scheduler type was chosen.\n",
    "    scheduler : type\n",
    "            Scheduler object chosen that will more directly update optimizer LR.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, optimizer=None, opts=dict(scheduler='null', lr_scheduler_decay=0.5, T_max=10, eta_min=5e-8, T_mult=2)):\n",
    "        self.schedulers = {'exp': (lambda optimizer: ExponentialLR(optimizer, opts[\"lr_scheduler_decay\"])),\n",
    "                           'null': (lambda optimizer: None),\n",
    "                           'warm_restarts': (lambda optimizer: CosineAnnealingWithRestartsLR(optimizer, T_max=opts['T_max'], eta_min=opts['eta_min'], last_epoch=-1, T_mult=opts['T_mult']))}\n",
    "        self.scheduler_step_fn = {'exp': (lambda scheduler: scheduler.step()),\n",
    "                                  'warm_restarts': (lambda scheduler: scheduler.step()),\n",
    "                                  'null': (lambda scheduler: None)}\n",
    "        self.initial_lr = optimizer.param_groups[0]['lr']\n",
    "        self.scheduler_choice = opts['scheduler']\n",
    "        self.scheduler = self.schedulers[self.scheduler_choice](\n",
    "            optimizer) if optimizer is not None else None\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"Update optimizer learning rate\"\"\"\n",
    "        self.scheduler_step_fn[self.scheduler_choice](self.scheduler)\n",
    "\n",
    "    def get_lr(self):\n",
    "        \"\"\"Return current learning rate.\n",
    "Returns\n",
    "-------\n",
    "float\n",
    "    Current learning rate.\n",
    "\"\"\"\n",
    "        lr = (self.initial_lr if self.scheduler_choice\n",
    "              == 'null' else self.scheduler.optimizer.param_groups[0]['lr'])\n",
    "        return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da2e66de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineAnnealingWithRestartsLR(torch.optim.lr_scheduler._LRScheduler):\n",
    "    r\"\"\"Set the learning rate of each parameter group using a cosine annealing\n",
    "    schedule, where :math:`\\eta_{max}` is set to the initial lr and\n",
    "    :math:`T_{cur}` is the number of epochs since the last restart in SGDR:\n",
    "     .. math::\n",
    "             \\eta_t = \\eta_{min} + \\frac{1}{2}(\\eta_{max} - \\eta_{min})(1 +\n",
    "            \\cos(\\frac{T_{cur}}{T_{max}}\\pi))\n",
    "     When last_epoch=-1, sets initial lr as lr.\n",
    "     It has been proposed in\n",
    "    `SGDR: Stochastic Gradient Descent with Warm Restarts`_. This implements\n",
    "    the cosine annealing part of SGDR, the restarts and number of iterations multiplier.\n",
    "     Args:\n",
    "            optimizer (Optimizer): Wrapped optimizer.\n",
    "            T_max (int): Maximum number of iterations.\n",
    "            T_mult (float): Multiply T_max by this number after each restart. Default: 1.\n",
    "            eta_min (float): Minimum learning rate. Default: 0.\n",
    "            last_epoch (int): The index of last epoch. Default: -1.\n",
    "     .. _SGDR\\: Stochastic Gradient Descent with Warm Restarts:\n",
    "            https://arxiv.org/abs/1608.03983\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, optimizer, T_max, eta_min=0, last_epoch=-1, T_mult=1., alpha_decay=1.0):\n",
    "        self.T_max = T_max\n",
    "        self.T_mult = T_mult\n",
    "        self.restart_every = T_max\n",
    "        self.eta_min = eta_min\n",
    "        self.restarts = 0\n",
    "        self.restarted_at = 0\n",
    "        self.alpha = alpha_decay\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "    def restart(self):\n",
    "        self.restarts += 1\n",
    "        self.restart_every = int(round(self.restart_every * self.T_mult))\n",
    "        self.restarted_at = self.last_epoch\n",
    "\n",
    "    def cosine(self, base_lr):\n",
    "        return self.eta_min + self.alpha**self.restarts * (base_lr - self.eta_min) * (1 + math.cos(math.pi * self.step_n() / self.restart_every)) / 2\n",
    "\n",
    "    def step_n(self):\n",
    "        return self.last_epoch - self.restarted_at\n",
    "\n",
    "    def get_lr(self):\n",
    "        if self.step_n() >= self.restart_every:\n",
    "            self.restart()\n",
    "        return [self.cosine(base_lr) for base_lr in self.base_lrs]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49e0aed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AuxNet(nn.Module):\n",
    "    def __init__(self,net,n_aux_features):\n",
    "        super().__init__()\n",
    "        self.net=net\n",
    "        self.features=self.net.features\n",
    "        self.output=self.net.output\n",
    "        self.n_features=self.net.output.in_features\n",
    "        self.n_aux_features=n_aux_features\n",
    "        self.transform_nn=nn.Sequential(nn.Linear(self.n_aux_features,self.n_features),nn.LeakyReLU())\n",
    "        self.gate_nn=MLP(self.n_features,[32],dropout_p=0.2,binary=False)#nn.Linear(self.n_features,1)\n",
    "\n",
    "    def forward(self,x,z=None):\n",
    "        x=self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        if z is not None:\n",
    "            z=self.transform_nn(z)\n",
    "            #print(x.shape,z.shape,self.gate_nn(x).shape,self.gate_nn(z).shape)\n",
    "            gate_h=F.softmax(torch.cat([self.gate_nn(xz) for xz in [x,z]],1),1)\n",
    "            x = gate_h[:,0].unsqueeze(1) * x + gate_h[:,1].unsqueeze(1) * z\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "def prepare_model(model_name,\n",
    "                  use_pretrained,\n",
    "                  pretrained_model_file_path,\n",
    "                  use_cuda=False,\n",
    "                  use_data_parallel=True,\n",
    "                  load_ignore_extra=False,\n",
    "                  num_classes=3,\n",
    "                  in_channels=3,\n",
    "                  remap_to_cpu=True,\n",
    "                  remove_module=False,\n",
    "                  n_aux_features=None):\n",
    "    from pytorchcv.model_provider import get_model\n",
    "    \"\"\" https://raw.githubusercontent.com/osmr/imgclsmob/master/pytorch/utils.py\n",
    "        Create and initialize model by name.\n",
    "        Parameters\n",
    "        ----------\n",
    "        model_name : str\n",
    "        Model name.\n",
    "        use_pretrained : bool\n",
    "        Whether to use pretrained weights.\n",
    "        pretrained_model_file_path : str\n",
    "        Path to file with pretrained weights.\n",
    "        use_cuda : bool\n",
    "        Whether to use CUDA.\n",
    "        use_data_parallel : bool, default True\n",
    "        Whether to use parallelization.\n",
    "        net_extra_kwargs : dict, default None\n",
    "        Extra parameters for model.\n",
    "        load_ignore_extra : bool, default False\n",
    "        Whether to ignore extra layers in pretrained model.\n",
    "        num_classes : int, default None\n",
    "        Number of classes.\n",
    "        in_channels : int, default None\n",
    "        Number of input channels.\n",
    "        remap_to_cpu : bool, default False\n",
    "        Whether to remape model to CPU during loading.\n",
    "        remove_module : bool, default False\n",
    "        Whether to remove module from loaded model.\n",
    "        Returns\n",
    "        -------\n",
    "        Module\n",
    "        Model.\n",
    "        \"\"\"\n",
    "  \n",
    "    net = get_model(model_name)\n",
    "\n",
    "    if n_aux_features is not None:\n",
    "        net=AuxNet(net,n_aux_features)\n",
    "    \n",
    "    return net\n",
    "\n",
    "\n",
    "def generate_model(architecture, num_classes, pretrained=False, n_aux_features=None):\n",
    "    #    from pytorchcv.pytorch.utils import prepare_model\n",
    "    if os.path.exists(architecture):\n",
    "        model = torch.load(architecture,map_location='cpu')\n",
    "    else:\n",
    "        model = prepare_model(architecture,\n",
    "                          use_pretrained=pretrained,\n",
    "                          pretrained_model_file_path='',\n",
    "                          use_cuda=False,\n",
    "                          num_classes=num_classes,\n",
    "                          n_aux_features=n_aux_features)\n",
    "    \n",
    "    \n",
    "    thresh = 3\n",
    "    ct = 0\n",
    "    #here we freeze up to and including the 4th layer\n",
    "    for child in model.children():\n",
    "        if ct <= thresh:\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = False\n",
    "            print(child, ct)\n",
    "            ct += 1\n",
    "    return model\n",
    "\n",
    "class ModelTrainer:\n",
    "    \"\"\"Trainer for the neural network model that wraps it into a scikit-learn like interface.\n",
    "    Parameters\n",
    "    ----------\n",
    "    model:nn.Module\n",
    "            Deep learning pytorch model.\n",
    "    n_epoch:int\n",
    "            Number training epochs.\n",
    "    validation_dataloader:DataLoader\n",
    "            Dataloader of validation dataset.\n",
    "    optimizer_opts:dict\n",
    "            Options for optimizer.\n",
    "    scheduler_opts:dict\n",
    "            Options for learning rate scheduler.\n",
    "    loss_fn:str\n",
    "            String to call a particular loss function for model.\n",
    "    reduction:str\n",
    "            Mean or sum reduction of loss.\n",
    "    num_train_batches:int\n",
    "            Number of training batches for epoch.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, n_epoch=300, validation_dataloader=None, optimizer_opts=dict(name='adam', lr=1e-3, weight_decay=1e-4), scheduler_opts=dict(scheduler='warm_restarts', lr_scheduler_decay=0.5, T_max=10, eta_min=5e-8, T_mult=2), loss_fn='ce', reduction='mean', num_train_batches=None, opt_level='O1', checkpoints_dir='checkpoints',tensor_dataset=False,transforms=None,save_metric='loss',save_after_n_batch=0):\n",
    "\n",
    "        self.model = model\n",
    "        # self.amp_handle = amp.init(enabled=True)\n",
    "        optimizers = {'adam': torch.optim.Adam, 'sgd': torch.optim.SGD}\n",
    "        loss_functions = {'bce': nn.BCEWithLogitsLoss(reduction=reduction), 'ce': nn.CrossEntropyLoss(\n",
    "            reduction=reduction), 'mse': nn.MSELoss(reduction=reduction), 'nll': nn.NLLLoss(reduction=reduction),'dice':DiceLoss()}\n",
    "        \n",
    "        if 'name' not in list(optimizer_opts.keys()):\n",
    "            optimizer_opts['name'] = 'adam'\n",
    "        \n",
    "        self.optimizer = optimizers[optimizer_opts.pop('name')](\n",
    "            self.model.parameters(), **optimizer_opts)\n",
    "        \n",
    "        if False and torch.cuda.is_available():\n",
    "            self.cuda = True\n",
    "            self.model, self.optimizer = amp.initialize(\n",
    "                self.model, self.optimizer, opt_level=opt_level)\n",
    "        else:\n",
    "            self.cuda = False\n",
    "        self.scheduler = Scheduler(\n",
    "            optimizer=self.optimizer, opts=scheduler_opts)\n",
    "        self.n_epoch = n_epoch\n",
    "        self.validation_dataloader = validation_dataloader\n",
    "        self.loss_fn = loss_functions[loss_fn]\n",
    "        self.loss_fn_name = loss_fn\n",
    "        self.bce = (self.loss_fn_name == 'bce')\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.original_loss_fn = copy.deepcopy(loss_functions[loss_fn])\n",
    "        self.num_train_batches = num_train_batches\n",
    "        self.val_loss_fn = copy.deepcopy(loss_functions[loss_fn])\n",
    "        self.verbosity=0\n",
    "        self.checkpoints_dir=checkpoints_dir\n",
    "        self.tensor_dataset=tensor_dataset\n",
    "        self.transforms=transforms\n",
    "        self.save_metric=save_metric\n",
    "        self.save_after_n_batch=save_after_n_batch\n",
    "        self.train_batch_count=0\n",
    "        self.initial_seed=0\n",
    "        self.seed=0\n",
    "\n",
    "    def save_checkpoint(self,model,epoch,batch=0):\n",
    "        os.makedirs(self.checkpoints_dir,exist_ok=True)\n",
    "        out_name = f\"{batch}.batch\" if batch else f\"{epoch}.epoch\"\n",
    "        torch.save(model,os.path.join(self.checkpoints_dir,f\"{out_name}.checkpoint.pth\"))\n",
    "\n",
    "    def calc_loss(self, y_pred, y_true):\n",
    "        \"\"\"Calculates loss supplied in init statement and modified by reweighting.\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_pred:tensor\n",
    "                Predictions.\n",
    "        y_true:tensor\n",
    "                True values.\n",
    "        Returns\n",
    "        -------\n",
    "        loss\n",
    "        \"\"\"\n",
    "\n",
    "        return self.loss_fn(y_pred, y_true)\n",
    "\n",
    "    def calc_val_loss(self, y_pred, y_true):\n",
    "        \"\"\"Calculates loss supplied in init statement on validation set.\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_pred:tensor\n",
    "                Predictions.\n",
    "        y_true:tensor\n",
    "                True values.\n",
    "        Returns\n",
    "        -------\n",
    "        val_loss\n",
    "        \"\"\"\n",
    "\n",
    "        return self.val_loss_fn(y_pred, y_true)\n",
    "\n",
    "    def reset_loss_fn(self):\n",
    "        \"\"\"Resets loss to original specified loss.\"\"\"\n",
    "        self.loss_fn = self.original_loss_fn\n",
    "\n",
    "    def add_class_balance_loss(self, y, custom_weights=''):\n",
    "        \"\"\"Updates loss function to handle class imbalance by weighting inverse to class appearance.\n",
    "        Parameters\n",
    "        ----------\n",
    "        dataset:DynamicImageDataset\n",
    "                Dataset to balance by.\n",
    "        \"\"\"\n",
    "        self.class_weights = compute_class_weight(class_weight='balanced',classes=np.unique(y),y=y)#dataset.get_class_weights() if not custom_weights else np.array(\n",
    "            #list(map(float, custom_weights.split(','))))\n",
    "        if custom_weights:\n",
    "            self.class_weights = self.class_weights / sum(self.class_weights)\n",
    "        print('Weights:', self.class_weights)\n",
    "        self.original_loss_fn = copy.deepcopy(self.loss_fn)\n",
    "        weight = torch.tensor(self.class_weights, dtype=torch.float)\n",
    "        if torch.cuda.is_available():\n",
    "            weight = weight.cuda()\n",
    "        if self.loss_fn_name == 'ce':\n",
    "            self.loss_fn = nn.CrossEntropyLoss(weight=weight)\n",
    "        elif self.loss_fn_name == 'nll':\n",
    "            self.loss_fn = nn.NLLLoss(weight=weight)\n",
    "        else:  # modify below for multi-target\n",
    "            self.loss_fn = lambda y_pred, y_true: sum([self.class_weights[i] * self.original_loss_fn(\n",
    "                y_pred[y_true == i], y_true[y_true == i]) if sum(y_true == i) else 0. for i in range(3)])\n",
    "\n",
    "    def calc_best_confusion(self, y_pred, y_true):\n",
    "        \"\"\"Calculate confusion matrix on validation set for classification/segmentation tasks, optimize threshold where positive.\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_pred:array\n",
    "                Predictions.\n",
    "        y_true:array\n",
    "                Ground truth.\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "                Optimized threshold to use on test set.\n",
    "        dataframe\n",
    "                Confusion matrix.\n",
    "        \"\"\"\n",
    "        fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "        threshold = thresholds[np.argmin(\n",
    "            np.sum((np.array([0, 1]) - np.vstack((fpr, tpr)).T)**2, axis=1)**.5)]\n",
    "        y_pred = (y_pred > threshold).astype(int)\n",
    "        return threshold, pd.DataFrame(confusion_matrix(y_true, y_pred), index=['F', 'T'], columns=['-', '+']).iloc[::-1, ::-1].T\n",
    "\n",
    "    def loss_backward(self, loss):\n",
    "        \"\"\"Backprop using mixed precision for added speed boost.\n",
    "        Parameters\n",
    "        ----------\n",
    "        loss:loss\n",
    "                Torch loss calculated.\n",
    "        \"\"\"\n",
    "        # with self.amp_handle.scale_loss(loss, self.optimizer) as scaled_loss:\n",
    "        # \tscaled_loss.backward()\n",
    "        # loss.backward()\n",
    "        if self.cuda:\n",
    "            with amp.scale_loss(loss, self.optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "\n",
    "    # @pysnooper.snoop()\n",
    "    def train_loop(self, epoch, train_dataloader):\n",
    "        \"\"\"One training epoch, calculate predictions, loss, backpropagate.\n",
    "        Parameters\n",
    "        ----------\n",
    "        epoch:int\n",
    "                Current epoch.\n",
    "        train_dataloader:DataLoader\n",
    "                Training data.\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "                Training loss for epoch\n",
    "        \"\"\"\n",
    "        self.model.train(True)\n",
    "        running_loss = 0.\n",
    "        n_batch = len(\n",
    "            train_dataloader.dataset) // train_dataloader.batch_size if self.num_train_batches == None else self.num_train_batches\n",
    "        for i, batch in enumerate(train_dataloader):\n",
    "            starttime = time.time()\n",
    "            X, y_true = batch[:2]\n",
    "            if len(batch)==3: Z=batch[2]\n",
    "            else: Z=None\n",
    "\n",
    "            if i == n_batch:\n",
    "                break\n",
    "\n",
    "            # X = Variable(batch[0], requires_grad=True)\n",
    "            # y_true = Variable(batch[1])\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                X = X.cuda()\n",
    "                y_true = y_true.cuda()\n",
    "                if Z is not None: Z=Z.cuda()\n",
    "\n",
    "\n",
    "            y_pred = self.model(X) if Z is None else self.model(X,Z)\n",
    "            # y_true=y_true.argmax(dim=1)\n",
    "\n",
    "            loss = self.calc_loss(y_pred, y_true.flatten())  # .view(-1,1)\n",
    "            train_loss = loss.item()\n",
    "            running_loss += train_loss\n",
    "            self.optimizer.zero_grad()\n",
    "            self.loss_backward(loss)  # loss.backward()\n",
    "            self.optimizer.step()\n",
    "            torch.cuda.empty_cache()\n",
    "            endtime = time.time()\n",
    "            if self.verbosity >=1:\n",
    "                print(\"Epoch {}[{}/{}] Time:{}, Train Loss:{}\".format(epoch,\n",
    "                                                                  i, n_batch, round(endtime - starttime, 3), train_loss))\n",
    "            self.train_batch_count+=1\n",
    "            if self.save_after_n_batch and self.train_batch_count%self.save_after_n_batch==0:\n",
    "                val_loss,val_f1=self.val_loop(epoch, self.val_dataloader)\n",
    "                self.batch_val_losses.append(val_loss)\n",
    "                self.batch_val_f1.append(val_f1)\n",
    "                self.save_best_val_model(val_loss, val_f1, self.batch_val_losses, self.batch_val_f1, epoch, True, self.train_batch_count)\n",
    "                self.model.train(True)\n",
    "\n",
    "        self.scheduler.step()\n",
    "        running_loss /= n_batch\n",
    "        return running_loss\n",
    "\n",
    "    def val_loop(self, epoch, val_dataloader, print_val_confusion=True, save_predictions=True):\n",
    "        \"\"\"Calculate loss over validation set.\n",
    "        Parameters\n",
    "        ----------\n",
    "        epoch:int\n",
    "                Current epoch.\n",
    "        val_dataloader:DataLoader\n",
    "                Validation iterator.\n",
    "        print_val_confusion:bool\n",
    "                Calculate confusion matrix and plot.\n",
    "        save_predictions:int\n",
    "                Print validation results.\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "                Validation loss for epoch.\n",
    "        \"\"\"\n",
    "        self.model.train(False)\n",
    "        n_batch = len(val_dataloader.dataset) // val_dataloader.batch_size\n",
    "        running_loss = 0.\n",
    "        Y = {'pred': [], 'true': []}\n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(val_dataloader):\n",
    "                # X = Variable(batch[0], requires_grad=True)\n",
    "                # y_true = Variable(batch[1])\n",
    "                X, y_true = batch[:2]\n",
    "                if len(batch)==3: Z=batch[2]\n",
    "                else: Z=None\n",
    "                if torch.cuda.is_available():\n",
    "                    X = X.cuda()\n",
    "                    y_true = y_true.cuda()\n",
    "                    if Z is not None: Z=Z.cuda()\n",
    "\n",
    "\n",
    "                y_pred = self.model(X) if Z is None else self.model(X,Z)\n",
    "                # y_true=y_true.argmax(dim=1)\n",
    "                # if save_predictions:\n",
    "                Y['true'].append(\n",
    "                    y_true.detach().cpu().numpy().astype(int).flatten())\n",
    "                y_pred_numpy = ((y_pred if not self.bce else self.sigmoid(y_pred)).detach().cpu().numpy()).astype(float)\n",
    "                if self.loss_fn_name in ['ce','dice']:\n",
    "                    y_pred_numpy = y_pred_numpy.argmax(axis=1)\n",
    "                Y['pred'].append(y_pred_numpy.flatten())\n",
    "\n",
    "                loss = nn.CrossEntropyLoss(y_pred,y_true.flatten())#.view(-1,1)\n",
    "                val_loss = loss.item()\n",
    "                running_loss += val_loss\n",
    "                if self.verbosity >=1:\n",
    "                    print(\"Epoch {}[{}/{}] Val Loss:{}\".format(epoch, i, n_batch, val_loss))\n",
    "        # if print_val_confusion and save_predictions:\n",
    "        y_pred, y_true = np.hstack(Y['pred']).flatten(), np.hstack(Y['true']).flatten()\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        running_loss /= n_batch\n",
    "        return running_loss, f1_score(y_true, y_pred,average='macro')\n",
    "\n",
    "    # @pysnooper.snoop(\"test_loop.log\")\n",
    "    def test_loop(self, test_dataloader):\n",
    "        \"\"\"Calculate final predictions on loss.\n",
    "        Parameters\n",
    "        ----------\n",
    "        test_dataloader:DataLoader\n",
    "                Test dataset.\n",
    "        Returns\n",
    "        -------\n",
    "        array\n",
    "                Predictions or embeddings.\n",
    "        \"\"\"\n",
    "        # self.model.train(False) KEEP DROPOUT? and BATCH NORM??\n",
    "        self.model.eval()\n",
    "        y_pred = []\n",
    "        Y_true = []\n",
    "        running_loss = 0.\n",
    "        n_batch = len(\n",
    "            test_dataloader.dataset) // test_dataloader.batch_size\n",
    "        with torch.no_grad():\n",
    "            for i, batch in tqdm.tqdm(enumerate(test_dataloader),total=n_batch):\n",
    "                #X = Variable(batch[0],requires_grad=False)\n",
    "                X, y_true = batch[:2]\n",
    "                if len(batch)==3: Z=batch[2]\n",
    "                else: Z=None\n",
    "                if torch.cuda.is_available():\n",
    "                    X = X.cuda()\n",
    "                    y_true = y_true.cuda()\n",
    "                    if Z is not None: Z=Z.cuda()\n",
    "\n",
    "                prediction = self.model(X) if Z is None else self.model(X,Z)\n",
    "                y_pred.append(prediction.detach().cpu().numpy())\n",
    "                Y_true.append(y_true.detach().cpu().numpy())\n",
    "        y_pred = np.concatenate(y_pred, axis=0)  # torch.cat(y_pred,0)\n",
    "        y_true = np.concatenate(Y_true, axis=0).flatten()\n",
    "        return y_pred,y_true\n",
    "\n",
    "    def fit(self, train_dataloader, verbose=False, print_every=10, save_model=True, plot_training_curves=True, plot_save_file='/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/users/Sophie_Chen/', print_val_confusion=True, save_val_predictions=True):\n",
    "        \"\"\"Fits the segmentation or classification model to the patches, saving the model with the lowest validation score.\n",
    "        Parameters\n",
    "        ----------\n",
    "        train_dataloader:DataLoader\n",
    "                Training dataset.\n",
    "        verbose:bool\n",
    "                Print training and validation loss?\n",
    "        print_every:int\n",
    "                Number of epochs until print?\n",
    "        save_model:bool\n",
    "                Whether to save model when reaching lowest validation loss.\n",
    "        plot_training_curves:bool\n",
    "                Plot training curves over epochs.\n",
    "        plot_save_file:str\n",
    "                File to save training curves.\n",
    "        print_val_confusion:bool\n",
    "                Print validation confusion matrix.\n",
    "        save_val_predictions:bool\n",
    "                Print validation results.\n",
    "        Returns\n",
    "        -------\n",
    "        self\n",
    "                Trainer.\n",
    "        float\n",
    "                Minimum val loss.\n",
    "        int\n",
    "                Best validation epoch with lowest loss.\n",
    "        \"\"\"\n",
    "        # choose model with best f1\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.val_f1 = []\n",
    "        self.batch_val_losses = []\n",
    "        self.batch_val_f1 = []\n",
    "        if verbose:\n",
    "            self.verbosity+=1\n",
    "        for epoch in range(self.n_epoch):\n",
    "            self.seed=self.initial_seed+epoch\n",
    "            np.random.seed(self.seed)\n",
    "            start_time = time.time()\n",
    "            train_loss = self.train_loop(epoch, train_dataloader)\n",
    "            current_time = time.time()\n",
    "            train_time = current_time - start_time\n",
    "            self.train_losses.append(train_loss)\n",
    "            val_loss, val_f1 = self.val_loop(epoch, self.validation_dataloader,\n",
    "                                     print_val_confusion=print_val_confusion, save_predictions=save_val_predictions)\n",
    "            val_time = time.time() - current_time\n",
    "            self.val_losses.append(val_loss)\n",
    "            self.val_f1.append(val_f1)\n",
    "            self.batch_val_losses.append(val_loss)\n",
    "            self.batch_val_f1.append(val_f1)\n",
    "            # if True:#verbose and not (epoch % print_every):\n",
    "            if plot_training_curves:\n",
    "                self.plot_train_val_curves(plot_save_file)\n",
    "            print(\"Epoch {}: Train Loss {}, Val Loss {}, Train Time {}, Val Time {}\".format(\n",
    "                epoch, train_loss, val_loss, train_time, val_time))\n",
    "            print('Training complete in {:.0f}m {:.0f}s'.format(train_time // 60, train_time % 60))\n",
    "            \n",
    "            self.save_best_val_model(val_loss, val_f1, self.val_losses, self.val_f1, epoch, save_model)\n",
    "            if \"save_every\" in dir(train_dataloader.dataset) and train_dataloader.dataset.save_every and epoch%train_dataloader.dataset.save_every==0:\n",
    "                train_dataloader.dataset.load_image_annot()\n",
    "        if save_model:\n",
    "            print(\"Saving best model at epoch {}\".format(self.best_epoch))\n",
    "            self.model.load_state_dict(self.best_model_state_dict)\n",
    "        return self, self.min_val_loss_f1, self.best_epoch\n",
    "\n",
    "    def save_best_val_model(self, val_loss, val_f1, val_loss_list, val_f1_list, epoch, save_model=True, batch=0):\n",
    "        if (val_loss <= min(val_loss_list) if self.save_metric=='loss' else val_f1 >= max(val_f1_list)) and save_model:\n",
    "            print(\"New best model at epoch {}\".format(epoch))\n",
    "            self.min_val_loss_f1 = val_loss if self.save_metric=='loss' else val_f1\n",
    "            self.best_epoch = epoch\n",
    "            if batch: self.best_batch = batch\n",
    "            self.best_model_state_dict = copy.deepcopy(self.model.state_dict())\n",
    "            self.save_checkpoint(self.best_model_state_dict,epoch,batch)\n",
    "\n",
    "    def plot_train_val_curves(self, save_file='/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/users/Sophie_Chen/'):\n",
    "        \"\"\"Plots training and validation curves.\n",
    "        Parameters\n",
    "        ----------\n",
    "        save_file:str\n",
    "                File to save to.\n",
    "        \"\"\"\n",
    "        plt.figure()\n",
    "        sns.lineplot('epoch', 'value', hue='variable',\n",
    "                     data=pd.DataFrame(np.vstack((np.arange(len(self.train_losses)), self.train_losses, self.val_losses)).T,\n",
    "                                       columns=['epoch', 'train', 'val']).melt(id_vars=['epoch'], value_vars=['train', 'val']))\n",
    "        if save_file is not None:\n",
    "            plt.savefig(save_file, dpi=300)\n",
    "\n",
    "    def predict(self, test_dataloader):\n",
    "        \"\"\"Make classification segmentation predictions on testing data.\n",
    "        Parameters\n",
    "        ----------\n",
    "        test_dataloader:DataLoader\n",
    "                Test data.\n",
    "        Returns\n",
    "        -------\n",
    "        array\n",
    "                Predictions.\n",
    "        \"\"\"\n",
    "        y_pred,y_true = self.test_loop(test_dataloader)\n",
    "        return y_pred,y_true\n",
    "\n",
    "    def fit_predict(self, train_dataloader, test_dataloader):\n",
    "        \"\"\"Fit model to training data and make classification segmentation predictions on testing data.\n",
    "        Parameters\n",
    "        ----------\n",
    "        train_dataloader:DataLoader\n",
    "                Train data.\n",
    "        test_dataloader:DataLoader\n",
    "                Test data.\n",
    "        Returns\n",
    "        -------\n",
    "        array\n",
    "                Predictions.\n",
    "        \"\"\"\n",
    "        return self.fit(train_dataloader)[0].predict(test_dataloader)\n",
    "\n",
    "    def return_model(self):\n",
    "        \"\"\"Returns pytorch model.\n",
    "        \"\"\"\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c641077d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reshape(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self,x):\n",
    "        return x.view(x.shape[0],-1)\n",
    "\n",
    "def worker_init_fn(worker_id):\n",
    "    np.random.seed(np.random.get_state()[1][0] + worker_id)\n",
    "\n",
    "def generate_transformers(image_size=224, resize=256, mean=[], std=[], include_jitter=False):\n",
    "    train_transform = [transforms.Resize((resize,resize))]\n",
    "    if include_jitter:\n",
    "        train_transform.append(transforms.ColorJitter(brightness=0.4,\n",
    "                                            contrast=0.4, saturation=0.4, hue=0.1))\n",
    "    train_transform.extend([transforms.RandomHorizontalFlip(p=0.5),\n",
    "           transforms.RandomVerticalFlip(p=0.5),\n",
    "           transforms.RandomRotation(90),\n",
    "           transforms.RandomResizedCrop((image_size,image_size)),\n",
    "           transforms.ToTensor(),\n",
    "           transforms.Normalize(mean if mean else [0.5, 0.5, 0.5],\n",
    "                                std if std else [0.1, 0.1, 0.1])\n",
    "           ])\n",
    "    train_transform=transforms.Compose(train_transform)\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((resize,resize)),\n",
    "        transforms.CenterCrop((image_size,image_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean if mean else [0.5, 0.5, 0.5],\n",
    "                             std if std else [0.1, 0.1, 0.1])\n",
    "    ])\n",
    "    normalization_transform = transforms.Compose([transforms.Resize((resize,resize)),\n",
    "                                                  transforms.CenterCrop(\n",
    "                                                      (image_size,image_size)),\n",
    "                                                  transforms.ToTensor()])\n",
    "    return {'train': train_transform, 'val': val_transform, 'test': val_transform, 'norm': normalization_transform}\n",
    "\n",
    "def generate_kornia_transforms(image_size=224, resize=256, mean=[], std=[], include_jitter=False):\n",
    "    mean=torch.tensor(mean) if mean else torch.tensor([0.5, 0.5, 0.5])\n",
    "    std=torch.tensor(std) if std else torch.tensor([0.1, 0.1, 0.1])\n",
    "    if torch.cuda.is_available():\n",
    "        mean=mean.cuda()\n",
    "        std=std.cuda()\n",
    "    train_transforms=[G.Resize((resize,resize))]\n",
    "    if include_jitter:\n",
    "        train_transforms.append(K.ColorJitter(brightness=0.4, contrast=0.4,\n",
    "                                   saturation=0.4, hue=0.1))\n",
    "    train_transforms.extend([K.RandomHorizontalFlip(p=0.5),\n",
    "           K.RandomVerticalFlip(p=0.5),\n",
    "           K.RandomRotation(90),\n",
    "           K.RandomResizedCrop((image_size,image_size)),\n",
    "           K.Normalize(mean,std)\n",
    "           ])\n",
    "    val_transforms=[G.Resize((resize,resize)),\n",
    "           K.CenterCrop((image_size,image_size)),\n",
    "           K.Normalize(mean,std)\n",
    "           ]\n",
    "    transforms=dict(train=nn.Sequential(*train_transforms),\n",
    "                val=nn.Sequential(*val_transforms))\n",
    "    if torch.cuda.is_available():\n",
    "        for k in transforms:\n",
    "            transforms[k]=transforms[k].cuda()\n",
    "    return transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17a92a06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (init_block): ResInitBlock(\n",
      "    (conv): ConvBlock(\n",
      "      (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activ): ReLU(inplace=True)\n",
      "    )\n",
      "    (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (stage1): Sequential(\n",
      "    (unit1): ResUnit(\n",
      "      (body): ResBottleneck(\n",
      "        (conv1): ConvBlock(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): ConvBlock(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv3): ConvBlock(\n",
      "          (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (identity_conv): ConvBlock(\n",
      "        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (activ): ReLU(inplace=True)\n",
      "    )\n",
      "    (unit2): ResUnit(\n",
      "      (body): ResBottleneck(\n",
      "        (conv1): ConvBlock(\n",
      "          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): ConvBlock(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv3): ConvBlock(\n",
      "          (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (activ): ReLU(inplace=True)\n",
      "    )\n",
      "    (unit3): ResUnit(\n",
      "      (body): ResBottleneck(\n",
      "        (conv1): ConvBlock(\n",
      "          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): ConvBlock(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv3): ConvBlock(\n",
      "          (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (activ): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (stage2): Sequential(\n",
      "    (unit1): ResUnit(\n",
      "      (body): ResBottleneck(\n",
      "        (conv1): ConvBlock(\n",
      "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): ConvBlock(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv3): ConvBlock(\n",
      "          (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (identity_conv): ConvBlock(\n",
      "        (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (activ): ReLU(inplace=True)\n",
      "    )\n",
      "    (unit2): ResUnit(\n",
      "      (body): ResBottleneck(\n",
      "        (conv1): ConvBlock(\n",
      "          (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): ConvBlock(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv3): ConvBlock(\n",
      "          (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (activ): ReLU(inplace=True)\n",
      "    )\n",
      "    (unit3): ResUnit(\n",
      "      (body): ResBottleneck(\n",
      "        (conv1): ConvBlock(\n",
      "          (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): ConvBlock(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv3): ConvBlock(\n",
      "          (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (activ): ReLU(inplace=True)\n",
      "    )\n",
      "    (unit4): ResUnit(\n",
      "      (body): ResBottleneck(\n",
      "        (conv1): ConvBlock(\n",
      "          (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): ConvBlock(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv3): ConvBlock(\n",
      "          (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (activ): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (stage3): Sequential(\n",
      "    (unit1): ResUnit(\n",
      "      (body): ResBottleneck(\n",
      "        (conv1): ConvBlock(\n",
      "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): ConvBlock(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv3): ConvBlock(\n",
      "          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (identity_conv): ConvBlock(\n",
      "        (conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (activ): ReLU(inplace=True)\n",
      "    )\n",
      "    (unit2): ResUnit(\n",
      "      (body): ResBottleneck(\n",
      "        (conv1): ConvBlock(\n",
      "          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): ConvBlock(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv3): ConvBlock(\n",
      "          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (activ): ReLU(inplace=True)\n",
      "    )\n",
      "    (unit3): ResUnit(\n",
      "      (body): ResBottleneck(\n",
      "        (conv1): ConvBlock(\n",
      "          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): ConvBlock(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv3): ConvBlock(\n",
      "          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (activ): ReLU(inplace=True)\n",
      "    )\n",
      "    (unit4): ResUnit(\n",
      "      (body): ResBottleneck(\n",
      "        (conv1): ConvBlock(\n",
      "          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): ConvBlock(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv3): ConvBlock(\n",
      "          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (activ): ReLU(inplace=True)\n",
      "    )\n",
      "    (unit5): ResUnit(\n",
      "      (body): ResBottleneck(\n",
      "        (conv1): ConvBlock(\n",
      "          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): ConvBlock(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv3): ConvBlock(\n",
      "          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (activ): ReLU(inplace=True)\n",
      "    )\n",
      "    (unit6): ResUnit(\n",
      "      (body): ResBottleneck(\n",
      "        (conv1): ConvBlock(\n",
      "          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): ConvBlock(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv3): ConvBlock(\n",
      "          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (activ): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (stage4): Sequential(\n",
      "    (unit1): ResUnit(\n",
      "      (body): ResBottleneck(\n",
      "        (conv1): ConvBlock(\n",
      "          (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): ConvBlock(\n",
      "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv3): ConvBlock(\n",
      "          (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (identity_conv): ConvBlock(\n",
      "        (conv): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (activ): ReLU(inplace=True)\n",
      "    )\n",
      "    (unit2): ResUnit(\n",
      "      (body): ResBottleneck(\n",
      "        (conv1): ConvBlock(\n",
      "          (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): ConvBlock(\n",
      "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv3): ConvBlock(\n",
      "          (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (activ): ReLU(inplace=True)\n",
      "    )\n",
      "    (unit3): ResUnit(\n",
      "      (body): ResBottleneck(\n",
      "        (conv1): ConvBlock(\n",
      "          (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): ConvBlock(\n",
      "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv3): ConvBlock(\n",
      "          (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (activ): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (final_pool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
      ") 0\n",
      "Linear(in_features=2048, out_features=1000, bias=True) 1\n",
      "Weights: [ 0.40405693  2.13768574 17.45029129]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "weight tensor should be defined either for all 1000 classes or no classes but got weight tensor of shape: [3]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 158>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    156\u001b[0m     fire\u001b[38;5;241m.\u001b[39mFire(train_model)\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 159\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m--> 156\u001b[0m     \u001b[43mfire\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/hiss/lib/python3.8/site-packages/fire/core.py:141\u001b[0m, in \u001b[0;36mFire\u001b[0;34m(component, command, name)\u001b[0m\n\u001b[1;32m    138\u001b[0m   context\u001b[38;5;241m.\u001b[39mupdate(caller_globals)\n\u001b[1;32m    139\u001b[0m   context\u001b[38;5;241m.\u001b[39mupdate(caller_locals)\n\u001b[0;32m--> 141\u001b[0m component_trace \u001b[38;5;241m=\u001b[39m \u001b[43m_Fire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomponent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparsed_flag_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m component_trace\u001b[38;5;241m.\u001b[39mHasError():\n\u001b[1;32m    144\u001b[0m   _DisplayError(component_trace)\n",
      "File \u001b[0;32m~/anaconda3/envs/hiss/lib/python3.8/site-packages/fire/core.py:466\u001b[0m, in \u001b[0;36m_Fire\u001b[0;34m(component, args, parsed_flag_args, context, name)\u001b[0m\n\u001b[1;32m    463\u001b[0m is_class \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39misclass(component)\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 466\u001b[0m   component, remaining_args \u001b[38;5;241m=\u001b[39m \u001b[43m_CallAndUpdateTrace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcomponent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m      \u001b[49m\u001b[43mremaining_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcomponent_trace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtreatment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclass\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_class\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mroutine\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomponent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    472\u001b[0m   handled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m FireError \u001b[38;5;28;01mas\u001b[39;00m error:\n",
      "File \u001b[0;32m~/anaconda3/envs/hiss/lib/python3.8/site-packages/fire/core.py:681\u001b[0m, in \u001b[0;36m_CallAndUpdateTrace\u001b[0;34m(component, args, component_trace, treatment, target)\u001b[0m\n\u001b[1;32m    679\u001b[0m   component \u001b[38;5;241m=\u001b[39m loop\u001b[38;5;241m.\u001b[39mrun_until_complete(fn(\u001b[38;5;241m*\u001b[39mvarargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[1;32m    680\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 681\u001b[0m   component \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mvarargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m treatment \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    684\u001b[0m   action \u001b[38;5;241m=\u001b[39m trace\u001b[38;5;241m.\u001b[39mINSTANTIATED_CLASS\n",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(inputs_dir, learning_rate, n_epochs, crop_size, resize, mean, std, num_classes, architecture, batch_size, predict, model_save_loc, pretrained_save_loc, predictions_save_path, predict_set, verbose, class_balance, extract_embeddings, extract_embeddings_df, embedding_out_dir, gpu_id, checkpoints_dir, pickle_dataset, label_map, save_metric, custom_dataset, save_predictions, pretrained, save_after_n_batch, include_test_set, use_npy_rotate, sample_frac, sample_every, num_workers, npy_rotate_sets_pkl, visualize_predictions)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m class_balance:\n\u001b[1;32m    106\u001b[0m     trainer\u001b[38;5;241m.\u001b[39madd_class_balance_loss(datasets[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtargets)\n\u001b[0;32m--> 108\u001b[0m trainer, min_val_loss_f1, best_epoch\u001b[38;5;241m=\u001b[39m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(trainer\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mstate_dict(), model_save_loc)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mmodel\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mModelTrainer.fit\u001b[0;34m(self, train_dataloader, verbose, print_every, save_model, plot_training_curves, plot_save_file, print_val_confusion, save_val_predictions)\u001b[0m\n\u001b[1;32m    455\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed)\n\u001b[1;32m    456\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 457\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    458\u001b[0m current_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    459\u001b[0m train_time \u001b[38;5;241m=\u001b[39m current_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mModelTrainer.train_loop\u001b[0;34m(self, epoch, train_dataloader)\u001b[0m\n\u001b[1;32m    298\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(X) \u001b[38;5;28;01mif\u001b[39;00m Z \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(X,Z)\n\u001b[1;32m    299\u001b[0m \u001b[38;5;66;03m# y_true=y_true.argmax(dim=1)\u001b[39;00m\n\u001b[0;32m--> 301\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalc_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# .view(-1,1)\u001b[39;00m\n\u001b[1;32m    302\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    303\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m train_loss\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mModelTrainer.calc_loss\u001b[0;34m(self, y_pred, y_true)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalc_loss\u001b[39m(\u001b[38;5;28mself\u001b[39m, y_pred, y_true):\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;124;03m\"\"\"Calculates loss supplied in init statement and modified by reweighting.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m    ----------\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;124;03m    loss\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/hiss/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/hiss/lib/python3.8/site-packages/torch/nn/modules/loss.py:1164\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/hiss/lib/python3.8/site-packages/torch/nn/functional.py:3014\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3012\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3013\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3014\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: weight tensor should be defined either for all 1000 classes or no classes but got weight tensor of shape: [3]"
     ]
    }
   ],
   "source": [
    "def train_model(inputs_dir=\"/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/users/Sophie_Chen/cnn_model_input/\",\n",
    "                learning_rate=1e-4,\n",
    "                n_epochs=300,\n",
    "                crop_size=224,\n",
    "                resize=256,\n",
    "                mean=[0.5, 0.5, 0.5],\n",
    "                std=[0.1, 0.1, 0.1],\n",
    "                num_classes=3,\n",
    "                architecture='resnet50',\n",
    "                batch_size=32,\n",
    "                predict=False,\n",
    "                model_save_loc='saved_model.pkl',\n",
    "                pretrained_save_loc='pretrained_model.pkl',\n",
    "                predictions_save_path='predictions.pkl',\n",
    "                predict_set='test',\n",
    "                verbose=False,\n",
    "                class_balance=True,\n",
    "                extract_embeddings=\"\",\n",
    "                extract_embeddings_df=\"\",\n",
    "                embedding_out_dir=\"./\",\n",
    "                gpu_id=-1,\n",
    "                checkpoints_dir=\"checkpoints\",\n",
    "                pickle_dataset=True,\n",
    "                label_map=dict(),\n",
    "                save_metric=\"loss\",\n",
    "                custom_dataset=None,\n",
    "                save_predictions=True,\n",
    "                pretrained=False,\n",
    "                save_after_n_batch=0,\n",
    "                include_test_set=False,\n",
    "                use_npy_rotate=False,\n",
    "                sample_frac=1.,\n",
    "                sample_every=0,\n",
    "                num_workers=0,\n",
    "                npy_rotate_sets_pkl=\"\",\n",
    "                visualize_predictions=True,\n",
    "                ):\n",
    "    assert save_metric in ['loss','f1']\n",
    "    if use_npy_rotate: tensor_dataset,pickle_dataset=False,False\n",
    "    else: sample_every=0\n",
    "    if predict: include_test_set=True\n",
    "    if predict: assert not use_npy_rotate\n",
    "    if extract_embeddings: assert predict, \"Must be in prediction mode to extract embeddings\"\n",
    "    if gpu_id>=0: torch.cuda.set_device(gpu_id)\n",
    "    transformers=generate_transformers \n",
    "    transformers = transformers(\n",
    "        image_size=crop_size, resize=resize, mean=mean, std=std)\n",
    "    if custom_dataset is not None:\n",
    "        assert predict\n",
    "        datasets={}\n",
    "        datasets['custom']=custom_dataset\n",
    "        predict_set='custom'\n",
    "    else:\n",
    "        if pickle_dataset:\n",
    "            datasets = {x: PickleDataset(os.path.join(inputs_dir,f\"{x}_data.pkl\"),transformers[x],label_map) for x in (['train','val']+(['test'] if include_test_set else [])) if os.path.exists(os.path.join(inputs_dir,f\"{x}_data.pkl\"))}\n",
    "        elif use_npy_rotate:\n",
    "            datasets = {x: NPYRotatingStack(os.path.join(inputs_dir,x),transformers[x],(sample_frac if x=='train' else 1.),sample_every,label_map,npy_rotate_sets_pkl,x) for x in (['train','val']+(['test'] if include_test_set else []))}\n",
    "        else:\n",
    "            datasets = {x: Datasets.ImageFolder(os.path.join(\n",
    "                inputs_dir, x), transformers[x]) for x in (['train','val']+(['test'] if include_test_set else []))}\n",
    "\n",
    "    if verbose: print(datasets)\n",
    "\n",
    "    dataloaders = {x: DataLoader(\n",
    "        datasets[x], batch_size=batch_size, num_workers=num_workers, shuffle=(x == 'train' and not predict), worker_init_fn=None) for x in datasets}\n",
    "\n",
    "    model = generate_model(architecture,\n",
    "                           num_classes,\n",
    "                           pretrained=pretrained,\n",
    "                           n_aux_features=None if  \"n_aux_features\" not in dir(datasets.get('train',datasets.get('custom',None))) else datasets.get('train',datasets.get('custom',None)).n_aux_features)\n",
    "    \n",
    "    \n",
    "    if verbose: print(model)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "\n",
    "    optimizer_opts = dict(name='adam',\n",
    "                          lr=learning_rate,\n",
    "                          weight_decay=1e-4)\n",
    "\n",
    "    scheduler_opts = dict(scheduler='warm_restarts',\n",
    "                          lr_scheduler_decay=0.5,\n",
    "                          T_max=10,\n",
    "                          eta_min=5e-8,\n",
    "                          T_mult=2)\n",
    "\n",
    "    trainer = ModelTrainer(model,\n",
    "                           n_epochs,\n",
    "                           None if predict else dataloaders['val'],\n",
    "                           optimizer_opts,\n",
    "                           scheduler_opts,\n",
    "                           loss_fn='dice' if not class_balance else 'ce',\n",
    "                           checkpoints_dir=checkpoints_dir,\n",
    "                           tensor_dataset=None,\n",
    "                           transforms=transformers,\n",
    "                           save_metric=save_metric,\n",
    "                           save_after_n_batch=save_after_n_batch)\n",
    "\n",
    "    if os.path.exists(pretrained_save_loc):\n",
    "        trainer.model.load_state_dict(torch.load(pretrained_save_loc,map_location=f\"cuda:{gpu_id}\" if gpu_id>=0 else \"cpu\"))\n",
    "\n",
    "    if not predict:\n",
    "\n",
    "        if class_balance:\n",
    "            trainer.add_class_balance_loss(datasets['train'].targets)\n",
    "\n",
    "        trainer, min_val_loss_f1, best_epoch=trainer.fit(dataloaders['train'],verbose=verbose)\n",
    "\n",
    "        torch.save(trainer.model.state_dict(), model_save_loc)\n",
    "\n",
    "        return trainer.model\n",
    "\n",
    "    else:\n",
    "        # assert not tensor_dataset, \"Only ImageFolder and NPYDatasets allowed\"\n",
    "\n",
    "        if os.path.exists(model_save_loc):\n",
    "            trainer.model.load_state_dict(torch.load(model_save_loc,map_location=f\"cuda:{gpu_id}\" if gpu_id>=0 else \"cpu\"))\n",
    "\n",
    "        if extract_embeddings:\n",
    "            trainer.model=nn.Sequential(trainer.model.features,Reshape())#,trainer.model.output\n",
    "            if predict_set=='custom':\n",
    "                dataset=datasets['custom']\n",
    "                assert 'embed' in dir(dataset), \"Embedding method required for dataset with model input, batch size and embedding output directory as arguments.\"\n",
    "            else:\n",
    "                assert len(extract_embeddings_df)>0 and os.path.exists(extract_embeddings_df), \"Must load data from SQL database or pickle if not using custom dataset\"\n",
    "                if extract_embeddings_df.endswith(\".db\"):\n",
    "                    from pathflowai.utils import load_sql_df\n",
    "                    patch_info=load_sql_df(extract_embeddings_df,resize)\n",
    "                elif extract_embeddings_df.endswith(\".pkl\"):\n",
    "                    patch_info=pd.read_pickle(extract_embeddings_df)\n",
    "                    assert patch_info['patch_size'].iloc[0]==resize, \"Patch size pickle does not match.\"\n",
    "                else:\n",
    "                    raise NotImplementedError\n",
    "                dataset=NPYDataset(patch_info,extract_embeddings,transformers[\"test\"],tensor_dataset)\n",
    "            return dataset.embed(trainer.model,batch_size,embedding_out_dir)\n",
    "            # return \"Output Embeddings\"\n",
    "            \n",
    "        else:\n",
    "            Y = dict()\n",
    "\n",
    "            Y['pred'],Y['true'] = trainer.predict(dataloaders[predict_set])\n",
    "\n",
    "            # Y['model'] = trainer.model\n",
    "\n",
    "            # Y['true'] = datasets[predict_set].targets\n",
    "\n",
    "            if save_predictions: torch.save(Y, predictions_save_path)\n",
    "\n",
    "            return Y\n",
    "    #if visualize_predictions:\n",
    "        \n",
    "        \n",
    "\n",
    "def main():\n",
    "    fire.Fire(train_model)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "580c5509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': <__main__.NPYRotatingStack object at 0x2adfa215fca0>, 'val': <__main__.NPYRotatingStack object at 0x2adfa2151940>}\n",
      "Sequential(\n",
      "  (init_block): ResInitBlock(\n",
      "    (conv): ConvBlock(\n",
      "      (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activ): ReLU(inplace=True)\n",
      "    )\n",
      "    (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (stage1): Sequential(\n",
      "    (unit1): ResUnit(\n",
      "      (body): ResBottleneck(\n",
      "        (conv1): ConvBlock(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): ConvBlock(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv3): ConvBlock(\n",
      "          (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (identity_conv): ConvBlock(\n",
      "        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (activ): ReLU(inplace=True)\n",
      "    )\n",
      "    (unit2): ResUnit(\n",
      "      (body): ResBottleneck(\n",
      "        (conv1): ConvBlock(\n",
      "          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): ConvBlock(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv3): ConvBlock(\n",
      "          (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (activ): ReLU(inplace=True)\n",
      "    )\n",
      "    (unit3): ResUnit(\n",
      "      (body): ResBottleneck(\n",
      "        (conv1): ConvBlock(\n",
      "          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): ConvBlock(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv3): ConvBlock(\n",
      "          (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (activ): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (stage2): Sequential(\n",
      "    (unit1): ResUnit(\n",
      "      (body): ResBottleneck(\n",
      "        (conv1): ConvBlock(\n",
      "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): ConvBlock(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv3): ConvBlock(\n",
      "          (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (identity_conv): ConvBlock(\n",
      "        (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (activ): ReLU(inplace=True)\n",
      "    )\n",
      "    (unit2): ResUnit(\n",
      "      (body): ResBottleneck(\n",
      "        (conv1): ConvBlock(\n",
      "          (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): ConvBlock(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv3): ConvBlock(\n",
      "          (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (activ): ReLU(inplace=True)\n",
      "    )\n",
      "    (unit3): ResUnit(\n",
      "      (body): ResBottleneck(\n",
      "        (conv1): ConvBlock(\n",
      "          (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): ConvBlock(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv3): ConvBlock(\n",
      "          (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (activ): ReLU(inplace=True)\n",
      "    )\n",
      "    (unit4): ResUnit(\n",
      "      (body): ResBottleneck(\n",
      "        (conv1): ConvBlock(\n",
      "          (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): ConvBlock(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv3): ConvBlock(\n",
      "          (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (activ): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (stage3): Sequential(\n",
      "    (unit1): ResUnit(\n",
      "      (body): ResBottleneck(\n",
      "        (conv1): ConvBlock(\n",
      "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): ConvBlock(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv3): ConvBlock(\n",
      "          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (identity_conv): ConvBlock(\n",
      "        (conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (activ): ReLU(inplace=True)\n",
      "    )\n",
      "    (unit2): ResUnit(\n",
      "      (body): ResBottleneck(\n",
      "        (conv1): ConvBlock(\n",
      "          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): ConvBlock(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv3): ConvBlock(\n",
      "          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (activ): ReLU(inplace=True)\n",
      "    )\n",
      "    (unit3): ResUnit(\n",
      "      (body): ResBottleneck(\n",
      "        (conv1): ConvBlock(\n",
      "          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): ConvBlock(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv3): ConvBlock(\n",
      "          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (activ): ReLU(inplace=True)\n",
      "    )\n",
      "    (unit4): ResUnit(\n",
      "      (body): ResBottleneck(\n",
      "        (conv1): ConvBlock(\n",
      "          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): ConvBlock(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv3): ConvBlock(\n",
      "          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (activ): ReLU(inplace=True)\n",
      "    )\n",
      "    (unit5): ResUnit(\n",
      "      (body): ResBottleneck(\n",
      "        (conv1): ConvBlock(\n",
      "          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): ConvBlock(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv3): ConvBlock(\n",
      "          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (activ): ReLU(inplace=True)\n",
      "    )\n",
      "    (unit6): ResUnit(\n",
      "      (body): ResBottleneck(\n",
      "        (conv1): ConvBlock(\n",
      "          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): ConvBlock(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv3): ConvBlock(\n",
      "          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (activ): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (stage4): Sequential(\n",
      "    (unit1): ResUnit(\n",
      "      (body): ResBottleneck(\n",
      "        (conv1): ConvBlock(\n",
      "          (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): ConvBlock(\n",
      "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv3): ConvBlock(\n",
      "          (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (identity_conv): ConvBlock(\n",
      "        (conv): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (activ): ReLU(inplace=True)\n",
      "    )\n",
      "    (unit2): ResUnit(\n",
      "      (body): ResBottleneck(\n",
      "        (conv1): ConvBlock(\n",
      "          (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): ConvBlock(\n",
      "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv3): ConvBlock(\n",
      "          (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (activ): ReLU(inplace=True)\n",
      "    )\n",
      "    (unit3): ResUnit(\n",
      "      (body): ResBottleneck(\n",
      "        (conv1): ConvBlock(\n",
      "          (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): ConvBlock(\n",
      "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activ): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv3): ConvBlock(\n",
      "          (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (activ): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (final_pool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
      ") 0\n",
      "Linear(in_features=2048, out_features=1000, bias=True) 1\n",
      "ResNet(\n",
      "  (features): Sequential(\n",
      "    (init_block): ResInitBlock(\n",
      "      (conv): ConvBlock(\n",
      "        (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activ): ReLU(inplace=True)\n",
      "      )\n",
      "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (stage1): Sequential(\n",
      "      (unit1): ResUnit(\n",
      "        (body): ResBottleneck(\n",
      "          (conv1): ConvBlock(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv2): ConvBlock(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv3): ConvBlock(\n",
      "            (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (identity_conv): ConvBlock(\n",
      "          (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (activ): ReLU(inplace=True)\n",
      "      )\n",
      "      (unit2): ResUnit(\n",
      "        (body): ResBottleneck(\n",
      "          (conv1): ConvBlock(\n",
      "            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv2): ConvBlock(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv3): ConvBlock(\n",
      "            (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activ): ReLU(inplace=True)\n",
      "      )\n",
      "      (unit3): ResUnit(\n",
      "        (body): ResBottleneck(\n",
      "          (conv1): ConvBlock(\n",
      "            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv2): ConvBlock(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv3): ConvBlock(\n",
      "            (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activ): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (stage2): Sequential(\n",
      "      (unit1): ResUnit(\n",
      "        (body): ResBottleneck(\n",
      "          (conv1): ConvBlock(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv2): ConvBlock(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv3): ConvBlock(\n",
      "            (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (identity_conv): ConvBlock(\n",
      "          (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (activ): ReLU(inplace=True)\n",
      "      )\n",
      "      (unit2): ResUnit(\n",
      "        (body): ResBottleneck(\n",
      "          (conv1): ConvBlock(\n",
      "            (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv2): ConvBlock(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv3): ConvBlock(\n",
      "            (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activ): ReLU(inplace=True)\n",
      "      )\n",
      "      (unit3): ResUnit(\n",
      "        (body): ResBottleneck(\n",
      "          (conv1): ConvBlock(\n",
      "            (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv2): ConvBlock(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv3): ConvBlock(\n",
      "            (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activ): ReLU(inplace=True)\n",
      "      )\n",
      "      (unit4): ResUnit(\n",
      "        (body): ResBottleneck(\n",
      "          (conv1): ConvBlock(\n",
      "            (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv2): ConvBlock(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv3): ConvBlock(\n",
      "            (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activ): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (stage3): Sequential(\n",
      "      (unit1): ResUnit(\n",
      "        (body): ResBottleneck(\n",
      "          (conv1): ConvBlock(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv2): ConvBlock(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv3): ConvBlock(\n",
      "            (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (identity_conv): ConvBlock(\n",
      "          (conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (activ): ReLU(inplace=True)\n",
      "      )\n",
      "      (unit2): ResUnit(\n",
      "        (body): ResBottleneck(\n",
      "          (conv1): ConvBlock(\n",
      "            (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv2): ConvBlock(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv3): ConvBlock(\n",
      "            (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activ): ReLU(inplace=True)\n",
      "      )\n",
      "      (unit3): ResUnit(\n",
      "        (body): ResBottleneck(\n",
      "          (conv1): ConvBlock(\n",
      "            (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv2): ConvBlock(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv3): ConvBlock(\n",
      "            (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activ): ReLU(inplace=True)\n",
      "      )\n",
      "      (unit4): ResUnit(\n",
      "        (body): ResBottleneck(\n",
      "          (conv1): ConvBlock(\n",
      "            (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv2): ConvBlock(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv3): ConvBlock(\n",
      "            (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activ): ReLU(inplace=True)\n",
      "      )\n",
      "      (unit5): ResUnit(\n",
      "        (body): ResBottleneck(\n",
      "          (conv1): ConvBlock(\n",
      "            (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv2): ConvBlock(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv3): ConvBlock(\n",
      "            (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activ): ReLU(inplace=True)\n",
      "      )\n",
      "      (unit6): ResUnit(\n",
      "        (body): ResBottleneck(\n",
      "          (conv1): ConvBlock(\n",
      "            (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv2): ConvBlock(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv3): ConvBlock(\n",
      "            (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activ): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (stage4): Sequential(\n",
      "      (unit1): ResUnit(\n",
      "        (body): ResBottleneck(\n",
      "          (conv1): ConvBlock(\n",
      "            (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv2): ConvBlock(\n",
      "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv3): ConvBlock(\n",
      "            (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (identity_conv): ConvBlock(\n",
      "          (conv): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (activ): ReLU(inplace=True)\n",
      "      )\n",
      "      (unit2): ResUnit(\n",
      "        (body): ResBottleneck(\n",
      "          (conv1): ConvBlock(\n",
      "            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv2): ConvBlock(\n",
      "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv3): ConvBlock(\n",
      "            (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activ): ReLU(inplace=True)\n",
      "      )\n",
      "      (unit3): ResUnit(\n",
      "        (body): ResBottleneck(\n",
      "          (conv1): ConvBlock(\n",
      "            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv2): ConvBlock(\n",
      "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv3): ConvBlock(\n",
      "            (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activ): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (final_pool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
      "  )\n",
      "  (output): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n",
      "Weights: [ 0.40405693 17.45029129  2.13768574]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/users/Sophie_Chen/cnn_model_input/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                \u001b[49m\u001b[43mpredict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmodel_save_loc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/users/Sophie_Chen/cnn_model_123.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                \u001b[49m\u001b[43mclass_balance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                \u001b[49m\u001b[43mpickle_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcustom_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                \u001b[49m\u001b[43msave_predictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                \u001b[49m\u001b[43minclude_test_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                \u001b[49m\u001b[43muse_npy_rotate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                \u001b[49m\u001b[43mlabel_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my_true\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my_true\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                \u001b[49m\u001b[43msample_frac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                \u001b[49m\u001b[43msample_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                \u001b[49m\u001b[43mnpy_rotate_sets_pkl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/users/Sophie_Chen/rotating_stack.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(inputs_dir, learning_rate, n_epochs, crop_size, resize, mean, std, num_classes, architecture, batch_size, predict, model_save_loc, pretrained_save_loc, predictions_save_path, predict_set, verbose, class_balance, extract_embeddings, extract_embeddings_df, embedding_out_dir, gpu_id, checkpoints_dir, pickle_dataset, label_map, save_metric, custom_dataset, save_predictions, pretrained, save_after_n_batch, include_test_set, use_npy_rotate, sample_frac, sample_every, num_workers, npy_rotate_sets_pkl, visualize_predictions)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m class_balance:\n\u001b[1;32m    106\u001b[0m     trainer\u001b[38;5;241m.\u001b[39madd_class_balance_loss(datasets[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtargets)\n\u001b[0;32m--> 108\u001b[0m trainer, min_val_loss_f1, best_epoch\u001b[38;5;241m=\u001b[39m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(trainer\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mstate_dict(), model_save_loc)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mmodel\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mModelTrainer.fit\u001b[0;34m(self, train_dataloader, verbose, print_every, save_model, plot_training_curves, plot_save_file, print_val_confusion, save_val_predictions)\u001b[0m\n\u001b[1;32m    455\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed)\n\u001b[1;32m    456\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 457\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    458\u001b[0m current_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    459\u001b[0m train_time \u001b[38;5;241m=\u001b[39m current_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mModelTrainer.train_loop\u001b[0;34m(self, epoch, train_dataloader)\u001b[0m\n\u001b[1;32m    277\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m\n\u001b[1;32m    278\u001b[0m n_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\n\u001b[1;32m    279\u001b[0m     train_dataloader\u001b[38;5;241m.\u001b[39mdataset) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m train_dataloader\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_train_batches \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_train_batches\n\u001b[0;32m--> 280\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataloader):\n\u001b[1;32m    281\u001b[0m     starttime \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    282\u001b[0m     X, y_true \u001b[38;5;241m=\u001b[39m batch[:\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/hiss/lib/python3.8/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/hiss/lib/python3.8/site-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/hiss/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/hiss/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mNPYRotatingStack.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     76\u001b[0m i,j\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mref_index[idx]\n\u001b[1;32m     77\u001b[0m npy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_npy[i]\n\u001b[0;32m---> 78\u001b[0m X\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnpy\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpatches\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     79\u001b[0m y\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mLongTensor(np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[npy][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpatch_info\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[j][\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_col[\u001b[38;5;241m1\u001b[39m]])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     80\u001b[0m X\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_pil(X))\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "train_model(inputs_dir=\"/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/users/Sophie_Chen/cnn_model_input/\",\n",
    "                learning_rate=1e-4,\n",
    "                n_epochs=10,\n",
    "                num_classes=3,\n",
    "                batch_size=32,\n",
    "                predict=False,\n",
    "                model_save_loc='/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/users/Sophie_Chen/cnn_model_123.pth',\n",
    "                verbose=2,\n",
    "                class_balance=True,\n",
    "                pickle_dataset=True,\n",
    "                custom_dataset=None,\n",
    "                save_predictions=True,\n",
    "                include_test_set=False,\n",
    "                use_npy_rotate=True,\n",
    "                label_map={'y_true':'y_true'},\n",
    "                sample_frac=1.,\n",
    "                sample_every=3,\n",
    "                num_workers=0,\n",
    "                npy_rotate_sets_pkl=\"/dartfs/rc/nosnapshots/V/VaickusL-nb/EDIT_Students/users/Sophie_Chen/rotating_stack.pkl\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b962c40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76bbe77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badebf61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef3ec56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2675b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hiss",
   "language": "python",
   "name": "hiss"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
